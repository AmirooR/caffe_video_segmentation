I0627 15:24:51.559839  3328 caffe.cpp:185] Using GPUs 0
I0627 15:24:51.568156  3328 caffe.cpp:190] GPU 0: Tesla K40c
I0627 15:24:51.698717  3328 solver.cpp:48] Initializing solver from parameters: 
train_net: "train_davis_simple.prototxt"
base_lr: 1e-05
display: 20
max_iter: 500
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 500
snapshot: 250
snapshot_prefix: "./snapshots/davis_simple"
device_id: 0
average_loss: 20
iter_size: 5
I0627 15:24:51.698823  3328 solver.cpp:81] Creating training net from train_net file: train_davis_simple.prototxt
I0627 15:24:51.700603  3328 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "cur_im"
  type: "Python"
  top: "cur_im"
  top: "masked_im"
  top: "next_im"
  top: "label"
  python_param {
    module: "davis_datalayer_prefetch_randomer"
    layer: "DavisDataLayerPrefetch"
    param_str: "{\'im_shape\': (384, 384), \'num_threads\': 2, \'max_queue_size\': 8, \'split\': \'training\', \'batch_size\': 4}"
  }
}
layer {
  name: "conv1_1c"
  type: "Convolution"
  bottom: "cur_im"
  top: "conv1_1c"
  param {
    name: "conv1_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 101
    kernel_size: 3
  }
}
layer {
  name: "relu1_1c"
  type: "ReLU"
  bottom: "conv1_1c"
  top: "conv1_1c"
}
layer {
  name: "conv1_2c"
  type: "Convolution"
  bottom: "conv1_1c"
  top: "conv1_2c"
  param {
    name: "conv1_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2c"
  type: "ReLU"
  bottom: "conv1_2c"
  top: "conv1_2c"
}
layer {
  name: "pool1c"
  type: "Pooling"
  bottom: "conv1_2c"
  top: "pool1c"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1c"
  type: "Convolution"
  bottom: "pool1c"
  top: "conv2_1c"
  param {
    name: "conv2_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1c"
  type: "ReLU"
  bottom: "conv2_1c"
  top: "conv2_1c"
}
layer {
  name: "conv2_2c"
  type: "Convolution"
  bottom: "conv2_1c"
  top: "conv2_2c"
  param {
    name: "conv2_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2c"
  type: "ReLU"
  bottom: "conv2_2c"
  top: "conv2_2c"
}
layer {
  name: "pool2c"
  type: "Pooling"
  bottom: "conv2_2c"
  top: "pool2c"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1c"
  type: "Convolution"
  bottom: "pool2c"
  top: "conv3_1c"
  param {
    name: "conv3_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1c"
  type: "ReLU"
  bottom: "conv3_1c"
  top: "conv3_1c"
}
layer {
  name: "conv3_2c"
  type: "Convolution"
  bottom: "conv3_1c"
  top: "conv3_2c"
  param {
    name: "conv3_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2c"
  type: "ReLU"
  bottom: "conv3_2c"
  top: "conv3_2c"
}
layer {
  name: "conv3_3c"
  type: "Convolution"
  bottom: "conv3_2c"
  top: "conv3_3c"
  param {
    name: "conv3_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3c"
  type: "ReLU"
  bottom: "conv3_3c"
  top: "conv3_3c"
}
layer {
  name: "pool3c"
  type: "Pooling"
  bottom: "conv3_3c"
  top: "pool3c"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1c"
  type: "Convolution"
  bottom: "pool3c"
  top: "conv4_1c"
  param {
    name: "conv4_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1c"
  type: "ReLU"
  bottom: "conv4_1c"
  top: "conv4_1c"
}
layer {
  name: "conv4_2c"
  type: "Convolution"
  bottom: "conv4_1c"
  top: "conv4_2c"
  param {
    name: "conv4_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2c"
  type: "ReLU"
  bottom: "conv4_2c"
  top: "conv4_2c"
}
layer {
  name: "conv4_3c"
  type: "Convolution"
  bottom: "conv4_2c"
  top: "conv4_3c"
  param {
    name: "conv4_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3c"
  type: "ReLU"
  bottom: "conv4_3c"
  top: "conv4_3c"
}
layer {
  name: "conv5_1c"
  type: "Convolution"
  bottom: "conv4_3c"
  top: "conv5_1c"
  param {
    name: "conv5_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_1c"
  type: "ReLU"
  bottom: "conv5_1c"
  top: "conv5_1c"
}
layer {
  name: "conv5_2c"
  type: "Convolution"
  bottom: "conv5_1c"
  top: "conv5_2c"
  param {
    name: "conv5_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_2c"
  type: "ReLU"
  bottom: "conv5_2c"
  top: "conv5_2c"
}
layer {
  name: "conv5_3c"
  type: "Convolution"
  bottom: "conv5_2c"
  top: "conv5_3c"
  param {
    name: "conv5_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad_h: 14
    pad_w: 14
    dilation: 2
  }
}
layer {
  name: "relu5_3c"
  type: "ReLU"
  bottom: "conv5_3c"
  top: "conv5_3c"
}
layer {
  name: "conv1_1m"
  type: "Convolution"
  bottom: "masked_im"
  top: "conv1_1m"
  param {
    name: "conv1_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 101
    kernel_size: 3
  }
}
layer {
  name: "relu1_1m"
  type: "ReLU"
  bottom: "conv1_1m"
  top: "conv1_1m"
}
layer {
  name: "conv1_2m"
  type: "Convolution"
  bottom: "conv1_1m"
  top: "conv1_2m"
  param {
    name: "conv1_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2m"
  type: "ReLU"
  bottom: "conv1_2m"
  top: "conv1_2m"
}
layer {
  name: "pool1m"
  type: "Pooling"
  bottom: "conv1_2m"
  top: "pool1m"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1m"
  type: "Convolution"
  bottom: "pool1m"
  top: "conv2_1m"
  param {
    name: "conv2_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1m"
  type: "ReLU"
  bottom: "conv2_1m"
  top: "conv2_1m"
}
layer {
  name: "conv2_2m"
  type: "Convolution"
  bottom: "conv2_1m"
  top: "conv2_2m"
  param {
    name: "conv2_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2m"
  type: "ReLU"
  bottom: "conv2_2m"
  top: "conv2_2m"
}
layer {
  name: "pool2m"
  type: "Pooling"
  bottom: "conv2_2m"
  top: "pool2m"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1m"
  type: "Convolution"
  bottom: "pool2m"
  top: "conv3_1m"
  param {
    name: "conv3_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1m"
  type: "ReLU"
  bottom: "conv3_1m"
  top: "conv3_1m"
}
layer {
  name: "conv3_2m"
  type: "Convolution"
  bottom: "conv3_1m"
  top: "conv3_2m"
  param {
    name: "conv3_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2m"
  type: "ReLU"
  bottom: "conv3_2m"
  top: "conv3_2m"
}
layer {
  name: "conv3_3m"
  type: "Convolution"
  bottom: "conv3_2m"
  top: "conv3_3m"
  param {
    name: "conv3_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3m"
  type: "ReLU"
  bottom: "conv3_3m"
  top: "conv3_3m"
}
layer {
  name: "pool3m"
  type: "Pooling"
  bottom: "conv3_3m"
  top: "pool3m"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1m"
  type: "Convolution"
  bottom: "pool3m"
  top: "conv4_1m"
  param {
    name: "conv4_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1m"
  type: "ReLU"
  bottom: "conv4_1m"
  top: "conv4_1m"
}
layer {
  name: "conv4_2m"
  type: "Convolution"
  bottom: "conv4_1m"
  top: "conv4_2m"
  param {
    name: "conv4_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2m"
  type: "ReLU"
  bottom: "conv4_2m"
  top: "conv4_2m"
}
layer {
  name: "conv4_3m"
  type: "Convolution"
  bottom: "conv4_2m"
  top: "conv4_3m"
  param {
    name: "conv4_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3m"
  type: "ReLU"
  bottom: "conv4_3m"
  top: "conv4_3m"
}
layer {
  name: "conv5_1m"
  type: "Convolution"
  bottom: "conv4_3m"
  top: "conv5_1m"
  param {
    name: "conv5_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_1m"
  type: "ReLU"
  bottom: "conv5_1m"
  top: "conv5_1m"
}
layer {
  name: "conv5_2m"
  type: "Convolution"
  bottom: "conv5_1m"
  top: "conv5_2m"
  param {
    name: "conv5_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_2m"
  type: "ReLU"
  bottom: "conv5_2m"
  top: "conv5_2m"
}
layer {
  name: "conv5_3m"
  type: "Convolution"
  bottom: "conv5_2m"
  top: "conv5_3m"
  param {
    name: "conv5_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad_h: 14
    pad_w: 14
    dilation: 2
  }
}
layer {
  name: "relu5_3m"
  type: "ReLU"
  bottom: "conv5_3m"
  top: "conv5_3m"
}
layer {
  name: "conv1_1n"
  type: "Convolution"
  bottom: "next_im"
  top: "conv1_1n"
  param {
    name: "conv1_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 101
    kernel_size: 3
  }
}
layer {
  name: "relu1_1n"
  type: "ReLU"
  bottom: "conv1_1n"
  top: "conv1_1n"
}
layer {
  name: "conv1_2n"
  type: "Convolution"
  bottom: "conv1_1n"
  top: "conv1_2n"
  param {
    name: "conv1_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2n"
  type: "ReLU"
  bottom: "conv1_2n"
  top: "conv1_2n"
}
layer {
  name: "pool1n"
  type: "Pooling"
  bottom: "conv1_2n"
  top: "pool1n"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1n"
  type: "Convolution"
  bottom: "pool1n"
  top: "conv2_1n"
  param {
    name: "conv2_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1n"
  type: "ReLU"
  bottom: "conv2_1n"
  top: "conv2_1n"
}
layer {
  name: "conv2_2n"
  type: "Convolution"
  bottom: "conv2_1n"
  top: "conv2_2n"
  param {
    name: "conv2_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2n"
  type: "ReLU"
  bottom: "conv2_2n"
  top: "conv2_2n"
}
layer {
  name: "pool2n"
  type: "Pooling"
  bottom: "conv2_2n"
  top: "pool2n"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1n"
  type: "Convolution"
  bottom: "pool2n"
  top: "conv3_1n"
  param {
    name: "conv3_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1n"
  type: "ReLU"
  bottom: "conv3_1n"
  top: "conv3_1n"
}
layer {
  name: "conv3_2n"
  type: "Convolution"
  bottom: "conv3_1n"
  top: "conv3_2n"
  param {
    name: "conv3_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2n"
  type: "ReLU"
  bottom: "conv3_2n"
  top: "conv3_2n"
}
layer {
  name: "conv3_3n"
  type: "Convolution"
  bottom: "conv3_2n"
  top: "conv3_3n"
  param {
    name: "conv3_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3n"
  type: "ReLU"
  bottom: "conv3_3n"
  top: "conv3_3n"
}
layer {
  name: "pool3n"
  type: "Pooling"
  bottom: "conv3_3n"
  top: "pool3n"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1n"
  type: "Convolution"
  bottom: "pool3n"
  top: "conv4_1n"
  param {
    name: "conv4_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1n"
  type: "ReLU"
  bottom: "conv4_1n"
  top: "conv4_1n"
}
layer {
  name: "conv4_2n"
  type: "Convolution"
  bottom: "conv4_1n"
  top: "conv4_2n"
  param {
    name: "conv4_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2n"
  type: "ReLU"
  bottom: "conv4_2n"
  top: "conv4_2n"
}
layer {
  name: "conv4_3n"
  type: "Convolution"
  bottom: "conv4_2n"
  top: "conv4_3n"
  param {
    name: "conv4_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3n"
  type: "ReLU"
  bottom: "conv4_3n"
  top: "conv4_3n"
}
layer {
  name: "conv5_1n"
  type: "Convolution"
  bottom: "conv4_3n"
  top: "conv5_1n"
  param {
    name: "conv5_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_1n"
  type: "ReLU"
  bottom: "conv5_1n"
  top: "conv5_1n"
}
layer {
  name: "conv5_2n"
  type: "Convolution"
  bottom: "conv5_1n"
  top: "conv5_2n"
  param {
    name: "conv5_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_2n"
  type: "ReLU"
  bottom: "conv5_2n"
  top: "conv5_2n"
}
layer {
  name: "conv5_3n"
  type: "Convolution"
  bottom: "conv5_2n"
  top: "conv5_3n"
  param {
    name: "conv5_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_3n"
  type: "ReLU"
  bottom: "conv5_3n"
  top: "conv5_3n"
}
layer {
  name: "concat1"
  type: "Concat"
  bottom: "conv5_3c"
  bottom: "conv5_3m"
  bottom: "conv5_3n"
  top: "concat1"
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "concat1"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 7
    dilation: 4
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "Convolution"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    kernel_size: 1
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "fc8"
  top: "upscore"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    bias_term: false
    kernel_size: 16
    group: 2
    stride: 8
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "score"
  type: "Crop"
  bottom: "upscore"
  bottom: "next_im"
  top: "score"
  crop_param {
    axis: 2
    offset: 8
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
  loss_param {
    ignore_label: 255
  }
}
I0627 15:24:51.700871  3328 layer_factory.hpp:77] Creating layer cur_im
/home/amir/davis/python/lib/davis/measures/t_stability.py:6: RuntimeWarning: to-Python converter for std::vector<bool, std::allocator<bool> > already registered; second conversion method ignored.
  from tstab import *
I0627 15:24:52.240005  3328 net.cpp:91] Creating Layer cur_im
I0627 15:24:52.240044  3328 net.cpp:399] cur_im -> cur_im
I0627 15:24:52.240067  3328 net.cpp:399] cur_im -> masked_im
I0627 15:24:52.240074  3328 net.cpp:399] cur_im -> next_im
I0627 15:24:52.240078  3328 net.cpp:399] cur_im -> label
I0627 15:24:52.288981  3328 net.cpp:141] Setting up cur_im
I0627 15:24:52.289016  3328 net.cpp:148] Top shape: 4 3 192 192 (442368)
I0627 15:24:52.289021  3328 net.cpp:148] Top shape: 4 3 192 192 (442368)
I0627 15:24:52.289023  3328 net.cpp:148] Top shape: 4 3 384 384 (1769472)
I0627 15:24:52.289026  3328 net.cpp:148] Top shape: 4 1 384 384 (589824)
I0627 15:24:52.289028  3328 net.cpp:156] Memory required for data: 12976128
I0627 15:24:52.289038  3328 layer_factory.hpp:77] Creating layer next_im_cur_im_2_split
I0627 15:24:52.289058  3328 net.cpp:91] Creating Layer next_im_cur_im_2_split
I0627 15:24:52.289063  3328 net.cpp:425] next_im_cur_im_2_split <- next_im
I0627 15:24:52.289088  3328 net.cpp:399] next_im_cur_im_2_split -> next_im_cur_im_2_split_0
I0627 15:24:52.289134  3328 net.cpp:399] next_im_cur_im_2_split -> next_im_cur_im_2_split_1
I0627 15:24:52.289168  3328 net.cpp:141] Setting up next_im_cur_im_2_split
I0627 15:24:52.289173  3328 net.cpp:148] Top shape: 4 3 384 384 (1769472)
I0627 15:24:52.289176  3328 net.cpp:148] Top shape: 4 3 384 384 (1769472)
I0627 15:24:52.289178  3328 net.cpp:156] Memory required for data: 27131904
I0627 15:24:52.289180  3328 layer_factory.hpp:77] Creating layer conv1_1c
I0627 15:24:52.289191  3328 net.cpp:91] Creating Layer conv1_1c
I0627 15:24:52.289194  3328 net.cpp:425] conv1_1c <- cur_im
I0627 15:24:52.289197  3328 net.cpp:399] conv1_1c -> conv1_1c
I0627 15:24:52.394485  3328 net.cpp:141] Setting up conv1_1c
I0627 15:24:52.394515  3328 net.cpp:148] Top shape: 4 64 392 392 (39337984)
I0627 15:24:52.394518  3328 net.cpp:156] Memory required for data: 184483840
I0627 15:24:52.394536  3328 layer_factory.hpp:77] Creating layer relu1_1c
I0627 15:24:52.394546  3328 net.cpp:91] Creating Layer relu1_1c
I0627 15:24:52.394549  3328 net.cpp:425] relu1_1c <- conv1_1c
I0627 15:24:52.394554  3328 net.cpp:386] relu1_1c -> conv1_1c (in-place)
I0627 15:24:52.394700  3328 net.cpp:141] Setting up relu1_1c
I0627 15:24:52.394706  3328 net.cpp:148] Top shape: 4 64 392 392 (39337984)
I0627 15:24:52.394709  3328 net.cpp:156] Memory required for data: 341835776
I0627 15:24:52.394711  3328 layer_factory.hpp:77] Creating layer conv1_2c
I0627 15:24:52.394721  3328 net.cpp:91] Creating Layer conv1_2c
I0627 15:24:52.394722  3328 net.cpp:425] conv1_2c <- conv1_1c
I0627 15:24:52.394726  3328 net.cpp:399] conv1_2c -> conv1_2c
I0627 15:24:52.395882  3328 net.cpp:141] Setting up conv1_2c
I0627 15:24:52.395892  3328 net.cpp:148] Top shape: 4 64 392 392 (39337984)
I0627 15:24:52.395895  3328 net.cpp:156] Memory required for data: 499187712
I0627 15:24:52.395901  3328 layer_factory.hpp:77] Creating layer relu1_2c
I0627 15:24:52.395905  3328 net.cpp:91] Creating Layer relu1_2c
I0627 15:24:52.395907  3328 net.cpp:425] relu1_2c <- conv1_2c
I0627 15:24:52.395913  3328 net.cpp:386] relu1_2c -> conv1_2c (in-place)
I0627 15:24:52.396097  3328 net.cpp:141] Setting up relu1_2c
I0627 15:24:52.396105  3328 net.cpp:148] Top shape: 4 64 392 392 (39337984)
I0627 15:24:52.396107  3328 net.cpp:156] Memory required for data: 656539648
I0627 15:24:52.396111  3328 layer_factory.hpp:77] Creating layer pool1c
I0627 15:24:52.396118  3328 net.cpp:91] Creating Layer pool1c
I0627 15:24:52.396121  3328 net.cpp:425] pool1c <- conv1_2c
I0627 15:24:52.396124  3328 net.cpp:399] pool1c -> pool1c
I0627 15:24:52.396160  3328 net.cpp:141] Setting up pool1c
I0627 15:24:52.396167  3328 net.cpp:148] Top shape: 4 64 196 196 (9834496)
I0627 15:24:52.396168  3328 net.cpp:156] Memory required for data: 695877632
I0627 15:24:52.396173  3328 layer_factory.hpp:77] Creating layer conv2_1c
I0627 15:24:52.396178  3328 net.cpp:91] Creating Layer conv2_1c
I0627 15:24:52.396180  3328 net.cpp:425] conv2_1c <- pool1c
I0627 15:24:52.396184  3328 net.cpp:399] conv2_1c -> conv2_1c
I0627 15:24:52.396867  3328 net.cpp:141] Setting up conv2_1c
I0627 15:24:52.396878  3328 net.cpp:148] Top shape: 4 128 196 196 (19668992)
I0627 15:24:52.396881  3328 net.cpp:156] Memory required for data: 774553600
I0627 15:24:52.396888  3328 layer_factory.hpp:77] Creating layer relu2_1c
I0627 15:24:52.396891  3328 net.cpp:91] Creating Layer relu2_1c
I0627 15:24:52.396893  3328 net.cpp:425] relu2_1c <- conv2_1c
I0627 15:24:52.396898  3328 net.cpp:386] relu2_1c -> conv2_1c (in-place)
I0627 15:24:52.396998  3328 net.cpp:141] Setting up relu2_1c
I0627 15:24:52.397004  3328 net.cpp:148] Top shape: 4 128 196 196 (19668992)
I0627 15:24:52.397006  3328 net.cpp:156] Memory required for data: 853229568
I0627 15:24:52.397008  3328 layer_factory.hpp:77] Creating layer conv2_2c
I0627 15:24:52.397013  3328 net.cpp:91] Creating Layer conv2_2c
I0627 15:24:52.397016  3328 net.cpp:425] conv2_2c <- conv2_1c
I0627 15:24:52.397019  3328 net.cpp:399] conv2_2c -> conv2_2c
I0627 15:24:52.397953  3328 net.cpp:141] Setting up conv2_2c
I0627 15:24:52.397967  3328 net.cpp:148] Top shape: 4 128 196 196 (19668992)
I0627 15:24:52.397981  3328 net.cpp:156] Memory required for data: 931905536
I0627 15:24:52.397986  3328 layer_factory.hpp:77] Creating layer relu2_2c
I0627 15:24:52.397991  3328 net.cpp:91] Creating Layer relu2_2c
I0627 15:24:52.397994  3328 net.cpp:425] relu2_2c <- conv2_2c
I0627 15:24:52.397997  3328 net.cpp:386] relu2_2c -> conv2_2c (in-place)
I0627 15:24:52.398095  3328 net.cpp:141] Setting up relu2_2c
I0627 15:24:52.398102  3328 net.cpp:148] Top shape: 4 128 196 196 (19668992)
I0627 15:24:52.398103  3328 net.cpp:156] Memory required for data: 1010581504
I0627 15:24:52.398109  3328 layer_factory.hpp:77] Creating layer pool2c
I0627 15:24:52.398115  3328 net.cpp:91] Creating Layer pool2c
I0627 15:24:52.398118  3328 net.cpp:425] pool2c <- conv2_2c
I0627 15:24:52.398121  3328 net.cpp:399] pool2c -> pool2c
I0627 15:24:52.398159  3328 net.cpp:141] Setting up pool2c
I0627 15:24:52.398164  3328 net.cpp:148] Top shape: 4 128 98 98 (4917248)
I0627 15:24:52.398166  3328 net.cpp:156] Memory required for data: 1030250496
I0627 15:24:52.398169  3328 layer_factory.hpp:77] Creating layer conv3_1c
I0627 15:24:52.398175  3328 net.cpp:91] Creating Layer conv3_1c
I0627 15:24:52.398176  3328 net.cpp:425] conv3_1c <- pool2c
I0627 15:24:52.398180  3328 net.cpp:399] conv3_1c -> conv3_1c
I0627 15:24:52.399430  3328 net.cpp:141] Setting up conv3_1c
I0627 15:24:52.399446  3328 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0627 15:24:52.399447  3328 net.cpp:156] Memory required for data: 1069588480
I0627 15:24:52.399457  3328 layer_factory.hpp:77] Creating layer relu3_1c
I0627 15:24:52.399463  3328 net.cpp:91] Creating Layer relu3_1c
I0627 15:24:52.399466  3328 net.cpp:425] relu3_1c <- conv3_1c
I0627 15:24:52.399469  3328 net.cpp:386] relu3_1c -> conv3_1c (in-place)
I0627 15:24:52.399668  3328 net.cpp:141] Setting up relu3_1c
I0627 15:24:52.399677  3328 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0627 15:24:52.399679  3328 net.cpp:156] Memory required for data: 1108926464
I0627 15:24:52.399685  3328 layer_factory.hpp:77] Creating layer conv3_2c
I0627 15:24:52.399694  3328 net.cpp:91] Creating Layer conv3_2c
I0627 15:24:52.399698  3328 net.cpp:425] conv3_2c <- conv3_1c
I0627 15:24:52.399700  3328 net.cpp:399] conv3_2c -> conv3_2c
I0627 15:24:52.401082  3328 net.cpp:141] Setting up conv3_2c
I0627 15:24:52.401099  3328 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0627 15:24:52.401103  3328 net.cpp:156] Memory required for data: 1148264448
I0627 15:24:52.401110  3328 layer_factory.hpp:77] Creating layer relu3_2c
I0627 15:24:52.401116  3328 net.cpp:91] Creating Layer relu3_2c
I0627 15:24:52.401119  3328 net.cpp:425] relu3_2c <- conv3_2c
I0627 15:24:52.401126  3328 net.cpp:386] relu3_2c -> conv3_2c (in-place)
I0627 15:24:52.401233  3328 net.cpp:141] Setting up relu3_2c
I0627 15:24:52.401239  3328 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0627 15:24:52.401242  3328 net.cpp:156] Memory required for data: 1187602432
I0627 15:24:52.401243  3328 layer_factory.hpp:77] Creating layer conv3_3c
I0627 15:24:52.401255  3328 net.cpp:91] Creating Layer conv3_3c
I0627 15:24:52.401257  3328 net.cpp:425] conv3_3c <- conv3_2c
I0627 15:24:52.401262  3328 net.cpp:399] conv3_3c -> conv3_3c
I0627 15:24:52.402606  3328 net.cpp:141] Setting up conv3_3c
I0627 15:24:52.402621  3328 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0627 15:24:52.402624  3328 net.cpp:156] Memory required for data: 1226940416
I0627 15:24:52.402631  3328 layer_factory.hpp:77] Creating layer relu3_3c
I0627 15:24:52.402639  3328 net.cpp:91] Creating Layer relu3_3c
I0627 15:24:52.402642  3328 net.cpp:425] relu3_3c <- conv3_3c
I0627 15:24:52.402645  3328 net.cpp:386] relu3_3c -> conv3_3c (in-place)
I0627 15:24:52.402751  3328 net.cpp:141] Setting up relu3_3c
I0627 15:24:52.402756  3328 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0627 15:24:52.402758  3328 net.cpp:156] Memory required for data: 1266278400
I0627 15:24:52.402761  3328 layer_factory.hpp:77] Creating layer pool3c
I0627 15:24:52.402766  3328 net.cpp:91] Creating Layer pool3c
I0627 15:24:52.402797  3328 net.cpp:425] pool3c <- conv3_3c
I0627 15:24:52.402801  3328 net.cpp:399] pool3c -> pool3c
I0627 15:24:52.402828  3328 net.cpp:141] Setting up pool3c
I0627 15:24:52.402832  3328 net.cpp:148] Top shape: 4 256 49 49 (2458624)
I0627 15:24:52.402834  3328 net.cpp:156] Memory required for data: 1276112896
I0627 15:24:52.402838  3328 layer_factory.hpp:77] Creating layer conv4_1c
I0627 15:24:52.402845  3328 net.cpp:91] Creating Layer conv4_1c
I0627 15:24:52.402848  3328 net.cpp:425] conv4_1c <- pool3c
I0627 15:24:52.402851  3328 net.cpp:399] conv4_1c -> conv4_1c
I0627 15:24:52.405093  3328 net.cpp:141] Setting up conv4_1c
I0627 15:24:52.405128  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.405130  3328 net.cpp:156] Memory required for data: 1295781888
I0627 15:24:52.405138  3328 layer_factory.hpp:77] Creating layer relu4_1c
I0627 15:24:52.405143  3328 net.cpp:91] Creating Layer relu4_1c
I0627 15:24:52.405146  3328 net.cpp:425] relu4_1c <- conv4_1c
I0627 15:24:52.405150  3328 net.cpp:386] relu4_1c -> conv4_1c (in-place)
I0627 15:24:52.405340  3328 net.cpp:141] Setting up relu4_1c
I0627 15:24:52.405347  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.405350  3328 net.cpp:156] Memory required for data: 1315450880
I0627 15:24:52.405354  3328 layer_factory.hpp:77] Creating layer conv4_2c
I0627 15:24:52.405372  3328 net.cpp:91] Creating Layer conv4_2c
I0627 15:24:52.405375  3328 net.cpp:425] conv4_2c <- conv4_1c
I0627 15:24:52.405380  3328 net.cpp:399] conv4_2c -> conv4_2c
I0627 15:24:52.409426  3328 net.cpp:141] Setting up conv4_2c
I0627 15:24:52.409464  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.409467  3328 net.cpp:156] Memory required for data: 1335119872
I0627 15:24:52.409478  3328 layer_factory.hpp:77] Creating layer relu4_2c
I0627 15:24:52.409487  3328 net.cpp:91] Creating Layer relu4_2c
I0627 15:24:52.409490  3328 net.cpp:425] relu4_2c <- conv4_2c
I0627 15:24:52.409494  3328 net.cpp:386] relu4_2c -> conv4_2c (in-place)
I0627 15:24:52.409600  3328 net.cpp:141] Setting up relu4_2c
I0627 15:24:52.409605  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.409607  3328 net.cpp:156] Memory required for data: 1354788864
I0627 15:24:52.409611  3328 layer_factory.hpp:77] Creating layer conv4_3c
I0627 15:24:52.409618  3328 net.cpp:91] Creating Layer conv4_3c
I0627 15:24:52.409621  3328 net.cpp:425] conv4_3c <- conv4_2c
I0627 15:24:52.409624  3328 net.cpp:399] conv4_3c -> conv4_3c
I0627 15:24:52.413496  3328 net.cpp:141] Setting up conv4_3c
I0627 15:24:52.413518  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.413522  3328 net.cpp:156] Memory required for data: 1374457856
I0627 15:24:52.413537  3328 layer_factory.hpp:77] Creating layer relu4_3c
I0627 15:24:52.413555  3328 net.cpp:91] Creating Layer relu4_3c
I0627 15:24:52.413558  3328 net.cpp:425] relu4_3c <- conv4_3c
I0627 15:24:52.413563  3328 net.cpp:386] relu4_3c -> conv4_3c (in-place)
I0627 15:24:52.413667  3328 net.cpp:141] Setting up relu4_3c
I0627 15:24:52.413673  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.413676  3328 net.cpp:156] Memory required for data: 1394126848
I0627 15:24:52.413677  3328 layer_factory.hpp:77] Creating layer conv5_1c
I0627 15:24:52.413683  3328 net.cpp:91] Creating Layer conv5_1c
I0627 15:24:52.413686  3328 net.cpp:425] conv5_1c <- conv4_3c
I0627 15:24:52.413689  3328 net.cpp:399] conv5_1c -> conv5_1c
I0627 15:24:52.417428  3328 net.cpp:141] Setting up conv5_1c
I0627 15:24:52.417446  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.417448  3328 net.cpp:156] Memory required for data: 1413795840
I0627 15:24:52.417455  3328 layer_factory.hpp:77] Creating layer relu5_1c
I0627 15:24:52.417464  3328 net.cpp:91] Creating Layer relu5_1c
I0627 15:24:52.417467  3328 net.cpp:425] relu5_1c <- conv5_1c
I0627 15:24:52.417472  3328 net.cpp:386] relu5_1c -> conv5_1c (in-place)
I0627 15:24:52.417762  3328 net.cpp:141] Setting up relu5_1c
I0627 15:24:52.417768  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.417780  3328 net.cpp:156] Memory required for data: 1433464832
I0627 15:24:52.417785  3328 layer_factory.hpp:77] Creating layer conv5_2c
I0627 15:24:52.417793  3328 net.cpp:91] Creating Layer conv5_2c
I0627 15:24:52.417795  3328 net.cpp:425] conv5_2c <- conv5_1c
I0627 15:24:52.417800  3328 net.cpp:399] conv5_2c -> conv5_2c
I0627 15:24:52.421171  3328 net.cpp:141] Setting up conv5_2c
I0627 15:24:52.421191  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.421195  3328 net.cpp:156] Memory required for data: 1453133824
I0627 15:24:52.421201  3328 layer_factory.hpp:77] Creating layer relu5_2c
I0627 15:24:52.421210  3328 net.cpp:91] Creating Layer relu5_2c
I0627 15:24:52.421212  3328 net.cpp:425] relu5_2c <- conv5_2c
I0627 15:24:52.421216  3328 net.cpp:386] relu5_2c -> conv5_2c (in-place)
I0627 15:24:52.421507  3328 net.cpp:141] Setting up relu5_2c
I0627 15:24:52.421516  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.421519  3328 net.cpp:156] Memory required for data: 1472802816
I0627 15:24:52.421520  3328 layer_factory.hpp:77] Creating layer conv5_3c
I0627 15:24:52.421530  3328 net.cpp:91] Creating Layer conv5_3c
I0627 15:24:52.421532  3328 net.cpp:425] conv5_3c <- conv5_2c
I0627 15:24:52.421537  3328 net.cpp:399] conv5_3c -> conv5_3c
I0627 15:24:52.425736  3328 net.cpp:141] Setting up conv5_3c
I0627 15:24:52.425755  3328 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0627 15:24:52.425758  3328 net.cpp:156] Memory required for data: 1516457984
I0627 15:24:52.425765  3328 layer_factory.hpp:77] Creating layer relu5_3c
I0627 15:24:52.425771  3328 net.cpp:91] Creating Layer relu5_3c
I0627 15:24:52.425775  3328 net.cpp:425] relu5_3c <- conv5_3c
I0627 15:24:52.425779  3328 net.cpp:386] relu5_3c -> conv5_3c (in-place)
I0627 15:24:52.425927  3328 net.cpp:141] Setting up relu5_3c
I0627 15:24:52.425935  3328 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0627 15:24:52.425937  3328 net.cpp:156] Memory required for data: 1560113152
I0627 15:24:52.425941  3328 layer_factory.hpp:77] Creating layer conv1_1m
I0627 15:24:52.425946  3328 net.cpp:91] Creating Layer conv1_1m
I0627 15:24:52.425948  3328 net.cpp:425] conv1_1m <- masked_im
I0627 15:24:52.425953  3328 net.cpp:399] conv1_1m -> conv1_1m
I0627 15:24:52.426954  3328 net.cpp:141] Setting up conv1_1m
I0627 15:24:52.426962  3328 net.cpp:148] Top shape: 4 64 392 392 (39337984)
I0627 15:24:52.426964  3328 net.cpp:156] Memory required for data: 1717465088
I0627 15:24:52.426967  3328 net.cpp:484] Sharing parameters 'conv1_1_w' owned by layer 'conv1_1c', param index 0
I0627 15:24:52.426970  3328 net.cpp:484] Sharing parameters 'conv1_1_b' owned by layer 'conv1_1c', param index 1
I0627 15:24:52.426972  3328 layer_factory.hpp:77] Creating layer relu1_1m
I0627 15:24:52.426985  3328 net.cpp:91] Creating Layer relu1_1m
I0627 15:24:52.426988  3328 net.cpp:425] relu1_1m <- conv1_1m
I0627 15:24:52.426993  3328 net.cpp:386] relu1_1m -> conv1_1m (in-place)
I0627 15:24:52.427106  3328 net.cpp:141] Setting up relu1_1m
I0627 15:24:52.427114  3328 net.cpp:148] Top shape: 4 64 392 392 (39337984)
I0627 15:24:52.427115  3328 net.cpp:156] Memory required for data: 1874817024
I0627 15:24:52.427117  3328 layer_factory.hpp:77] Creating layer conv1_2m
I0627 15:24:52.427124  3328 net.cpp:91] Creating Layer conv1_2m
I0627 15:24:52.427129  3328 net.cpp:425] conv1_2m <- conv1_1m
I0627 15:24:52.427134  3328 net.cpp:399] conv1_2m -> conv1_2m
I0627 15:24:52.428095  3328 net.cpp:141] Setting up conv1_2m
I0627 15:24:52.428104  3328 net.cpp:148] Top shape: 4 64 392 392 (39337984)
I0627 15:24:52.428107  3328 net.cpp:156] Memory required for data: 2032168960
I0627 15:24:52.428109  3328 net.cpp:484] Sharing parameters 'conv1_2_w' owned by layer 'conv1_2c', param index 0
I0627 15:24:52.428112  3328 net.cpp:484] Sharing parameters 'conv1_2_b' owned by layer 'conv1_2c', param index 1
I0627 15:24:52.428114  3328 layer_factory.hpp:77] Creating layer relu1_2m
I0627 15:24:52.428117  3328 net.cpp:91] Creating Layer relu1_2m
I0627 15:24:52.428119  3328 net.cpp:425] relu1_2m <- conv1_2m
I0627 15:24:52.428133  3328 net.cpp:386] relu1_2m -> conv1_2m (in-place)
I0627 15:24:52.428320  3328 net.cpp:141] Setting up relu1_2m
I0627 15:24:52.428328  3328 net.cpp:148] Top shape: 4 64 392 392 (39337984)
I0627 15:24:52.428330  3328 net.cpp:156] Memory required for data: 2189520896
I0627 15:24:52.428334  3328 layer_factory.hpp:77] Creating layer pool1m
I0627 15:24:52.428340  3328 net.cpp:91] Creating Layer pool1m
I0627 15:24:52.428344  3328 net.cpp:425] pool1m <- conv1_2m
I0627 15:24:52.428346  3328 net.cpp:399] pool1m -> pool1m
I0627 15:24:52.428376  3328 net.cpp:141] Setting up pool1m
I0627 15:24:52.428383  3328 net.cpp:148] Top shape: 4 64 196 196 (9834496)
I0627 15:24:52.428385  3328 net.cpp:156] Memory required for data: 2228858880
I0627 15:24:52.428387  3328 layer_factory.hpp:77] Creating layer conv2_1m
I0627 15:24:52.428392  3328 net.cpp:91] Creating Layer conv2_1m
I0627 15:24:52.428395  3328 net.cpp:425] conv2_1m <- pool1m
I0627 15:24:52.428398  3328 net.cpp:399] conv2_1m -> conv2_1m
I0627 15:24:52.429095  3328 net.cpp:141] Setting up conv2_1m
I0627 15:24:52.429103  3328 net.cpp:148] Top shape: 4 128 196 196 (19668992)
I0627 15:24:52.429106  3328 net.cpp:156] Memory required for data: 2307534848
I0627 15:24:52.429110  3328 net.cpp:484] Sharing parameters 'conv2_1_w' owned by layer 'conv2_1c', param index 0
I0627 15:24:52.429112  3328 net.cpp:484] Sharing parameters 'conv2_1_b' owned by layer 'conv2_1c', param index 1
I0627 15:24:52.429114  3328 layer_factory.hpp:77] Creating layer relu2_1m
I0627 15:24:52.429118  3328 net.cpp:91] Creating Layer relu2_1m
I0627 15:24:52.429121  3328 net.cpp:425] relu2_1m <- conv2_1m
I0627 15:24:52.429126  3328 net.cpp:386] relu2_1m -> conv2_1m (in-place)
I0627 15:24:52.429230  3328 net.cpp:141] Setting up relu2_1m
I0627 15:24:52.429237  3328 net.cpp:148] Top shape: 4 128 196 196 (19668992)
I0627 15:24:52.429239  3328 net.cpp:156] Memory required for data: 2386210816
I0627 15:24:52.429244  3328 layer_factory.hpp:77] Creating layer conv2_2m
I0627 15:24:52.429250  3328 net.cpp:91] Creating Layer conv2_2m
I0627 15:24:52.429251  3328 net.cpp:425] conv2_2m <- conv2_1m
I0627 15:24:52.429256  3328 net.cpp:399] conv2_2m -> conv2_2m
I0627 15:24:52.430491  3328 net.cpp:141] Setting up conv2_2m
I0627 15:24:52.430503  3328 net.cpp:148] Top shape: 4 128 196 196 (19668992)
I0627 15:24:52.430506  3328 net.cpp:156] Memory required for data: 2464886784
I0627 15:24:52.430516  3328 net.cpp:484] Sharing parameters 'conv2_2_w' owned by layer 'conv2_2c', param index 0
I0627 15:24:52.430526  3328 net.cpp:484] Sharing parameters 'conv2_2_b' owned by layer 'conv2_2c', param index 1
I0627 15:24:52.430528  3328 layer_factory.hpp:77] Creating layer relu2_2m
I0627 15:24:52.430536  3328 net.cpp:91] Creating Layer relu2_2m
I0627 15:24:52.430541  3328 net.cpp:425] relu2_2m <- conv2_2m
I0627 15:24:52.430544  3328 net.cpp:386] relu2_2m -> conv2_2m (in-place)
I0627 15:24:52.430672  3328 net.cpp:141] Setting up relu2_2m
I0627 15:24:52.430678  3328 net.cpp:148] Top shape: 4 128 196 196 (19668992)
I0627 15:24:52.430680  3328 net.cpp:156] Memory required for data: 2543562752
I0627 15:24:52.430682  3328 layer_factory.hpp:77] Creating layer pool2m
I0627 15:24:52.430688  3328 net.cpp:91] Creating Layer pool2m
I0627 15:24:52.430691  3328 net.cpp:425] pool2m <- conv2_2m
I0627 15:24:52.430696  3328 net.cpp:399] pool2m -> pool2m
I0627 15:24:52.430727  3328 net.cpp:141] Setting up pool2m
I0627 15:24:52.430733  3328 net.cpp:148] Top shape: 4 128 98 98 (4917248)
I0627 15:24:52.430735  3328 net.cpp:156] Memory required for data: 2563231744
I0627 15:24:52.430737  3328 layer_factory.hpp:77] Creating layer conv3_1m
I0627 15:24:52.430745  3328 net.cpp:91] Creating Layer conv3_1m
I0627 15:24:52.430750  3328 net.cpp:425] conv3_1m <- pool2m
I0627 15:24:52.430753  3328 net.cpp:399] conv3_1m -> conv3_1m
I0627 15:24:52.432140  3328 net.cpp:141] Setting up conv3_1m
I0627 15:24:52.432153  3328 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0627 15:24:52.432155  3328 net.cpp:156] Memory required for data: 2602569728
I0627 15:24:52.432160  3328 net.cpp:484] Sharing parameters 'conv3_1_w' owned by layer 'conv3_1c', param index 0
I0627 15:24:52.432174  3328 net.cpp:484] Sharing parameters 'conv3_1_b' owned by layer 'conv3_1c', param index 1
I0627 15:24:52.432176  3328 layer_factory.hpp:77] Creating layer relu3_1m
I0627 15:24:52.432184  3328 net.cpp:91] Creating Layer relu3_1m
I0627 15:24:52.432186  3328 net.cpp:425] relu3_1m <- conv3_1m
I0627 15:24:52.432190  3328 net.cpp:386] relu3_1m -> conv3_1m (in-place)
I0627 15:24:52.432437  3328 net.cpp:141] Setting up relu3_1m
I0627 15:24:52.432446  3328 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0627 15:24:52.432448  3328 net.cpp:156] Memory required for data: 2641907712
I0627 15:24:52.432452  3328 layer_factory.hpp:77] Creating layer conv3_2m
I0627 15:24:52.432458  3328 net.cpp:91] Creating Layer conv3_2m
I0627 15:24:52.432461  3328 net.cpp:425] conv3_2m <- conv3_1m
I0627 15:24:52.432466  3328 net.cpp:399] conv3_2m -> conv3_2m
I0627 15:24:52.433938  3328 net.cpp:141] Setting up conv3_2m
I0627 15:24:52.433954  3328 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0627 15:24:52.433956  3328 net.cpp:156] Memory required for data: 2681245696
I0627 15:24:52.433960  3328 net.cpp:484] Sharing parameters 'conv3_2_w' owned by layer 'conv3_2c', param index 0
I0627 15:24:52.433964  3328 net.cpp:484] Sharing parameters 'conv3_2_b' owned by layer 'conv3_2c', param index 1
I0627 15:24:52.433966  3328 layer_factory.hpp:77] Creating layer relu3_2m
I0627 15:24:52.433974  3328 net.cpp:91] Creating Layer relu3_2m
I0627 15:24:52.433976  3328 net.cpp:425] relu3_2m <- conv3_2m
I0627 15:24:52.433982  3328 net.cpp:386] relu3_2m -> conv3_2m (in-place)
I0627 15:24:52.434092  3328 net.cpp:141] Setting up relu3_2m
I0627 15:24:52.434098  3328 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0627 15:24:52.434100  3328 net.cpp:156] Memory required for data: 2720583680
I0627 15:24:52.434103  3328 layer_factory.hpp:77] Creating layer conv3_3m
I0627 15:24:52.434111  3328 net.cpp:91] Creating Layer conv3_3m
I0627 15:24:52.434113  3328 net.cpp:425] conv3_3m <- conv3_2m
I0627 15:24:52.434118  3328 net.cpp:399] conv3_3m -> conv3_3m
I0627 15:24:52.435454  3328 net.cpp:141] Setting up conv3_3m
I0627 15:24:52.435467  3328 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0627 15:24:52.435469  3328 net.cpp:156] Memory required for data: 2759921664
I0627 15:24:52.435472  3328 net.cpp:484] Sharing parameters 'conv3_3_w' owned by layer 'conv3_3c', param index 0
I0627 15:24:52.435477  3328 net.cpp:484] Sharing parameters 'conv3_3_b' owned by layer 'conv3_3c', param index 1
I0627 15:24:52.435482  3328 layer_factory.hpp:77] Creating layer relu3_3m
I0627 15:24:52.435488  3328 net.cpp:91] Creating Layer relu3_3m
I0627 15:24:52.435492  3328 net.cpp:425] relu3_3m <- conv3_3m
I0627 15:24:52.435494  3328 net.cpp:386] relu3_3m -> conv3_3m (in-place)
I0627 15:24:52.435626  3328 net.cpp:141] Setting up relu3_3m
I0627 15:24:52.435632  3328 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0627 15:24:52.435634  3328 net.cpp:156] Memory required for data: 2799259648
I0627 15:24:52.435636  3328 layer_factory.hpp:77] Creating layer pool3m
I0627 15:24:52.435643  3328 net.cpp:91] Creating Layer pool3m
I0627 15:24:52.435647  3328 net.cpp:425] pool3m <- conv3_3m
I0627 15:24:52.435653  3328 net.cpp:399] pool3m -> pool3m
I0627 15:24:52.435688  3328 net.cpp:141] Setting up pool3m
I0627 15:24:52.435693  3328 net.cpp:148] Top shape: 4 256 49 49 (2458624)
I0627 15:24:52.435695  3328 net.cpp:156] Memory required for data: 2809094144
I0627 15:24:52.435698  3328 layer_factory.hpp:77] Creating layer conv4_1m
I0627 15:24:52.435709  3328 net.cpp:91] Creating Layer conv4_1m
I0627 15:24:52.435713  3328 net.cpp:425] conv4_1m <- pool3m
I0627 15:24:52.435717  3328 net.cpp:399] conv4_1m -> conv4_1m
I0627 15:24:52.438016  3328 net.cpp:141] Setting up conv4_1m
I0627 15:24:52.438035  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.438037  3328 net.cpp:156] Memory required for data: 2828763136
I0627 15:24:52.438041  3328 net.cpp:484] Sharing parameters 'conv4_1_w' owned by layer 'conv4_1c', param index 0
I0627 15:24:52.438055  3328 net.cpp:484] Sharing parameters 'conv4_1_b' owned by layer 'conv4_1c', param index 1
I0627 15:24:52.438056  3328 layer_factory.hpp:77] Creating layer relu4_1m
I0627 15:24:52.438062  3328 net.cpp:91] Creating Layer relu4_1m
I0627 15:24:52.438067  3328 net.cpp:425] relu4_1m <- conv4_1m
I0627 15:24:52.438071  3328 net.cpp:386] relu4_1m -> conv4_1m (in-place)
I0627 15:24:52.438269  3328 net.cpp:141] Setting up relu4_1m
I0627 15:24:52.438277  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.438279  3328 net.cpp:156] Memory required for data: 2848432128
I0627 15:24:52.438285  3328 layer_factory.hpp:77] Creating layer conv4_2m
I0627 15:24:52.438295  3328 net.cpp:91] Creating Layer conv4_2m
I0627 15:24:52.438297  3328 net.cpp:425] conv4_2m <- conv4_1m
I0627 15:24:52.438302  3328 net.cpp:399] conv4_2m -> conv4_2m
I0627 15:24:52.441946  3328 net.cpp:141] Setting up conv4_2m
I0627 15:24:52.441964  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.441967  3328 net.cpp:156] Memory required for data: 2868101120
I0627 15:24:52.441972  3328 net.cpp:484] Sharing parameters 'conv4_2_w' owned by layer 'conv4_2c', param index 0
I0627 15:24:52.441975  3328 net.cpp:484] Sharing parameters 'conv4_2_b' owned by layer 'conv4_2c', param index 1
I0627 15:24:52.441977  3328 layer_factory.hpp:77] Creating layer relu4_2m
I0627 15:24:52.441985  3328 net.cpp:91] Creating Layer relu4_2m
I0627 15:24:52.441989  3328 net.cpp:425] relu4_2m <- conv4_2m
I0627 15:24:52.441997  3328 net.cpp:386] relu4_2m -> conv4_2m (in-place)
I0627 15:24:52.442116  3328 net.cpp:141] Setting up relu4_2m
I0627 15:24:52.442124  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.442126  3328 net.cpp:156] Memory required for data: 2887770112
I0627 15:24:52.442129  3328 layer_factory.hpp:77] Creating layer conv4_3m
I0627 15:24:52.442138  3328 net.cpp:91] Creating Layer conv4_3m
I0627 15:24:52.442142  3328 net.cpp:425] conv4_3m <- conv4_2m
I0627 15:24:52.442145  3328 net.cpp:399] conv4_3m -> conv4_3m
I0627 15:24:52.446332  3328 net.cpp:141] Setting up conv4_3m
I0627 15:24:52.446362  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.446364  3328 net.cpp:156] Memory required for data: 2907439104
I0627 15:24:52.446370  3328 net.cpp:484] Sharing parameters 'conv4_3_w' owned by layer 'conv4_3c', param index 0
I0627 15:24:52.446375  3328 net.cpp:484] Sharing parameters 'conv4_3_b' owned by layer 'conv4_3c', param index 1
I0627 15:24:52.446378  3328 layer_factory.hpp:77] Creating layer relu4_3m
I0627 15:24:52.446389  3328 net.cpp:91] Creating Layer relu4_3m
I0627 15:24:52.446393  3328 net.cpp:425] relu4_3m <- conv4_3m
I0627 15:24:52.446400  3328 net.cpp:386] relu4_3m -> conv4_3m (in-place)
I0627 15:24:52.446702  3328 net.cpp:141] Setting up relu4_3m
I0627 15:24:52.446712  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.446714  3328 net.cpp:156] Memory required for data: 2927108096
I0627 15:24:52.446720  3328 layer_factory.hpp:77] Creating layer conv5_1m
I0627 15:24:52.446729  3328 net.cpp:91] Creating Layer conv5_1m
I0627 15:24:52.446732  3328 net.cpp:425] conv5_1m <- conv4_3m
I0627 15:24:52.446738  3328 net.cpp:399] conv5_1m -> conv5_1m
I0627 15:24:52.450479  3328 net.cpp:141] Setting up conv5_1m
I0627 15:24:52.450531  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.450533  3328 net.cpp:156] Memory required for data: 2946777088
I0627 15:24:52.450541  3328 net.cpp:484] Sharing parameters 'conv5_1_w' owned by layer 'conv5_1c', param index 0
I0627 15:24:52.450544  3328 net.cpp:484] Sharing parameters 'conv5_1_b' owned by layer 'conv5_1c', param index 1
I0627 15:24:52.450546  3328 layer_factory.hpp:77] Creating layer relu5_1m
I0627 15:24:52.450556  3328 net.cpp:91] Creating Layer relu5_1m
I0627 15:24:52.450562  3328 net.cpp:425] relu5_1m <- conv5_1m
I0627 15:24:52.450568  3328 net.cpp:386] relu5_1m -> conv5_1m (in-place)
I0627 15:24:52.450897  3328 net.cpp:141] Setting up relu5_1m
I0627 15:24:52.450906  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.450917  3328 net.cpp:156] Memory required for data: 2966446080
I0627 15:24:52.450918  3328 layer_factory.hpp:77] Creating layer conv5_2m
I0627 15:24:52.450925  3328 net.cpp:91] Creating Layer conv5_2m
I0627 15:24:52.450928  3328 net.cpp:425] conv5_2m <- conv5_1m
I0627 15:24:52.450933  3328 net.cpp:399] conv5_2m -> conv5_2m
I0627 15:24:52.455556  3328 net.cpp:141] Setting up conv5_2m
I0627 15:24:52.455581  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.455585  3328 net.cpp:156] Memory required for data: 2986115072
I0627 15:24:52.455590  3328 net.cpp:484] Sharing parameters 'conv5_2_w' owned by layer 'conv5_2c', param index 0
I0627 15:24:52.455595  3328 net.cpp:484] Sharing parameters 'conv5_2_b' owned by layer 'conv5_2c', param index 1
I0627 15:24:52.455596  3328 layer_factory.hpp:77] Creating layer relu5_2m
I0627 15:24:52.455607  3328 net.cpp:91] Creating Layer relu5_2m
I0627 15:24:52.455611  3328 net.cpp:425] relu5_2m <- conv5_2m
I0627 15:24:52.455616  3328 net.cpp:386] relu5_2m -> conv5_2m (in-place)
I0627 15:24:52.455809  3328 net.cpp:141] Setting up relu5_2m
I0627 15:24:52.455816  3328 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0627 15:24:52.455817  3328 net.cpp:156] Memory required for data: 3005784064
I0627 15:24:52.455822  3328 layer_factory.hpp:77] Creating layer conv5_3m
I0627 15:24:52.455832  3328 net.cpp:91] Creating Layer conv5_3m
I0627 15:24:52.455833  3328 net.cpp:425] conv5_3m <- conv5_2m
I0627 15:24:52.455838  3328 net.cpp:399] conv5_3m -> conv5_3m
I0627 15:24:52.460350  3328 net.cpp:141] Setting up conv5_3m
I0627 15:24:52.460381  3328 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0627 15:24:52.460383  3328 net.cpp:156] Memory required for data: 3049439232
I0627 15:24:52.460389  3328 net.cpp:484] Sharing parameters 'conv5_3_w' owned by layer 'conv5_3c', param index 0
I0627 15:24:52.460393  3328 net.cpp:484] Sharing parameters 'conv5_3_b' owned by layer 'conv5_3c', param index 1
I0627 15:24:52.460396  3328 layer_factory.hpp:77] Creating layer relu5_3m
I0627 15:24:52.460408  3328 net.cpp:91] Creating Layer relu5_3m
I0627 15:24:52.460412  3328 net.cpp:425] relu5_3m <- conv5_3m
I0627 15:24:52.460418  3328 net.cpp:386] relu5_3m -> conv5_3m (in-place)
I0627 15:24:52.460779  3328 net.cpp:141] Setting up relu5_3m
I0627 15:24:52.460788  3328 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0627 15:24:52.460790  3328 net.cpp:156] Memory required for data: 3093094400
I0627 15:24:52.460793  3328 layer_factory.hpp:77] Creating layer conv1_1n
I0627 15:24:52.460803  3328 net.cpp:91] Creating Layer conv1_1n
I0627 15:24:52.460806  3328 net.cpp:425] conv1_1n <- next_im_cur_im_2_split_0
I0627 15:24:52.460813  3328 net.cpp:399] conv1_1n -> conv1_1n
I0627 15:24:52.462046  3328 net.cpp:141] Setting up conv1_1n
I0627 15:24:52.462065  3328 net.cpp:148] Top shape: 4 64 584 584 (87310336)
I0627 15:24:52.462067  3328 net.cpp:156] Memory required for data: 3442335744
I0627 15:24:52.462072  3328 net.cpp:484] Sharing parameters 'conv1_1_w' owned by layer 'conv1_1c', param index 0
I0627 15:24:52.462076  3328 net.cpp:484] Sharing parameters 'conv1_1_b' owned by layer 'conv1_1c', param index 1
I0627 15:24:52.462080  3328 layer_factory.hpp:77] Creating layer relu1_1n
I0627 15:24:52.462086  3328 net.cpp:91] Creating Layer relu1_1n
I0627 15:24:52.462090  3328 net.cpp:425] relu1_1n <- conv1_1n
I0627 15:24:52.462095  3328 net.cpp:386] relu1_1n -> conv1_1n (in-place)
I0627 15:24:52.462227  3328 net.cpp:141] Setting up relu1_1n
I0627 15:24:52.462234  3328 net.cpp:148] Top shape: 4 64 584 584 (87310336)
I0627 15:24:52.462237  3328 net.cpp:156] Memory required for data: 3791577088
I0627 15:24:52.462241  3328 layer_factory.hpp:77] Creating layer conv1_2n
I0627 15:24:52.462249  3328 net.cpp:91] Creating Layer conv1_2n
I0627 15:24:52.462252  3328 net.cpp:425] conv1_2n <- conv1_1n
I0627 15:24:52.462256  3328 net.cpp:399] conv1_2n -> conv1_2n
I0627 15:24:52.463939  3328 net.cpp:141] Setting up conv1_2n
I0627 15:24:52.463955  3328 net.cpp:148] Top shape: 4 64 584 584 (87310336)
I0627 15:24:52.463958  3328 net.cpp:156] Memory required for data: 4140818432
I0627 15:24:52.463974  3328 net.cpp:484] Sharing parameters 'conv1_2_w' owned by layer 'conv1_2c', param index 0
I0627 15:24:52.463979  3328 net.cpp:484] Sharing parameters 'conv1_2_b' owned by layer 'conv1_2c', param index 1
I0627 15:24:52.463980  3328 layer_factory.hpp:77] Creating layer relu1_2n
I0627 15:24:52.463986  3328 net.cpp:91] Creating Layer relu1_2n
I0627 15:24:52.463989  3328 net.cpp:425] relu1_2n <- conv1_2n
I0627 15:24:52.463992  3328 net.cpp:386] relu1_2n -> conv1_2n (in-place)
I0627 15:24:52.464244  3328 net.cpp:141] Setting up relu1_2n
I0627 15:24:52.464254  3328 net.cpp:148] Top shape: 4 64 584 584 (87310336)
I0627 15:24:52.464257  3328 net.cpp:156] Memory required for data: 4490059776
I0627 15:24:52.464259  3328 layer_factory.hpp:77] Creating layer pool1n
I0627 15:24:52.464275  3328 net.cpp:91] Creating Layer pool1n
I0627 15:24:52.464278  3328 net.cpp:425] pool1n <- conv1_2n
I0627 15:24:52.464283  3328 net.cpp:399] pool1n -> pool1n
I0627 15:24:52.464323  3328 net.cpp:141] Setting up pool1n
I0627 15:24:52.464329  3328 net.cpp:148] Top shape: 4 64 292 292 (21827584)
I0627 15:24:52.464330  3328 net.cpp:156] Memory required for data: 4577370112
I0627 15:24:52.464334  3328 layer_factory.hpp:77] Creating layer conv2_1n
I0627 15:24:52.464344  3328 net.cpp:91] Creating Layer conv2_1n
I0627 15:24:52.464345  3328 net.cpp:425] conv2_1n <- pool1n
I0627 15:24:52.464349  3328 net.cpp:399] conv2_1n -> conv2_1n
I0627 15:24:52.465112  3328 net.cpp:141] Setting up conv2_1n
I0627 15:24:52.465121  3328 net.cpp:148] Top shape: 4 128 292 292 (43655168)
I0627 15:24:52.465123  3328 net.cpp:156] Memory required for data: 4751990784
I0627 15:24:52.465126  3328 net.cpp:484] Sharing parameters 'conv2_1_w' owned by layer 'conv2_1c', param index 0
I0627 15:24:52.465129  3328 net.cpp:484] Sharing parameters 'conv2_1_b' owned by layer 'conv2_1c', param index 1
I0627 15:24:52.465133  3328 layer_factory.hpp:77] Creating layer relu2_1n
I0627 15:24:52.465137  3328 net.cpp:91] Creating Layer relu2_1n
I0627 15:24:52.465139  3328 net.cpp:425] relu2_1n <- conv2_1n
I0627 15:24:52.465143  3328 net.cpp:386] relu2_1n -> conv2_1n (in-place)
I0627 15:24:52.465350  3328 net.cpp:141] Setting up relu2_1n
I0627 15:24:52.465358  3328 net.cpp:148] Top shape: 4 128 292 292 (43655168)
I0627 15:24:52.465359  3328 net.cpp:156] Memory required for data: 4926611456
I0627 15:24:52.465363  3328 layer_factory.hpp:77] Creating layer conv2_2n
I0627 15:24:52.465369  3328 net.cpp:91] Creating Layer conv2_2n
I0627 15:24:52.465373  3328 net.cpp:425] conv2_2n <- conv2_1n
I0627 15:24:52.465378  3328 net.cpp:399] conv2_2n -> conv2_2n
I0627 15:24:52.466459  3328 net.cpp:141] Setting up conv2_2n
I0627 15:24:52.466485  3328 net.cpp:148] Top shape: 4 128 292 292 (43655168)
I0627 15:24:52.466487  3328 net.cpp:156] Memory required for data: 5101232128
I0627 15:24:52.466491  3328 net.cpp:484] Sharing parameters 'conv2_2_w' owned by layer 'conv2_2c', param index 0
I0627 15:24:52.466495  3328 net.cpp:484] Sharing parameters 'conv2_2_b' owned by layer 'conv2_2c', param index 1
I0627 15:24:52.466496  3328 layer_factory.hpp:77] Creating layer relu2_2n
I0627 15:24:52.466500  3328 net.cpp:91] Creating Layer relu2_2n
I0627 15:24:52.466503  3328 net.cpp:425] relu2_2n <- conv2_2n
I0627 15:24:52.466506  3328 net.cpp:386] relu2_2n -> conv2_2n (in-place)
I0627 15:24:52.466617  3328 net.cpp:141] Setting up relu2_2n
I0627 15:24:52.466624  3328 net.cpp:148] Top shape: 4 128 292 292 (43655168)
I0627 15:24:52.466625  3328 net.cpp:156] Memory required for data: 5275852800
I0627 15:24:52.466627  3328 layer_factory.hpp:77] Creating layer pool2n
I0627 15:24:52.466632  3328 net.cpp:91] Creating Layer pool2n
I0627 15:24:52.466634  3328 net.cpp:425] pool2n <- conv2_2n
I0627 15:24:52.466639  3328 net.cpp:399] pool2n -> pool2n
I0627 15:24:52.466671  3328 net.cpp:141] Setting up pool2n
I0627 15:24:52.466675  3328 net.cpp:148] Top shape: 4 128 146 146 (10913792)
I0627 15:24:52.466676  3328 net.cpp:156] Memory required for data: 5319507968
I0627 15:24:52.466681  3328 layer_factory.hpp:77] Creating layer conv3_1n
I0627 15:24:52.466701  3328 net.cpp:91] Creating Layer conv3_1n
I0627 15:24:52.466704  3328 net.cpp:425] conv3_1n <- pool2n
I0627 15:24:52.466711  3328 net.cpp:399] conv3_1n -> conv3_1n
I0627 15:24:52.468133  3328 net.cpp:141] Setting up conv3_1n
I0627 15:24:52.468147  3328 net.cpp:148] Top shape: 4 256 146 146 (21827584)
I0627 15:24:52.468150  3328 net.cpp:156] Memory required for data: 5406818304
I0627 15:24:52.468154  3328 net.cpp:484] Sharing parameters 'conv3_1_w' owned by layer 'conv3_1c', param index 0
I0627 15:24:52.468158  3328 net.cpp:484] Sharing parameters 'conv3_1_b' owned by layer 'conv3_1c', param index 1
I0627 15:24:52.468161  3328 layer_factory.hpp:77] Creating layer relu3_1n
I0627 15:24:52.468166  3328 net.cpp:91] Creating Layer relu3_1n
I0627 15:24:52.468168  3328 net.cpp:425] relu3_1n <- conv3_1n
I0627 15:24:52.468173  3328 net.cpp:386] relu3_1n -> conv3_1n (in-place)
I0627 15:24:52.468413  3328 net.cpp:141] Setting up relu3_1n
I0627 15:24:52.468420  3328 net.cpp:148] Top shape: 4 256 146 146 (21827584)
I0627 15:24:52.468423  3328 net.cpp:156] Memory required for data: 5494128640
I0627 15:24:52.468425  3328 layer_factory.hpp:77] Creating layer conv3_2n
I0627 15:24:52.468431  3328 net.cpp:91] Creating Layer conv3_2n
I0627 15:24:52.468433  3328 net.cpp:425] conv3_2n <- conv3_1n
I0627 15:24:52.468446  3328 net.cpp:399] conv3_2n -> conv3_2n
I0627 15:24:52.469703  3328 net.cpp:141] Setting up conv3_2n
I0627 15:24:52.469727  3328 net.cpp:148] Top shape: 4 256 146 146 (21827584)
I0627 15:24:52.469730  3328 net.cpp:156] Memory required for data: 5581438976
I0627 15:24:52.469738  3328 net.cpp:484] Sharing parameters 'conv3_2_w' owned by layer 'conv3_2c', param index 0
I0627 15:24:52.469741  3328 net.cpp:484] Sharing parameters 'conv3_2_b' owned by layer 'conv3_2c', param index 1
I0627 15:24:52.469743  3328 layer_factory.hpp:77] Creating layer relu3_2n
I0627 15:24:52.469776  3328 net.cpp:91] Creating Layer relu3_2n
I0627 15:24:52.469779  3328 net.cpp:425] relu3_2n <- conv3_2n
I0627 15:24:52.469784  3328 net.cpp:386] relu3_2n -> conv3_2n (in-place)
I0627 15:24:52.470005  3328 net.cpp:141] Setting up relu3_2n
I0627 15:24:52.470031  3328 net.cpp:148] Top shape: 4 256 146 146 (21827584)
I0627 15:24:52.470033  3328 net.cpp:156] Memory required for data: 5668749312
I0627 15:24:52.470041  3328 layer_factory.hpp:77] Creating layer conv3_3n
I0627 15:24:52.470051  3328 net.cpp:91] Creating Layer conv3_3n
I0627 15:24:52.470053  3328 net.cpp:425] conv3_3n <- conv3_2n
I0627 15:24:52.470057  3328 net.cpp:399] conv3_3n -> conv3_3n
I0627 15:24:52.471796  3328 net.cpp:141] Setting up conv3_3n
I0627 15:24:52.471817  3328 net.cpp:148] Top shape: 4 256 146 146 (21827584)
I0627 15:24:52.471819  3328 net.cpp:156] Memory required for data: 5756059648
I0627 15:24:52.471853  3328 net.cpp:484] Sharing parameters 'conv3_3_w' owned by layer 'conv3_3c', param index 0
I0627 15:24:52.471858  3328 net.cpp:484] Sharing parameters 'conv3_3_b' owned by layer 'conv3_3c', param index 1
I0627 15:24:52.471860  3328 layer_factory.hpp:77] Creating layer relu3_3n
I0627 15:24:52.471868  3328 net.cpp:91] Creating Layer relu3_3n
I0627 15:24:52.471871  3328 net.cpp:425] relu3_3n <- conv3_3n
I0627 15:24:52.471878  3328 net.cpp:386] relu3_3n -> conv3_3n (in-place)
I0627 15:24:52.472003  3328 net.cpp:141] Setting up relu3_3n
I0627 15:24:52.472009  3328 net.cpp:148] Top shape: 4 256 146 146 (21827584)
I0627 15:24:52.472012  3328 net.cpp:156] Memory required for data: 5843369984
I0627 15:24:52.472014  3328 layer_factory.hpp:77] Creating layer pool3n
I0627 15:24:52.472023  3328 net.cpp:91] Creating Layer pool3n
I0627 15:24:52.472024  3328 net.cpp:425] pool3n <- conv3_3n
I0627 15:24:52.472028  3328 net.cpp:399] pool3n -> pool3n
I0627 15:24:52.472072  3328 net.cpp:141] Setting up pool3n
I0627 15:24:52.472077  3328 net.cpp:148] Top shape: 4 256 73 73 (5456896)
I0627 15:24:52.472079  3328 net.cpp:156] Memory required for data: 5865197568
I0627 15:24:52.472084  3328 layer_factory.hpp:77] Creating layer conv4_1n
I0627 15:24:52.472113  3328 net.cpp:91] Creating Layer conv4_1n
I0627 15:24:52.472116  3328 net.cpp:425] conv4_1n <- pool3n
I0627 15:24:52.472120  3328 net.cpp:399] conv4_1n -> conv4_1n
I0627 15:24:52.474674  3328 net.cpp:141] Setting up conv4_1n
I0627 15:24:52.474700  3328 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0627 15:24:52.474704  3328 net.cpp:156] Memory required for data: 5908852736
I0627 15:24:52.474709  3328 net.cpp:484] Sharing parameters 'conv4_1_w' owned by layer 'conv4_1c', param index 0
I0627 15:24:52.474714  3328 net.cpp:484] Sharing parameters 'conv4_1_b' owned by layer 'conv4_1c', param index 1
I0627 15:24:52.474717  3328 layer_factory.hpp:77] Creating layer relu4_1n
I0627 15:24:52.474726  3328 net.cpp:91] Creating Layer relu4_1n
I0627 15:24:52.474730  3328 net.cpp:425] relu4_1n <- conv4_1n
I0627 15:24:52.474735  3328 net.cpp:386] relu4_1n -> conv4_1n (in-place)
I0627 15:24:52.474947  3328 net.cpp:141] Setting up relu4_1n
I0627 15:24:52.474954  3328 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0627 15:24:52.474957  3328 net.cpp:156] Memory required for data: 5952507904
I0627 15:24:52.474959  3328 layer_factory.hpp:77] Creating layer conv4_2n
I0627 15:24:52.474967  3328 net.cpp:91] Creating Layer conv4_2n
I0627 15:24:52.474970  3328 net.cpp:425] conv4_2n <- conv4_1n
I0627 15:24:52.474977  3328 net.cpp:399] conv4_2n -> conv4_2n
I0627 15:24:52.479462  3328 net.cpp:141] Setting up conv4_2n
I0627 15:24:52.479506  3328 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0627 15:24:52.479516  3328 net.cpp:156] Memory required for data: 5996163072
I0627 15:24:52.479522  3328 net.cpp:484] Sharing parameters 'conv4_2_w' owned by layer 'conv4_2c', param index 0
I0627 15:24:52.479526  3328 net.cpp:484] Sharing parameters 'conv4_2_b' owned by layer 'conv4_2c', param index 1
I0627 15:24:52.479529  3328 layer_factory.hpp:77] Creating layer relu4_2n
I0627 15:24:52.479542  3328 net.cpp:91] Creating Layer relu4_2n
I0627 15:24:52.479545  3328 net.cpp:425] relu4_2n <- conv4_2n
I0627 15:24:52.479552  3328 net.cpp:386] relu4_2n -> conv4_2n (in-place)
I0627 15:24:52.479781  3328 net.cpp:141] Setting up relu4_2n
I0627 15:24:52.479790  3328 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0627 15:24:52.479792  3328 net.cpp:156] Memory required for data: 6039818240
I0627 15:24:52.479799  3328 layer_factory.hpp:77] Creating layer conv4_3n
I0627 15:24:52.479807  3328 net.cpp:91] Creating Layer conv4_3n
I0627 15:24:52.479811  3328 net.cpp:425] conv4_3n <- conv4_2n
I0627 15:24:52.479815  3328 net.cpp:399] conv4_3n -> conv4_3n
I0627 15:24:52.484633  3328 net.cpp:141] Setting up conv4_3n
I0627 15:24:52.484658  3328 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0627 15:24:52.484661  3328 net.cpp:156] Memory required for data: 6083473408
I0627 15:24:52.484668  3328 net.cpp:484] Sharing parameters 'conv4_3_w' owned by layer 'conv4_3c', param index 0
I0627 15:24:52.484673  3328 net.cpp:484] Sharing parameters 'conv4_3_b' owned by layer 'conv4_3c', param index 1
I0627 15:24:52.484675  3328 layer_factory.hpp:77] Creating layer relu4_3n
I0627 15:24:52.484697  3328 net.cpp:91] Creating Layer relu4_3n
I0627 15:24:52.484701  3328 net.cpp:425] relu4_3n <- conv4_3n
I0627 15:24:52.484706  3328 net.cpp:386] relu4_3n -> conv4_3n (in-place)
I0627 15:24:52.484827  3328 net.cpp:141] Setting up relu4_3n
I0627 15:24:52.484834  3328 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0627 15:24:52.484836  3328 net.cpp:156] Memory required for data: 6127128576
I0627 15:24:52.484838  3328 layer_factory.hpp:77] Creating layer conv5_1n
I0627 15:24:52.484849  3328 net.cpp:91] Creating Layer conv5_1n
I0627 15:24:52.484853  3328 net.cpp:425] conv5_1n <- conv4_3n
I0627 15:24:52.484861  3328 net.cpp:399] conv5_1n -> conv5_1n
I0627 15:24:52.488761  3328 net.cpp:141] Setting up conv5_1n
I0627 15:24:52.488781  3328 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0627 15:24:52.488785  3328 net.cpp:156] Memory required for data: 6170783744
I0627 15:24:52.488790  3328 net.cpp:484] Sharing parameters 'conv5_1_w' owned by layer 'conv5_1c', param index 0
I0627 15:24:52.488795  3328 net.cpp:484] Sharing parameters 'conv5_1_b' owned by layer 'conv5_1c', param index 1
I0627 15:24:52.488812  3328 layer_factory.hpp:77] Creating layer relu5_1n
I0627 15:24:52.488821  3328 net.cpp:91] Creating Layer relu5_1n
I0627 15:24:52.488826  3328 net.cpp:425] relu5_1n <- conv5_1n
I0627 15:24:52.488832  3328 net.cpp:386] relu5_1n -> conv5_1n (in-place)
I0627 15:24:52.489142  3328 net.cpp:141] Setting up relu5_1n
I0627 15:24:52.489151  3328 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0627 15:24:52.489152  3328 net.cpp:156] Memory required for data: 6214438912
I0627 15:24:52.489156  3328 layer_factory.hpp:77] Creating layer conv5_2n
I0627 15:24:52.489163  3328 net.cpp:91] Creating Layer conv5_2n
I0627 15:24:52.489166  3328 net.cpp:425] conv5_2n <- conv5_1n
I0627 15:24:52.489171  3328 net.cpp:399] conv5_2n -> conv5_2n
I0627 15:24:52.492424  3328 net.cpp:141] Setting up conv5_2n
I0627 15:24:52.492454  3328 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0627 15:24:52.492456  3328 net.cpp:156] Memory required for data: 6258094080
I0627 15:24:52.492462  3328 net.cpp:484] Sharing parameters 'conv5_2_w' owned by layer 'conv5_2c', param index 0
I0627 15:24:52.492465  3328 net.cpp:484] Sharing parameters 'conv5_2_b' owned by layer 'conv5_2c', param index 1
I0627 15:24:52.492467  3328 layer_factory.hpp:77] Creating layer relu5_2n
I0627 15:24:52.492480  3328 net.cpp:91] Creating Layer relu5_2n
I0627 15:24:52.492486  3328 net.cpp:425] relu5_2n <- conv5_2n
I0627 15:24:52.492491  3328 net.cpp:386] relu5_2n -> conv5_2n (in-place)
I0627 15:24:52.492698  3328 net.cpp:141] Setting up relu5_2n
I0627 15:24:52.492705  3328 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0627 15:24:52.492707  3328 net.cpp:156] Memory required for data: 6301749248
I0627 15:24:52.492710  3328 layer_factory.hpp:77] Creating layer conv5_3n
I0627 15:24:52.492718  3328 net.cpp:91] Creating Layer conv5_3n
I0627 15:24:52.492720  3328 net.cpp:425] conv5_3n <- conv5_2n
I0627 15:24:52.492725  3328 net.cpp:399] conv5_3n -> conv5_3n
I0627 15:24:52.497097  3328 net.cpp:141] Setting up conv5_3n
I0627 15:24:52.497122  3328 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0627 15:24:52.497124  3328 net.cpp:156] Memory required for data: 6345404416
I0627 15:24:52.497130  3328 net.cpp:484] Sharing parameters 'conv5_3_w' owned by layer 'conv5_3c', param index 0
I0627 15:24:52.497133  3328 net.cpp:484] Sharing parameters 'conv5_3_b' owned by layer 'conv5_3c', param index 1
I0627 15:24:52.497136  3328 layer_factory.hpp:77] Creating layer relu5_3n
I0627 15:24:52.497144  3328 net.cpp:91] Creating Layer relu5_3n
I0627 15:24:52.497149  3328 net.cpp:425] relu5_3n <- conv5_3n
I0627 15:24:52.497154  3328 net.cpp:386] relu5_3n -> conv5_3n (in-place)
I0627 15:24:52.497509  3328 net.cpp:141] Setting up relu5_3n
I0627 15:24:52.497517  3328 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0627 15:24:52.497519  3328 net.cpp:156] Memory required for data: 6389059584
I0627 15:24:52.497524  3328 layer_factory.hpp:77] Creating layer concat1
I0627 15:24:52.497530  3328 net.cpp:91] Creating Layer concat1
I0627 15:24:52.497534  3328 net.cpp:425] concat1 <- conv5_3c
I0627 15:24:52.497536  3328 net.cpp:425] concat1 <- conv5_3m
I0627 15:24:52.497539  3328 net.cpp:425] concat1 <- conv5_3n
I0627 15:24:52.497542  3328 net.cpp:399] concat1 -> concat1
I0627 15:24:52.497578  3328 net.cpp:141] Setting up concat1
I0627 15:24:52.497583  3328 net.cpp:148] Top shape: 4 1536 73 73 (32741376)
I0627 15:24:52.497586  3328 net.cpp:156] Memory required for data: 6520025088
I0627 15:24:52.497587  3328 layer_factory.hpp:77] Creating layer fc6
I0627 15:24:52.497594  3328 net.cpp:91] Creating Layer fc6
I0627 15:24:52.497596  3328 net.cpp:425] fc6 <- concat1
I0627 15:24:52.497599  3328 net.cpp:399] fc6 -> fc6
I0627 15:24:52.621073  3328 net.cpp:141] Setting up fc6
I0627 15:24:52.621100  3328 net.cpp:148] Top shape: 4 1024 49 49 (9834496)
I0627 15:24:52.621104  3328 net.cpp:156] Memory required for data: 6559363072
I0627 15:24:52.621109  3328 layer_factory.hpp:77] Creating layer relu6
I0627 15:24:52.621116  3328 net.cpp:91] Creating Layer relu6
I0627 15:24:52.621134  3328 net.cpp:425] relu6 <- fc6
I0627 15:24:52.621139  3328 net.cpp:386] relu6 -> fc6 (in-place)
I0627 15:24:52.621321  3328 net.cpp:141] Setting up relu6
I0627 15:24:52.621328  3328 net.cpp:148] Top shape: 4 1024 49 49 (9834496)
I0627 15:24:52.621330  3328 net.cpp:156] Memory required for data: 6598701056
I0627 15:24:52.621332  3328 layer_factory.hpp:77] Creating layer drop6
I0627 15:24:52.621340  3328 net.cpp:91] Creating Layer drop6
I0627 15:24:52.621343  3328 net.cpp:425] drop6 <- fc6
I0627 15:24:52.621345  3328 net.cpp:386] drop6 -> fc6 (in-place)
I0627 15:24:52.621373  3328 net.cpp:141] Setting up drop6
I0627 15:24:52.621376  3328 net.cpp:148] Top shape: 4 1024 49 49 (9834496)
I0627 15:24:52.621378  3328 net.cpp:156] Memory required for data: 6638039040
I0627 15:24:52.621382  3328 layer_factory.hpp:77] Creating layer fc7
I0627 15:24:52.621388  3328 net.cpp:91] Creating Layer fc7
I0627 15:24:52.621394  3328 net.cpp:425] fc7 <- fc6
I0627 15:24:52.621398  3328 net.cpp:399] fc7 -> fc7
I0627 15:24:52.623422  3328 net.cpp:141] Setting up fc7
I0627 15:24:52.623438  3328 net.cpp:148] Top shape: 4 1024 49 49 (9834496)
I0627 15:24:52.623441  3328 net.cpp:156] Memory required for data: 6677377024
I0627 15:24:52.623446  3328 layer_factory.hpp:77] Creating layer relu7
I0627 15:24:52.623455  3328 net.cpp:91] Creating Layer relu7
I0627 15:24:52.623456  3328 net.cpp:425] relu7 <- fc7
I0627 15:24:52.623461  3328 net.cpp:386] relu7 -> fc7 (in-place)
I0627 15:24:52.623667  3328 net.cpp:141] Setting up relu7
I0627 15:24:52.623673  3328 net.cpp:148] Top shape: 4 1024 49 49 (9834496)
I0627 15:24:52.623675  3328 net.cpp:156] Memory required for data: 6716715008
I0627 15:24:52.623677  3328 layer_factory.hpp:77] Creating layer drop7
I0627 15:24:52.623683  3328 net.cpp:91] Creating Layer drop7
I0627 15:24:52.623685  3328 net.cpp:425] drop7 <- fc7
I0627 15:24:52.623688  3328 net.cpp:386] drop7 -> fc7 (in-place)
I0627 15:24:52.623709  3328 net.cpp:141] Setting up drop7
I0627 15:24:52.623713  3328 net.cpp:148] Top shape: 4 1024 49 49 (9834496)
I0627 15:24:52.623714  3328 net.cpp:156] Memory required for data: 6756052992
I0627 15:24:52.623716  3328 layer_factory.hpp:77] Creating layer fc8
I0627 15:24:52.623723  3328 net.cpp:91] Creating Layer fc8
I0627 15:24:52.623725  3328 net.cpp:425] fc8 <- fc7
I0627 15:24:52.623729  3328 net.cpp:399] fc8 -> fc8
I0627 15:24:52.624477  3328 net.cpp:141] Setting up fc8
I0627 15:24:52.624486  3328 net.cpp:148] Top shape: 4 2 49 49 (19208)
I0627 15:24:52.624490  3328 net.cpp:156] Memory required for data: 6756129824
I0627 15:24:52.624493  3328 layer_factory.hpp:77] Creating layer upscore
I0627 15:24:52.624512  3328 net.cpp:91] Creating Layer upscore
I0627 15:24:52.624514  3328 net.cpp:425] upscore <- fc8
I0627 15:24:52.624522  3328 net.cpp:399] upscore -> upscore
I0627 15:24:52.624704  3328 net.cpp:141] Setting up upscore
I0627 15:24:52.624709  3328 net.cpp:148] Top shape: 4 2 400 400 (1280000)
I0627 15:24:52.624712  3328 net.cpp:156] Memory required for data: 6761249824
I0627 15:24:52.624717  3328 layer_factory.hpp:77] Creating layer score
I0627 15:24:52.624727  3328 net.cpp:91] Creating Layer score
I0627 15:24:52.624730  3328 net.cpp:425] score <- upscore
I0627 15:24:52.624733  3328 net.cpp:425] score <- next_im_cur_im_2_split_1
I0627 15:24:52.624737  3328 net.cpp:399] score -> score
I0627 15:24:52.624763  3328 net.cpp:141] Setting up score
I0627 15:24:52.624768  3328 net.cpp:148] Top shape: 4 2 384 384 (1179648)
I0627 15:24:52.624769  3328 net.cpp:156] Memory required for data: 6765968416
I0627 15:24:52.624771  3328 layer_factory.hpp:77] Creating layer loss
I0627 15:24:52.624788  3328 net.cpp:91] Creating Layer loss
I0627 15:24:52.624791  3328 net.cpp:425] loss <- score
I0627 15:24:52.624794  3328 net.cpp:425] loss <- label
I0627 15:24:52.624799  3328 net.cpp:399] loss -> loss
I0627 15:24:52.624809  3328 layer_factory.hpp:77] Creating layer loss
I0627 15:24:52.626479  3328 net.cpp:141] Setting up loss
I0627 15:24:52.626507  3328 net.cpp:148] Top shape: (1)
I0627 15:24:52.626528  3328 net.cpp:151]     with loss weight 1
I0627 15:24:52.626579  3328 net.cpp:156] Memory required for data: 6765968420
I0627 15:24:52.626582  3328 net.cpp:217] loss needs backward computation.
I0627 15:24:52.626585  3328 net.cpp:217] score needs backward computation.
I0627 15:24:52.626588  3328 net.cpp:217] upscore needs backward computation.
I0627 15:24:52.626590  3328 net.cpp:217] fc8 needs backward computation.
I0627 15:24:52.626593  3328 net.cpp:217] drop7 needs backward computation.
I0627 15:24:52.626595  3328 net.cpp:217] relu7 needs backward computation.
I0627 15:24:52.626597  3328 net.cpp:217] fc7 needs backward computation.
I0627 15:24:52.626600  3328 net.cpp:217] drop6 needs backward computation.
I0627 15:24:52.626601  3328 net.cpp:217] relu6 needs backward computation.
I0627 15:24:52.626603  3328 net.cpp:217] fc6 needs backward computation.
I0627 15:24:52.626605  3328 net.cpp:217] concat1 needs backward computation.
I0627 15:24:52.626610  3328 net.cpp:217] relu5_3n needs backward computation.
I0627 15:24:52.626611  3328 net.cpp:217] conv5_3n needs backward computation.
I0627 15:24:52.626613  3328 net.cpp:217] relu5_2n needs backward computation.
I0627 15:24:52.626616  3328 net.cpp:217] conv5_2n needs backward computation.
I0627 15:24:52.626617  3328 net.cpp:217] relu5_1n needs backward computation.
I0627 15:24:52.626619  3328 net.cpp:217] conv5_1n needs backward computation.
I0627 15:24:52.626621  3328 net.cpp:217] relu4_3n needs backward computation.
I0627 15:24:52.626623  3328 net.cpp:217] conv4_3n needs backward computation.
I0627 15:24:52.626626  3328 net.cpp:217] relu4_2n needs backward computation.
I0627 15:24:52.626627  3328 net.cpp:217] conv4_2n needs backward computation.
I0627 15:24:52.626629  3328 net.cpp:217] relu4_1n needs backward computation.
I0627 15:24:52.626631  3328 net.cpp:217] conv4_1n needs backward computation.
I0627 15:24:52.626633  3328 net.cpp:217] pool3n needs backward computation.
I0627 15:24:52.626636  3328 net.cpp:217] relu3_3n needs backward computation.
I0627 15:24:52.626638  3328 net.cpp:217] conv3_3n needs backward computation.
I0627 15:24:52.626641  3328 net.cpp:217] relu3_2n needs backward computation.
I0627 15:24:52.626642  3328 net.cpp:217] conv3_2n needs backward computation.
I0627 15:24:52.626644  3328 net.cpp:217] relu3_1n needs backward computation.
I0627 15:24:52.626646  3328 net.cpp:217] conv3_1n needs backward computation.
I0627 15:24:52.626649  3328 net.cpp:217] pool2n needs backward computation.
I0627 15:24:52.626657  3328 net.cpp:217] relu2_2n needs backward computation.
I0627 15:24:52.626659  3328 net.cpp:217] conv2_2n needs backward computation.
I0627 15:24:52.626662  3328 net.cpp:217] relu2_1n needs backward computation.
I0627 15:24:52.626663  3328 net.cpp:217] conv2_1n needs backward computation.
I0627 15:24:52.626665  3328 net.cpp:217] pool1n needs backward computation.
I0627 15:24:52.626668  3328 net.cpp:217] relu1_2n needs backward computation.
I0627 15:24:52.626670  3328 net.cpp:217] conv1_2n needs backward computation.
I0627 15:24:52.626672  3328 net.cpp:217] relu1_1n needs backward computation.
I0627 15:24:52.626674  3328 net.cpp:217] conv1_1n needs backward computation.
I0627 15:24:52.626677  3328 net.cpp:217] relu5_3m needs backward computation.
I0627 15:24:52.626679  3328 net.cpp:217] conv5_3m needs backward computation.
I0627 15:24:52.626682  3328 net.cpp:217] relu5_2m needs backward computation.
I0627 15:24:52.626683  3328 net.cpp:217] conv5_2m needs backward computation.
I0627 15:24:52.626685  3328 net.cpp:217] relu5_1m needs backward computation.
I0627 15:24:52.626688  3328 net.cpp:217] conv5_1m needs backward computation.
I0627 15:24:52.626689  3328 net.cpp:217] relu4_3m needs backward computation.
I0627 15:24:52.626691  3328 net.cpp:217] conv4_3m needs backward computation.
I0627 15:24:52.626694  3328 net.cpp:217] relu4_2m needs backward computation.
I0627 15:24:52.626696  3328 net.cpp:217] conv4_2m needs backward computation.
I0627 15:24:52.626698  3328 net.cpp:217] relu4_1m needs backward computation.
I0627 15:24:52.626700  3328 net.cpp:217] conv4_1m needs backward computation.
I0627 15:24:52.626708  3328 net.cpp:217] pool3m needs backward computation.
I0627 15:24:52.626711  3328 net.cpp:217] relu3_3m needs backward computation.
I0627 15:24:52.626713  3328 net.cpp:217] conv3_3m needs backward computation.
I0627 15:24:52.626715  3328 net.cpp:217] relu3_2m needs backward computation.
I0627 15:24:52.626718  3328 net.cpp:217] conv3_2m needs backward computation.
I0627 15:24:52.626720  3328 net.cpp:217] relu3_1m needs backward computation.
I0627 15:24:52.626723  3328 net.cpp:217] conv3_1m needs backward computation.
I0627 15:24:52.626725  3328 net.cpp:217] pool2m needs backward computation.
I0627 15:24:52.626729  3328 net.cpp:217] relu2_2m needs backward computation.
I0627 15:24:52.626730  3328 net.cpp:217] conv2_2m needs backward computation.
I0627 15:24:52.626732  3328 net.cpp:217] relu2_1m needs backward computation.
I0627 15:24:52.626734  3328 net.cpp:217] conv2_1m needs backward computation.
I0627 15:24:52.626737  3328 net.cpp:217] pool1m needs backward computation.
I0627 15:24:52.626739  3328 net.cpp:217] relu1_2m needs backward computation.
I0627 15:24:52.626741  3328 net.cpp:217] conv1_2m needs backward computation.
I0627 15:24:52.626744  3328 net.cpp:217] relu1_1m needs backward computation.
I0627 15:24:52.626746  3328 net.cpp:217] conv1_1m needs backward computation.
I0627 15:24:52.626749  3328 net.cpp:217] relu5_3c needs backward computation.
I0627 15:24:52.626751  3328 net.cpp:217] conv5_3c needs backward computation.
I0627 15:24:52.626754  3328 net.cpp:217] relu5_2c needs backward computation.
I0627 15:24:52.626755  3328 net.cpp:217] conv5_2c needs backward computation.
I0627 15:24:52.626759  3328 net.cpp:217] relu5_1c needs backward computation.
I0627 15:24:52.626760  3328 net.cpp:217] conv5_1c needs backward computation.
I0627 15:24:52.626762  3328 net.cpp:217] relu4_3c needs backward computation.
I0627 15:24:52.626765  3328 net.cpp:217] conv4_3c needs backward computation.
I0627 15:24:52.626767  3328 net.cpp:217] relu4_2c needs backward computation.
I0627 15:24:52.626770  3328 net.cpp:217] conv4_2c needs backward computation.
I0627 15:24:52.626772  3328 net.cpp:217] relu4_1c needs backward computation.
I0627 15:24:52.626775  3328 net.cpp:217] conv4_1c needs backward computation.
I0627 15:24:52.626777  3328 net.cpp:217] pool3c needs backward computation.
I0627 15:24:52.626780  3328 net.cpp:217] relu3_3c needs backward computation.
I0627 15:24:52.626781  3328 net.cpp:217] conv3_3c needs backward computation.
I0627 15:24:52.626785  3328 net.cpp:217] relu3_2c needs backward computation.
I0627 15:24:52.626786  3328 net.cpp:217] conv3_2c needs backward computation.
I0627 15:24:52.626790  3328 net.cpp:217] relu3_1c needs backward computation.
I0627 15:24:52.626791  3328 net.cpp:217] conv3_1c needs backward computation.
I0627 15:24:52.626794  3328 net.cpp:217] pool2c needs backward computation.
I0627 15:24:52.626796  3328 net.cpp:217] relu2_2c needs backward computation.
I0627 15:24:52.626799  3328 net.cpp:217] conv2_2c needs backward computation.
I0627 15:24:52.626806  3328 net.cpp:217] relu2_1c needs backward computation.
I0627 15:24:52.626809  3328 net.cpp:217] conv2_1c needs backward computation.
I0627 15:24:52.626814  3328 net.cpp:217] pool1c needs backward computation.
I0627 15:24:52.626816  3328 net.cpp:217] relu1_2c needs backward computation.
I0627 15:24:52.626818  3328 net.cpp:217] conv1_2c needs backward computation.
I0627 15:24:52.626826  3328 net.cpp:217] relu1_1c needs backward computation.
I0627 15:24:52.626830  3328 net.cpp:217] conv1_1c needs backward computation.
I0627 15:24:52.626833  3328 net.cpp:219] next_im_cur_im_2_split does not need backward computation.
I0627 15:24:52.626837  3328 net.cpp:219] cur_im does not need backward computation.
I0627 15:24:52.626838  3328 net.cpp:261] This network produces output loss
I0627 15:24:52.637929  3328 net.cpp:274] Network initialization done.
I0627 15:24:52.638238  3328 solver.cpp:60] Solver scaffolding done.
I0627 15:24:52.639389  3328 caffe.cpp:129] Finetuning from ./snapshots/train/train__iter_9047.caffemodel
I0627 15:24:53.178412  3328 caffe.cpp:219] Starting Optimization
I0627 15:24:53.178442  3328 solver.cpp:279] Solving 
I0627 15:24:53.178445  3328 solver.cpp:280] Learning Rate Policy: step
I0627 15:25:15.993760  3328 solver.cpp:228] Iteration 0, loss = 0.0943742
I0627 15:25:15.993785  3328 solver.cpp:244]     Train net output #0: loss = 0.115704 (* 1 = 0.115704 loss)
I0627 15:25:15.993795  3328 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0627 15:34:31.774785  3328 solver.cpp:228] Iteration 20, loss = 0.0992945
I0627 15:34:31.774852  3328 solver.cpp:244]     Train net output #0: loss = 0.108586 (* 1 = 0.108586 loss)
I0627 15:34:31.774858  3328 sgd_solver.cpp:106] Iteration 20, lr = 1e-05
I0627 15:43:22.486862  3328 solver.cpp:228] Iteration 40, loss = 0.0937869
I0627 15:43:22.486922  3328 solver.cpp:244]     Train net output #0: loss = 0.0871084 (* 1 = 0.0871084 loss)
I0627 15:43:22.486928  3328 sgd_solver.cpp:106] Iteration 40, lr = 1e-05
I0627 15:52:16.556417  3328 solver.cpp:228] Iteration 60, loss = 0.0933428
I0627 15:52:16.556500  3328 solver.cpp:244]     Train net output #0: loss = 0.0786695 (* 1 = 0.0786695 loss)
I0627 15:52:16.556519  3328 sgd_solver.cpp:106] Iteration 60, lr = 1e-05
I0627 16:01:04.295006  3328 solver.cpp:228] Iteration 80, loss = 0.0935772
I0627 16:01:04.295079  3328 solver.cpp:244]     Train net output #0: loss = 0.0850296 (* 1 = 0.0850296 loss)
I0627 16:01:04.295085  3328 sgd_solver.cpp:106] Iteration 80, lr = 1e-05
I0627 16:09:50.380574  3328 solver.cpp:228] Iteration 100, loss = 0.0923932
I0627 16:09:50.380664  3328 solver.cpp:244]     Train net output #0: loss = 0.101003 (* 1 = 0.101003 loss)
I0627 16:09:50.380672  3328 sgd_solver.cpp:106] Iteration 100, lr = 1e-05
I0627 16:18:36.565978  3328 solver.cpp:228] Iteration 120, loss = 0.0925772
I0627 16:18:36.566051  3328 solver.cpp:244]     Train net output #0: loss = 0.111265 (* 1 = 0.111265 loss)
I0627 16:18:36.566056  3328 sgd_solver.cpp:106] Iteration 120, lr = 1e-05
I0627 16:27:24.666471  3328 solver.cpp:228] Iteration 140, loss = 0.0938174
I0627 16:27:24.666589  3328 solver.cpp:244]     Train net output #0: loss = 0.0802234 (* 1 = 0.0802234 loss)
I0627 16:27:24.666595  3328 sgd_solver.cpp:106] Iteration 140, lr = 1e-05
I0627 16:36:15.507009  3328 solver.cpp:228] Iteration 160, loss = 0.0896888
I0627 16:36:15.507097  3328 solver.cpp:244]     Train net output #0: loss = 0.0892613 (* 1 = 0.0892613 loss)
I0627 16:36:15.507102  3328 sgd_solver.cpp:106] Iteration 160, lr = 1e-05
I0627 16:45:03.578773  3328 solver.cpp:228] Iteration 180, loss = 0.090981
I0627 16:45:03.578878  3328 solver.cpp:244]     Train net output #0: loss = 0.08603 (* 1 = 0.08603 loss)
I0627 16:45:03.578886  3328 sgd_solver.cpp:106] Iteration 180, lr = 1e-05
I0627 16:53:51.014287  3328 solver.cpp:228] Iteration 200, loss = 0.0886502
I0627 16:53:51.014348  3328 solver.cpp:244]     Train net output #0: loss = 0.107637 (* 1 = 0.107637 loss)
I0627 16:53:51.014354  3328 sgd_solver.cpp:106] Iteration 200, lr = 1e-05
I0627 17:02:38.368672  3328 solver.cpp:228] Iteration 220, loss = 0.088524
I0627 17:02:38.368749  3328 solver.cpp:244]     Train net output #0: loss = 0.0764875 (* 1 = 0.0764875 loss)
I0627 17:02:38.368755  3328 sgd_solver.cpp:106] Iteration 220, lr = 1e-05
I0627 17:11:27.160186  3328 solver.cpp:228] Iteration 240, loss = 0.0882066
I0627 17:11:27.160858  3328 solver.cpp:244]     Train net output #0: loss = 0.0773252 (* 1 = 0.0773252 loss)
I0627 17:11:27.160866  3328 sgd_solver.cpp:106] Iteration 240, lr = 1e-05
I0627 17:15:32.477777  3328 solver.cpp:454] Snapshotting to binary proto file ./snapshots/davis_simple_iter_250.caffemodel
I0627 17:15:38.118731  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/davis_simple_iter_250.solverstate
I0627 17:20:29.022958  3328 solver.cpp:228] Iteration 260, loss = 0.0919488
I0627 17:20:29.023152  3328 solver.cpp:244]     Train net output #0: loss = 0.0941289 (* 1 = 0.0941289 loss)
I0627 17:20:29.023159  3328 sgd_solver.cpp:106] Iteration 260, lr = 1e-05
I0627 17:29:20.159145  3328 solver.cpp:228] Iteration 280, loss = 0.0893951
I0627 17:29:20.159245  3328 solver.cpp:244]     Train net output #0: loss = 0.104775 (* 1 = 0.104775 loss)
I0627 17:29:20.159250  3328 sgd_solver.cpp:106] Iteration 280, lr = 1e-05
I0627 17:38:09.989593  3328 solver.cpp:228] Iteration 300, loss = 0.0881045
I0627 17:38:09.989670  3328 solver.cpp:244]     Train net output #0: loss = 0.0899655 (* 1 = 0.0899655 loss)
I0627 17:38:09.989676  3328 sgd_solver.cpp:106] Iteration 300, lr = 1e-05
I0627 17:47:17.951133  3328 solver.cpp:228] Iteration 320, loss = 0.0887862
I0627 17:47:17.951253  3328 solver.cpp:244]     Train net output #0: loss = 0.114738 (* 1 = 0.114738 loss)
I0627 17:47:17.951261  3328 sgd_solver.cpp:106] Iteration 320, lr = 1e-05
I0627 17:56:54.128525  3328 solver.cpp:228] Iteration 340, loss = 0.0891327
I0627 17:56:54.128604  3328 solver.cpp:244]     Train net output #0: loss = 0.0855492 (* 1 = 0.0855492 loss)
I0627 17:56:54.128610  3328 sgd_solver.cpp:106] Iteration 340, lr = 1e-05
I0627 18:06:31.731051  3328 solver.cpp:228] Iteration 360, loss = 0.0918811
I0627 18:06:31.731132  3328 solver.cpp:244]     Train net output #0: loss = 0.213072 (* 1 = 0.213072 loss)
I0627 18:06:31.731140  3328 sgd_solver.cpp:106] Iteration 360, lr = 1e-05
I0627 18:15:31.842758  3328 solver.cpp:228] Iteration 380, loss = 0.0904683
I0627 18:15:31.842840  3328 solver.cpp:244]     Train net output #0: loss = 0.0744178 (* 1 = 0.0744178 loss)
I0627 18:15:31.842847  3328 sgd_solver.cpp:106] Iteration 380, lr = 1e-05
I0627 18:24:34.133554  3328 solver.cpp:228] Iteration 400, loss = 0.0883295
I0627 18:24:34.133641  3328 solver.cpp:244]     Train net output #0: loss = 0.0998106 (* 1 = 0.0998106 loss)
I0627 18:24:34.133648  3328 sgd_solver.cpp:106] Iteration 400, lr = 1e-05
I0627 18:33:51.505784  3328 solver.cpp:228] Iteration 420, loss = 0.0885166
I0627 18:33:51.505834  3328 solver.cpp:244]     Train net output #0: loss = 0.0655622 (* 1 = 0.0655622 loss)
I0627 18:33:51.505841  3328 sgd_solver.cpp:106] Iteration 420, lr = 1e-05
I0627 18:42:48.208370  3328 solver.cpp:228] Iteration 440, loss = 0.0881472
I0627 18:42:48.208408  3328 solver.cpp:244]     Train net output #0: loss = 0.10496 (* 1 = 0.10496 loss)
I0627 18:42:48.208415  3328 sgd_solver.cpp:106] Iteration 440, lr = 1e-05
I0627 18:51:46.304803  3328 solver.cpp:228] Iteration 460, loss = 0.0876513
I0627 18:51:46.304877  3328 solver.cpp:244]     Train net output #0: loss = 0.0936059 (* 1 = 0.0936059 loss)
I0627 18:51:46.304894  3328 sgd_solver.cpp:106] Iteration 460, lr = 1e-05
I0627 19:00:45.516597  3328 solver.cpp:228] Iteration 480, loss = 0.087761
I0627 19:00:45.516677  3328 solver.cpp:244]     Train net output #0: loss = 0.0849108 (* 1 = 0.0849108 loss)
I0627 19:00:45.516683  3328 sgd_solver.cpp:106] Iteration 480, lr = 1e-05
I0627 19:09:15.616386  3328 solver.cpp:454] Snapshotting to binary proto file ./snapshots/davis_simple_iter_500.caffemodel
I0627 19:09:26.363317  3328 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/davis_simple_iter_500.solverstate
I0627 19:09:30.323529  3328 solver.cpp:317] Iteration 500, loss = 0.0863455
I0627 19:09:30.323565  3328 solver.cpp:322] Optimization Done.
I0627 19:09:31.785038  3328 caffe.cpp:222] Optimization Done.

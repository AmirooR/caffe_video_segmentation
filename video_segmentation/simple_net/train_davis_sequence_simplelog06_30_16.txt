I0630 00:43:38.822101 20971 caffe.cpp:185] Using GPUs 0
I0630 00:43:38.829488 20971 caffe.cpp:190] GPU 0: Tesla K40c
I0630 00:43:38.943403 20971 solver.cpp:48] Initializing solver from parameters: 
train_net: "train_davis_sequence_simple.prototxt"
base_lr: 1e-05
display: 20
max_iter: 25000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2500
snapshot: 1250
snapshot_prefix: "./snapshots/davis_sequence_simple"
device_id: 0
average_loss: 20
iter_size: 1
I0630 00:43:38.943506 20971 solver.cpp:81] Creating training net from train_net file: train_davis_sequence_simple.prototxt
I0630 00:43:38.945305 20971 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "cur_im"
  type: "Python"
  top: "cur_im"
  top: "masked_im"
  top: "next_im"
  top: "label"
  python_param {
    module: "davis_datalayer_server"
    layer: "DavisDataLayerServer"
    param_str: "{\'shuffle\': True, \'im_shape\': (384, 384), \'batch_size\': 4, \'max_len\': 20, \'split\': \'training\', \'port\': \'6678\'}"
  }
}
layer {
  name: "conv1_1c"
  type: "Convolution"
  bottom: "cur_im"
  top: "conv1_1c"
  param {
    name: "conv1_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 101
    kernel_size: 3
  }
}
layer {
  name: "relu1_1c"
  type: "ReLU"
  bottom: "conv1_1c"
  top: "conv1_1c"
}
layer {
  name: "conv1_2c"
  type: "Convolution"
  bottom: "conv1_1c"
  top: "conv1_2c"
  param {
    name: "conv1_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2c"
  type: "ReLU"
  bottom: "conv1_2c"
  top: "conv1_2c"
}
layer {
  name: "pool1c"
  type: "Pooling"
  bottom: "conv1_2c"
  top: "pool1c"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1c"
  type: "Convolution"
  bottom: "pool1c"
  top: "conv2_1c"
  param {
    name: "conv2_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1c"
  type: "ReLU"
  bottom: "conv2_1c"
  top: "conv2_1c"
}
layer {
  name: "conv2_2c"
  type: "Convolution"
  bottom: "conv2_1c"
  top: "conv2_2c"
  param {
    name: "conv2_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2c"
  type: "ReLU"
  bottom: "conv2_2c"
  top: "conv2_2c"
}
layer {
  name: "pool2c"
  type: "Pooling"
  bottom: "conv2_2c"
  top: "pool2c"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1c"
  type: "Convolution"
  bottom: "pool2c"
  top: "conv3_1c"
  param {
    name: "conv3_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1c"
  type: "ReLU"
  bottom: "conv3_1c"
  top: "conv3_1c"
}
layer {
  name: "conv3_2c"
  type: "Convolution"
  bottom: "conv3_1c"
  top: "conv3_2c"
  param {
    name: "conv3_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2c"
  type: "ReLU"
  bottom: "conv3_2c"
  top: "conv3_2c"
}
layer {
  name: "conv3_3c"
  type: "Convolution"
  bottom: "conv3_2c"
  top: "conv3_3c"
  param {
    name: "conv3_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3c"
  type: "ReLU"
  bottom: "conv3_3c"
  top: "conv3_3c"
}
layer {
  name: "pool3c"
  type: "Pooling"
  bottom: "conv3_3c"
  top: "pool3c"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1c"
  type: "Convolution"
  bottom: "pool3c"
  top: "conv4_1c"
  param {
    name: "conv4_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1c"
  type: "ReLU"
  bottom: "conv4_1c"
  top: "conv4_1c"
}
layer {
  name: "conv4_2c"
  type: "Convolution"
  bottom: "conv4_1c"
  top: "conv4_2c"
  param {
    name: "conv4_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2c"
  type: "ReLU"
  bottom: "conv4_2c"
  top: "conv4_2c"
}
layer {
  name: "conv4_3c"
  type: "Convolution"
  bottom: "conv4_2c"
  top: "conv4_3c"
  param {
    name: "conv4_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3c"
  type: "ReLU"
  bottom: "conv4_3c"
  top: "conv4_3c"
}
layer {
  name: "conv5_1c"
  type: "Convolution"
  bottom: "conv4_3c"
  top: "conv5_1c"
  param {
    name: "conv5_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_1c"
  type: "ReLU"
  bottom: "conv5_1c"
  top: "conv5_1c"
}
layer {
  name: "conv5_2c"
  type: "Convolution"
  bottom: "conv5_1c"
  top: "conv5_2c"
  param {
    name: "conv5_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_2c"
  type: "ReLU"
  bottom: "conv5_2c"
  top: "conv5_2c"
}
layer {
  name: "conv5_3c"
  type: "Convolution"
  bottom: "conv5_2c"
  top: "conv5_3c"
  param {
    name: "conv5_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad_h: 14
    pad_w: 14
    dilation: 2
  }
}
layer {
  name: "relu5_3c"
  type: "ReLU"
  bottom: "conv5_3c"
  top: "conv5_3c"
}
layer {
  name: "conv1_1m"
  type: "Convolution"
  bottom: "masked_im"
  top: "conv1_1m"
  param {
    name: "conv1_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 101
    kernel_size: 3
  }
}
layer {
  name: "relu1_1m"
  type: "ReLU"
  bottom: "conv1_1m"
  top: "conv1_1m"
}
layer {
  name: "conv1_2m"
  type: "Convolution"
  bottom: "conv1_1m"
  top: "conv1_2m"
  param {
    name: "conv1_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2m"
  type: "ReLU"
  bottom: "conv1_2m"
  top: "conv1_2m"
}
layer {
  name: "pool1m"
  type: "Pooling"
  bottom: "conv1_2m"
  top: "pool1m"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1m"
  type: "Convolution"
  bottom: "pool1m"
  top: "conv2_1m"
  param {
    name: "conv2_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1m"
  type: "ReLU"
  bottom: "conv2_1m"
  top: "conv2_1m"
}
layer {
  name: "conv2_2m"
  type: "Convolution"
  bottom: "conv2_1m"
  top: "conv2_2m"
  param {
    name: "conv2_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2m"
  type: "ReLU"
  bottom: "conv2_2m"
  top: "conv2_2m"
}
layer {
  name: "pool2m"
  type: "Pooling"
  bottom: "conv2_2m"
  top: "pool2m"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1m"
  type: "Convolution"
  bottom: "pool2m"
  top: "conv3_1m"
  param {
    name: "conv3_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1m"
  type: "ReLU"
  bottom: "conv3_1m"
  top: "conv3_1m"
}
layer {
  name: "conv3_2m"
  type: "Convolution"
  bottom: "conv3_1m"
  top: "conv3_2m"
  param {
    name: "conv3_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2m"
  type: "ReLU"
  bottom: "conv3_2m"
  top: "conv3_2m"
}
layer {
  name: "conv3_3m"
  type: "Convolution"
  bottom: "conv3_2m"
  top: "conv3_3m"
  param {
    name: "conv3_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3m"
  type: "ReLU"
  bottom: "conv3_3m"
  top: "conv3_3m"
}
layer {
  name: "pool3m"
  type: "Pooling"
  bottom: "conv3_3m"
  top: "pool3m"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1m"
  type: "Convolution"
  bottom: "pool3m"
  top: "conv4_1m"
  param {
    name: "conv4_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1m"
  type: "ReLU"
  bottom: "conv4_1m"
  top: "conv4_1m"
}
layer {
  name: "conv4_2m"
  type: "Convolution"
  bottom: "conv4_1m"
  top: "conv4_2m"
  param {
    name: "conv4_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2m"
  type: "ReLU"
  bottom: "conv4_2m"
  top: "conv4_2m"
}
layer {
  name: "conv4_3m"
  type: "Convolution"
  bottom: "conv4_2m"
  top: "conv4_3m"
  param {
    name: "conv4_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3m"
  type: "ReLU"
  bottom: "conv4_3m"
  top: "conv4_3m"
}
layer {
  name: "conv5_1m"
  type: "Convolution"
  bottom: "conv4_3m"
  top: "conv5_1m"
  param {
    name: "conv5_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_1m"
  type: "ReLU"
  bottom: "conv5_1m"
  top: "conv5_1m"
}
layer {
  name: "conv5_2m"
  type: "Convolution"
  bottom: "conv5_1m"
  top: "conv5_2m"
  param {
    name: "conv5_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_2m"
  type: "ReLU"
  bottom: "conv5_2m"
  top: "conv5_2m"
}
layer {
  name: "conv5_3m"
  type: "Convolution"
  bottom: "conv5_2m"
  top: "conv5_3m"
  param {
    name: "conv5_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad_h: 14
    pad_w: 14
    dilation: 2
  }
}
layer {
  name: "relu5_3m"
  type: "ReLU"
  bottom: "conv5_3m"
  top: "conv5_3m"
}
layer {
  name: "conv1_1n"
  type: "Convolution"
  bottom: "next_im"
  top: "conv1_1n"
  param {
    name: "conv1_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 101
    kernel_size: 3
  }
}
layer {
  name: "relu1_1n"
  type: "ReLU"
  bottom: "conv1_1n"
  top: "conv1_1n"
}
layer {
  name: "conv1_2n"
  type: "Convolution"
  bottom: "conv1_1n"
  top: "conv1_2n"
  param {
    name: "conv1_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv1_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2n"
  type: "ReLU"
  bottom: "conv1_2n"
  top: "conv1_2n"
}
layer {
  name: "pool1n"
  type: "Pooling"
  bottom: "conv1_2n"
  top: "pool1n"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1n"
  type: "Convolution"
  bottom: "pool1n"
  top: "conv2_1n"
  param {
    name: "conv2_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1n"
  type: "ReLU"
  bottom: "conv2_1n"
  top: "conv2_1n"
}
layer {
  name: "conv2_2n"
  type: "Convolution"
  bottom: "conv2_1n"
  top: "conv2_2n"
  param {
    name: "conv2_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv2_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2n"
  type: "ReLU"
  bottom: "conv2_2n"
  top: "conv2_2n"
}
layer {
  name: "pool2n"
  type: "Pooling"
  bottom: "conv2_2n"
  top: "pool2n"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1n"
  type: "Convolution"
  bottom: "pool2n"
  top: "conv3_1n"
  param {
    name: "conv3_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1n"
  type: "ReLU"
  bottom: "conv3_1n"
  top: "conv3_1n"
}
layer {
  name: "conv3_2n"
  type: "Convolution"
  bottom: "conv3_1n"
  top: "conv3_2n"
  param {
    name: "conv3_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2n"
  type: "ReLU"
  bottom: "conv3_2n"
  top: "conv3_2n"
}
layer {
  name: "conv3_3n"
  type: "Convolution"
  bottom: "conv3_2n"
  top: "conv3_3n"
  param {
    name: "conv3_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv3_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3n"
  type: "ReLU"
  bottom: "conv3_3n"
  top: "conv3_3n"
}
layer {
  name: "pool3n"
  type: "Pooling"
  bottom: "conv3_3n"
  top: "pool3n"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1n"
  type: "Convolution"
  bottom: "pool3n"
  top: "conv4_1n"
  param {
    name: "conv4_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1n"
  type: "ReLU"
  bottom: "conv4_1n"
  top: "conv4_1n"
}
layer {
  name: "conv4_2n"
  type: "Convolution"
  bottom: "conv4_1n"
  top: "conv4_2n"
  param {
    name: "conv4_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2n"
  type: "ReLU"
  bottom: "conv4_2n"
  top: "conv4_2n"
}
layer {
  name: "conv4_3n"
  type: "Convolution"
  bottom: "conv4_2n"
  top: "conv4_3n"
  param {
    name: "conv4_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv4_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3n"
  type: "ReLU"
  bottom: "conv4_3n"
  top: "conv4_3n"
}
layer {
  name: "conv5_1n"
  type: "Convolution"
  bottom: "conv4_3n"
  top: "conv5_1n"
  param {
    name: "conv5_1_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_1_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_1n"
  type: "ReLU"
  bottom: "conv5_1n"
  top: "conv5_1n"
}
layer {
  name: "conv5_2n"
  type: "Convolution"
  bottom: "conv5_1n"
  top: "conv5_2n"
  param {
    name: "conv5_2_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_2_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_2n"
  type: "ReLU"
  bottom: "conv5_2n"
  top: "conv5_2n"
}
layer {
  name: "conv5_3n"
  type: "Convolution"
  bottom: "conv5_2n"
  top: "conv5_3n"
  param {
    name: "conv5_3_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv5_3_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_3n"
  type: "ReLU"
  bottom: "conv5_3n"
  top: "conv5_3n"
}
layer {
  name: "concat1"
  type: "Concat"
  bottom: "conv5_3c"
  bottom: "conv5_3m"
  bottom: "conv5_3n"
  top: "concat1"
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "concat1"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 7
    dilation: 4
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "Convolution"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    kernel_size: 1
  }
}
layer {
  name: "upscore"
  type: "Deconvolution"
  bottom: "fc8"
  top: "upscore"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    bias_term: false
    kernel_size: 16
    group: 2
    stride: 8
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "score"
  type: "Crop"
  bottom: "upscore"
  bottom: "next_im"
  top: "score"
  crop_param {
    axis: 2
    offset: 8
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
  loss_param {
    ignore_label: 255
  }
}
layer {
  name: "clinet_top"
  type: "Python"
  bottom: "score"
  top: "clinet_top"
  python_param {
    module: "davis_datalayer_client"
    layer: "DavisDataLayerClient"
    param_str: "{\'port\': \'6678\'}"
  }
}
I0630 00:43:38.945587 20971 layer_factory.hpp:77] Creating layer cur_im
/home/amir/davis/python/lib/davis/measures/t_stability.py:6: RuntimeWarning: to-Python converter for std::vector<bool, std::allocator<bool> > already registered; second conversion method ignored.
  from tstab import *
I0630 00:43:39.523010 20971 net.cpp:91] Creating Layer cur_im
I0630 00:43:39.523041 20971 net.cpp:399] cur_im -> cur_im
I0630 00:43:39.523056 20971 net.cpp:399] cur_im -> masked_im
I0630 00:43:39.523064 20971 net.cpp:399] cur_im -> next_im
I0630 00:43:39.523068 20971 net.cpp:399] cur_im -> label
I0630 00:43:39.569082 20971 net.cpp:141] Setting up cur_im
I0630 00:43:39.569113 20971 net.cpp:148] Top shape: 4 3 192 192 (442368)
I0630 00:43:39.569118 20971 net.cpp:148] Top shape: 4 3 192 192 (442368)
I0630 00:43:39.569121 20971 net.cpp:148] Top shape: 4 3 384 384 (1769472)
I0630 00:43:39.569125 20971 net.cpp:148] Top shape: 4 1 384 384 (589824)
I0630 00:43:39.569128 20971 net.cpp:156] Memory required for data: 12976128
I0630 00:43:39.569140 20971 layer_factory.hpp:77] Creating layer next_im_cur_im_2_split
I0630 00:43:39.569171 20971 net.cpp:91] Creating Layer next_im_cur_im_2_split
I0630 00:43:39.569188 20971 net.cpp:425] next_im_cur_im_2_split <- next_im
I0630 00:43:39.569203 20971 net.cpp:399] next_im_cur_im_2_split -> next_im_cur_im_2_split_0
I0630 00:43:39.569214 20971 net.cpp:399] next_im_cur_im_2_split -> next_im_cur_im_2_split_1
I0630 00:43:39.569243 20971 net.cpp:141] Setting up next_im_cur_im_2_split
I0630 00:43:39.569248 20971 net.cpp:148] Top shape: 4 3 384 384 (1769472)
I0630 00:43:39.569250 20971 net.cpp:148] Top shape: 4 3 384 384 (1769472)
I0630 00:43:39.569252 20971 net.cpp:156] Memory required for data: 27131904
I0630 00:43:39.569254 20971 layer_factory.hpp:77] Creating layer conv1_1c
I0630 00:43:39.569268 20971 net.cpp:91] Creating Layer conv1_1c
I0630 00:43:39.569272 20971 net.cpp:425] conv1_1c <- cur_im
I0630 00:43:39.569277 20971 net.cpp:399] conv1_1c -> conv1_1c
I0630 00:43:39.694135 20971 net.cpp:141] Setting up conv1_1c
I0630 00:43:39.694165 20971 net.cpp:148] Top shape: 4 64 392 392 (39337984)
I0630 00:43:39.694169 20971 net.cpp:156] Memory required for data: 184483840
I0630 00:43:39.694181 20971 layer_factory.hpp:77] Creating layer relu1_1c
I0630 00:43:39.694190 20971 net.cpp:91] Creating Layer relu1_1c
I0630 00:43:39.694191 20971 net.cpp:425] relu1_1c <- conv1_1c
I0630 00:43:39.694195 20971 net.cpp:386] relu1_1c -> conv1_1c (in-place)
I0630 00:43:39.694314 20971 net.cpp:141] Setting up relu1_1c
I0630 00:43:39.694320 20971 net.cpp:148] Top shape: 4 64 392 392 (39337984)
I0630 00:43:39.694324 20971 net.cpp:156] Memory required for data: 341835776
I0630 00:43:39.694325 20971 layer_factory.hpp:77] Creating layer conv1_2c
I0630 00:43:39.694335 20971 net.cpp:91] Creating Layer conv1_2c
I0630 00:43:39.694339 20971 net.cpp:425] conv1_2c <- conv1_1c
I0630 00:43:39.694342 20971 net.cpp:399] conv1_2c -> conv1_2c
I0630 00:43:39.695541 20971 net.cpp:141] Setting up conv1_2c
I0630 00:43:39.695551 20971 net.cpp:148] Top shape: 4 64 392 392 (39337984)
I0630 00:43:39.695554 20971 net.cpp:156] Memory required for data: 499187712
I0630 00:43:39.695561 20971 layer_factory.hpp:77] Creating layer relu1_2c
I0630 00:43:39.695565 20971 net.cpp:91] Creating Layer relu1_2c
I0630 00:43:39.695567 20971 net.cpp:425] relu1_2c <- conv1_2c
I0630 00:43:39.695574 20971 net.cpp:386] relu1_2c -> conv1_2c (in-place)
I0630 00:43:39.695760 20971 net.cpp:141] Setting up relu1_2c
I0630 00:43:39.695766 20971 net.cpp:148] Top shape: 4 64 392 392 (39337984)
I0630 00:43:39.695768 20971 net.cpp:156] Memory required for data: 656539648
I0630 00:43:39.695771 20971 layer_factory.hpp:77] Creating layer pool1c
I0630 00:43:39.695777 20971 net.cpp:91] Creating Layer pool1c
I0630 00:43:39.695780 20971 net.cpp:425] pool1c <- conv1_2c
I0630 00:43:39.695785 20971 net.cpp:399] pool1c -> pool1c
I0630 00:43:39.695822 20971 net.cpp:141] Setting up pool1c
I0630 00:43:39.695827 20971 net.cpp:148] Top shape: 4 64 196 196 (9834496)
I0630 00:43:39.695828 20971 net.cpp:156] Memory required for data: 695877632
I0630 00:43:39.695830 20971 layer_factory.hpp:77] Creating layer conv2_1c
I0630 00:43:39.695837 20971 net.cpp:91] Creating Layer conv2_1c
I0630 00:43:39.695839 20971 net.cpp:425] conv2_1c <- pool1c
I0630 00:43:39.695843 20971 net.cpp:399] conv2_1c -> conv2_1c
I0630 00:43:39.696575 20971 net.cpp:141] Setting up conv2_1c
I0630 00:43:39.696583 20971 net.cpp:148] Top shape: 4 128 196 196 (19668992)
I0630 00:43:39.696585 20971 net.cpp:156] Memory required for data: 774553600
I0630 00:43:39.696591 20971 layer_factory.hpp:77] Creating layer relu2_1c
I0630 00:43:39.696596 20971 net.cpp:91] Creating Layer relu2_1c
I0630 00:43:39.696599 20971 net.cpp:425] relu2_1c <- conv2_1c
I0630 00:43:39.696601 20971 net.cpp:386] relu2_1c -> conv2_1c (in-place)
I0630 00:43:39.696712 20971 net.cpp:141] Setting up relu2_1c
I0630 00:43:39.696717 20971 net.cpp:148] Top shape: 4 128 196 196 (19668992)
I0630 00:43:39.696719 20971 net.cpp:156] Memory required for data: 853229568
I0630 00:43:39.696722 20971 layer_factory.hpp:77] Creating layer conv2_2c
I0630 00:43:39.696728 20971 net.cpp:91] Creating Layer conv2_2c
I0630 00:43:39.696740 20971 net.cpp:425] conv2_2c <- conv2_1c
I0630 00:43:39.696744 20971 net.cpp:399] conv2_2c -> conv2_2c
I0630 00:43:39.697661 20971 net.cpp:141] Setting up conv2_2c
I0630 00:43:39.697669 20971 net.cpp:148] Top shape: 4 128 196 196 (19668992)
I0630 00:43:39.697671 20971 net.cpp:156] Memory required for data: 931905536
I0630 00:43:39.697675 20971 layer_factory.hpp:77] Creating layer relu2_2c
I0630 00:43:39.697679 20971 net.cpp:91] Creating Layer relu2_2c
I0630 00:43:39.697681 20971 net.cpp:425] relu2_2c <- conv2_2c
I0630 00:43:39.697685 20971 net.cpp:386] relu2_2c -> conv2_2c (in-place)
I0630 00:43:39.697789 20971 net.cpp:141] Setting up relu2_2c
I0630 00:43:39.697796 20971 net.cpp:148] Top shape: 4 128 196 196 (19668992)
I0630 00:43:39.697798 20971 net.cpp:156] Memory required for data: 1010581504
I0630 00:43:39.697800 20971 layer_factory.hpp:77] Creating layer pool2c
I0630 00:43:39.697806 20971 net.cpp:91] Creating Layer pool2c
I0630 00:43:39.697808 20971 net.cpp:425] pool2c <- conv2_2c
I0630 00:43:39.697811 20971 net.cpp:399] pool2c -> pool2c
I0630 00:43:39.697835 20971 net.cpp:141] Setting up pool2c
I0630 00:43:39.697839 20971 net.cpp:148] Top shape: 4 128 98 98 (4917248)
I0630 00:43:39.697841 20971 net.cpp:156] Memory required for data: 1030250496
I0630 00:43:39.697844 20971 layer_factory.hpp:77] Creating layer conv3_1c
I0630 00:43:39.697847 20971 net.cpp:91] Creating Layer conv3_1c
I0630 00:43:39.697850 20971 net.cpp:425] conv3_1c <- pool2c
I0630 00:43:39.697854 20971 net.cpp:399] conv3_1c -> conv3_1c
I0630 00:43:39.699836 20971 net.cpp:141] Setting up conv3_1c
I0630 00:43:39.699869 20971 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0630 00:43:39.699874 20971 net.cpp:156] Memory required for data: 1069588480
I0630 00:43:39.699899 20971 layer_factory.hpp:77] Creating layer relu3_1c
I0630 00:43:39.699913 20971 net.cpp:91] Creating Layer relu3_1c
I0630 00:43:39.699921 20971 net.cpp:425] relu3_1c <- conv3_1c
I0630 00:43:39.699930 20971 net.cpp:386] relu3_1c -> conv3_1c (in-place)
I0630 00:43:39.700284 20971 net.cpp:141] Setting up relu3_1c
I0630 00:43:39.700294 20971 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0630 00:43:39.700299 20971 net.cpp:156] Memory required for data: 1108926464
I0630 00:43:39.700302 20971 layer_factory.hpp:77] Creating layer conv3_2c
I0630 00:43:39.700317 20971 net.cpp:91] Creating Layer conv3_2c
I0630 00:43:39.700322 20971 net.cpp:425] conv3_2c <- conv3_1c
I0630 00:43:39.700338 20971 net.cpp:399] conv3_2c -> conv3_2c
I0630 00:43:39.702030 20971 net.cpp:141] Setting up conv3_2c
I0630 00:43:39.702046 20971 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0630 00:43:39.702051 20971 net.cpp:156] Memory required for data: 1148264448
I0630 00:43:39.702064 20971 layer_factory.hpp:77] Creating layer relu3_2c
I0630 00:43:39.702070 20971 net.cpp:91] Creating Layer relu3_2c
I0630 00:43:39.702074 20971 net.cpp:425] relu3_2c <- conv3_2c
I0630 00:43:39.702077 20971 net.cpp:386] relu3_2c -> conv3_2c (in-place)
I0630 00:43:39.702183 20971 net.cpp:141] Setting up relu3_2c
I0630 00:43:39.702189 20971 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0630 00:43:39.702191 20971 net.cpp:156] Memory required for data: 1187602432
I0630 00:43:39.702193 20971 layer_factory.hpp:77] Creating layer conv3_3c
I0630 00:43:39.702203 20971 net.cpp:91] Creating Layer conv3_3c
I0630 00:43:39.702205 20971 net.cpp:425] conv3_3c <- conv3_2c
I0630 00:43:39.702209 20971 net.cpp:399] conv3_3c -> conv3_3c
I0630 00:43:39.704169 20971 net.cpp:141] Setting up conv3_3c
I0630 00:43:39.704203 20971 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0630 00:43:39.704210 20971 net.cpp:156] Memory required for data: 1226940416
I0630 00:43:39.704226 20971 layer_factory.hpp:77] Creating layer relu3_3c
I0630 00:43:39.704237 20971 net.cpp:91] Creating Layer relu3_3c
I0630 00:43:39.704242 20971 net.cpp:425] relu3_3c <- conv3_3c
I0630 00:43:39.704249 20971 net.cpp:386] relu3_3c -> conv3_3c (in-place)
I0630 00:43:39.704434 20971 net.cpp:141] Setting up relu3_3c
I0630 00:43:39.704444 20971 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0630 00:43:39.704463 20971 net.cpp:156] Memory required for data: 1266278400
I0630 00:43:39.704466 20971 layer_factory.hpp:77] Creating layer pool3c
I0630 00:43:39.704476 20971 net.cpp:91] Creating Layer pool3c
I0630 00:43:39.704480 20971 net.cpp:425] pool3c <- conv3_3c
I0630 00:43:39.704488 20971 net.cpp:399] pool3c -> pool3c
I0630 00:43:39.704531 20971 net.cpp:141] Setting up pool3c
I0630 00:43:39.704540 20971 net.cpp:148] Top shape: 4 256 49 49 (2458624)
I0630 00:43:39.704542 20971 net.cpp:156] Memory required for data: 1276112896
I0630 00:43:39.704545 20971 layer_factory.hpp:77] Creating layer conv4_1c
I0630 00:43:39.704555 20971 net.cpp:91] Creating Layer conv4_1c
I0630 00:43:39.704558 20971 net.cpp:425] conv4_1c <- pool3c
I0630 00:43:39.704565 20971 net.cpp:399] conv4_1c -> conv4_1c
I0630 00:43:39.708696 20971 net.cpp:141] Setting up conv4_1c
I0630 00:43:39.708797 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.708814 20971 net.cpp:156] Memory required for data: 1295781888
I0630 00:43:39.708827 20971 layer_factory.hpp:77] Creating layer relu4_1c
I0630 00:43:39.708844 20971 net.cpp:91] Creating Layer relu4_1c
I0630 00:43:39.708849 20971 net.cpp:425] relu4_1c <- conv4_1c
I0630 00:43:39.708864 20971 net.cpp:386] relu4_1c -> conv4_1c (in-place)
I0630 00:43:39.709108 20971 net.cpp:141] Setting up relu4_1c
I0630 00:43:39.709120 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.709122 20971 net.cpp:156] Memory required for data: 1315450880
I0630 00:43:39.709127 20971 layer_factory.hpp:77] Creating layer conv4_2c
I0630 00:43:39.709136 20971 net.cpp:91] Creating Layer conv4_2c
I0630 00:43:39.709138 20971 net.cpp:425] conv4_2c <- conv4_1c
I0630 00:43:39.709142 20971 net.cpp:399] conv4_2c -> conv4_2c
I0630 00:43:39.713336 20971 net.cpp:141] Setting up conv4_2c
I0630 00:43:39.713371 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.713373 20971 net.cpp:156] Memory required for data: 1335119872
I0630 00:43:39.713392 20971 layer_factory.hpp:77] Creating layer relu4_2c
I0630 00:43:39.713412 20971 net.cpp:91] Creating Layer relu4_2c
I0630 00:43:39.713416 20971 net.cpp:425] relu4_2c <- conv4_2c
I0630 00:43:39.713423 20971 net.cpp:386] relu4_2c -> conv4_2c (in-place)
I0630 00:43:39.713542 20971 net.cpp:141] Setting up relu4_2c
I0630 00:43:39.713548 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.713551 20971 net.cpp:156] Memory required for data: 1354788864
I0630 00:43:39.713552 20971 layer_factory.hpp:77] Creating layer conv4_3c
I0630 00:43:39.713562 20971 net.cpp:91] Creating Layer conv4_3c
I0630 00:43:39.713564 20971 net.cpp:425] conv4_3c <- conv4_2c
I0630 00:43:39.713568 20971 net.cpp:399] conv4_3c -> conv4_3c
I0630 00:43:39.717164 20971 net.cpp:141] Setting up conv4_3c
I0630 00:43:39.717182 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.717185 20971 net.cpp:156] Memory required for data: 1374457856
I0630 00:43:39.717192 20971 layer_factory.hpp:77] Creating layer relu4_3c
I0630 00:43:39.717198 20971 net.cpp:91] Creating Layer relu4_3c
I0630 00:43:39.717201 20971 net.cpp:425] relu4_3c <- conv4_3c
I0630 00:43:39.717208 20971 net.cpp:386] relu4_3c -> conv4_3c (in-place)
I0630 00:43:39.717321 20971 net.cpp:141] Setting up relu4_3c
I0630 00:43:39.717326 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.717329 20971 net.cpp:156] Memory required for data: 1394126848
I0630 00:43:39.717332 20971 layer_factory.hpp:77] Creating layer conv5_1c
I0630 00:43:39.717339 20971 net.cpp:91] Creating Layer conv5_1c
I0630 00:43:39.717341 20971 net.cpp:425] conv5_1c <- conv4_3c
I0630 00:43:39.717344 20971 net.cpp:399] conv5_1c -> conv5_1c
I0630 00:43:39.720410 20971 net.cpp:141] Setting up conv5_1c
I0630 00:43:39.720432 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.720435 20971 net.cpp:156] Memory required for data: 1413795840
I0630 00:43:39.720444 20971 layer_factory.hpp:77] Creating layer relu5_1c
I0630 00:43:39.720453 20971 net.cpp:91] Creating Layer relu5_1c
I0630 00:43:39.720458 20971 net.cpp:425] relu5_1c <- conv5_1c
I0630 00:43:39.720474 20971 net.cpp:386] relu5_1c -> conv5_1c (in-place)
I0630 00:43:39.720808 20971 net.cpp:141] Setting up relu5_1c
I0630 00:43:39.720818 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.720821 20971 net.cpp:156] Memory required for data: 1433464832
I0630 00:43:39.720824 20971 layer_factory.hpp:77] Creating layer conv5_2c
I0630 00:43:39.720835 20971 net.cpp:91] Creating Layer conv5_2c
I0630 00:43:39.720839 20971 net.cpp:425] conv5_2c <- conv5_1c
I0630 00:43:39.720846 20971 net.cpp:399] conv5_2c -> conv5_2c
I0630 00:43:39.724843 20971 net.cpp:141] Setting up conv5_2c
I0630 00:43:39.724865 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.724869 20971 net.cpp:156] Memory required for data: 1453133824
I0630 00:43:39.724879 20971 layer_factory.hpp:77] Creating layer relu5_2c
I0630 00:43:39.724889 20971 net.cpp:91] Creating Layer relu5_2c
I0630 00:43:39.724892 20971 net.cpp:425] relu5_2c <- conv5_2c
I0630 00:43:39.724898 20971 net.cpp:386] relu5_2c -> conv5_2c (in-place)
I0630 00:43:39.725257 20971 net.cpp:141] Setting up relu5_2c
I0630 00:43:39.725266 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.725270 20971 net.cpp:156] Memory required for data: 1472802816
I0630 00:43:39.725273 20971 layer_factory.hpp:77] Creating layer conv5_3c
I0630 00:43:39.725294 20971 net.cpp:91] Creating Layer conv5_3c
I0630 00:43:39.725297 20971 net.cpp:425] conv5_3c <- conv5_2c
I0630 00:43:39.725301 20971 net.cpp:399] conv5_3c -> conv5_3c
I0630 00:43:39.728415 20971 net.cpp:141] Setting up conv5_3c
I0630 00:43:39.728435 20971 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0630 00:43:39.728437 20971 net.cpp:156] Memory required for data: 1516457984
I0630 00:43:39.728444 20971 layer_factory.hpp:77] Creating layer relu5_3c
I0630 00:43:39.728451 20971 net.cpp:91] Creating Layer relu5_3c
I0630 00:43:39.728456 20971 net.cpp:425] relu5_3c <- conv5_3c
I0630 00:43:39.728459 20971 net.cpp:386] relu5_3c -> conv5_3c (in-place)
I0630 00:43:39.728621 20971 net.cpp:141] Setting up relu5_3c
I0630 00:43:39.728627 20971 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0630 00:43:39.728629 20971 net.cpp:156] Memory required for data: 1560113152
I0630 00:43:39.728632 20971 layer_factory.hpp:77] Creating layer conv1_1m
I0630 00:43:39.728638 20971 net.cpp:91] Creating Layer conv1_1m
I0630 00:43:39.728641 20971 net.cpp:425] conv1_1m <- masked_im
I0630 00:43:39.728646 20971 net.cpp:399] conv1_1m -> conv1_1m
I0630 00:43:39.729729 20971 net.cpp:141] Setting up conv1_1m
I0630 00:43:39.729750 20971 net.cpp:148] Top shape: 4 64 392 392 (39337984)
I0630 00:43:39.729754 20971 net.cpp:156] Memory required for data: 1717465088
I0630 00:43:39.729760 20971 net.cpp:484] Sharing parameters 'conv1_1_w' owned by layer 'conv1_1c', param index 0
I0630 00:43:39.729766 20971 net.cpp:484] Sharing parameters 'conv1_1_b' owned by layer 'conv1_1c', param index 1
I0630 00:43:39.729776 20971 layer_factory.hpp:77] Creating layer relu1_1m
I0630 00:43:39.729794 20971 net.cpp:91] Creating Layer relu1_1m
I0630 00:43:39.729800 20971 net.cpp:425] relu1_1m <- conv1_1m
I0630 00:43:39.729806 20971 net.cpp:386] relu1_1m -> conv1_1m (in-place)
I0630 00:43:39.730036 20971 net.cpp:141] Setting up relu1_1m
I0630 00:43:39.730044 20971 net.cpp:148] Top shape: 4 64 392 392 (39337984)
I0630 00:43:39.730048 20971 net.cpp:156] Memory required for data: 1874817024
I0630 00:43:39.730051 20971 layer_factory.hpp:77] Creating layer conv1_2m
I0630 00:43:39.730063 20971 net.cpp:91] Creating Layer conv1_2m
I0630 00:43:39.730067 20971 net.cpp:425] conv1_2m <- conv1_1m
I0630 00:43:39.730077 20971 net.cpp:399] conv1_2m -> conv1_2m
I0630 00:43:39.731317 20971 net.cpp:141] Setting up conv1_2m
I0630 00:43:39.731326 20971 net.cpp:148] Top shape: 4 64 392 392 (39337984)
I0630 00:43:39.731330 20971 net.cpp:156] Memory required for data: 2032168960
I0630 00:43:39.731333 20971 net.cpp:484] Sharing parameters 'conv1_2_w' owned by layer 'conv1_2c', param index 0
I0630 00:43:39.731335 20971 net.cpp:484] Sharing parameters 'conv1_2_b' owned by layer 'conv1_2c', param index 1
I0630 00:43:39.731350 20971 layer_factory.hpp:77] Creating layer relu1_2m
I0630 00:43:39.731360 20971 net.cpp:91] Creating Layer relu1_2m
I0630 00:43:39.731364 20971 net.cpp:425] relu1_2m <- conv1_2m
I0630 00:43:39.731366 20971 net.cpp:386] relu1_2m -> conv1_2m (in-place)
I0630 00:43:39.731559 20971 net.cpp:141] Setting up relu1_2m
I0630 00:43:39.731566 20971 net.cpp:148] Top shape: 4 64 392 392 (39337984)
I0630 00:43:39.731569 20971 net.cpp:156] Memory required for data: 2189520896
I0630 00:43:39.731570 20971 layer_factory.hpp:77] Creating layer pool1m
I0630 00:43:39.731580 20971 net.cpp:91] Creating Layer pool1m
I0630 00:43:39.731581 20971 net.cpp:425] pool1m <- conv1_2m
I0630 00:43:39.731585 20971 net.cpp:399] pool1m -> pool1m
I0630 00:43:39.731616 20971 net.cpp:141] Setting up pool1m
I0630 00:43:39.731621 20971 net.cpp:148] Top shape: 4 64 196 196 (9834496)
I0630 00:43:39.731623 20971 net.cpp:156] Memory required for data: 2228858880
I0630 00:43:39.731626 20971 layer_factory.hpp:77] Creating layer conv2_1m
I0630 00:43:39.731632 20971 net.cpp:91] Creating Layer conv2_1m
I0630 00:43:39.731634 20971 net.cpp:425] conv2_1m <- pool1m
I0630 00:43:39.731638 20971 net.cpp:399] conv2_1m -> conv2_1m
I0630 00:43:39.732326 20971 net.cpp:141] Setting up conv2_1m
I0630 00:43:39.732333 20971 net.cpp:148] Top shape: 4 128 196 196 (19668992)
I0630 00:43:39.732336 20971 net.cpp:156] Memory required for data: 2307534848
I0630 00:43:39.732338 20971 net.cpp:484] Sharing parameters 'conv2_1_w' owned by layer 'conv2_1c', param index 0
I0630 00:43:39.732342 20971 net.cpp:484] Sharing parameters 'conv2_1_b' owned by layer 'conv2_1c', param index 1
I0630 00:43:39.732343 20971 layer_factory.hpp:77] Creating layer relu2_1m
I0630 00:43:39.732348 20971 net.cpp:91] Creating Layer relu2_1m
I0630 00:43:39.732350 20971 net.cpp:425] relu2_1m <- conv2_1m
I0630 00:43:39.732353 20971 net.cpp:386] relu2_1m -> conv2_1m (in-place)
I0630 00:43:39.732462 20971 net.cpp:141] Setting up relu2_1m
I0630 00:43:39.732467 20971 net.cpp:148] Top shape: 4 128 196 196 (19668992)
I0630 00:43:39.732470 20971 net.cpp:156] Memory required for data: 2386210816
I0630 00:43:39.732471 20971 layer_factory.hpp:77] Creating layer conv2_2m
I0630 00:43:39.732478 20971 net.cpp:91] Creating Layer conv2_2m
I0630 00:43:39.732481 20971 net.cpp:425] conv2_2m <- conv2_1m
I0630 00:43:39.732486 20971 net.cpp:399] conv2_2m -> conv2_2m
I0630 00:43:39.733974 20971 net.cpp:141] Setting up conv2_2m
I0630 00:43:39.734033 20971 net.cpp:148] Top shape: 4 128 196 196 (19668992)
I0630 00:43:39.734042 20971 net.cpp:156] Memory required for data: 2464886784
I0630 00:43:39.734066 20971 net.cpp:484] Sharing parameters 'conv2_2_w' owned by layer 'conv2_2c', param index 0
I0630 00:43:39.734076 20971 net.cpp:484] Sharing parameters 'conv2_2_b' owned by layer 'conv2_2c', param index 1
I0630 00:43:39.734082 20971 layer_factory.hpp:77] Creating layer relu2_2m
I0630 00:43:39.734100 20971 net.cpp:91] Creating Layer relu2_2m
I0630 00:43:39.734107 20971 net.cpp:425] relu2_2m <- conv2_2m
I0630 00:43:39.734122 20971 net.cpp:386] relu2_2m -> conv2_2m (in-place)
I0630 00:43:39.734354 20971 net.cpp:141] Setting up relu2_2m
I0630 00:43:39.734365 20971 net.cpp:148] Top shape: 4 128 196 196 (19668992)
I0630 00:43:39.734369 20971 net.cpp:156] Memory required for data: 2543562752
I0630 00:43:39.734378 20971 layer_factory.hpp:77] Creating layer pool2m
I0630 00:43:39.734395 20971 net.cpp:91] Creating Layer pool2m
I0630 00:43:39.734401 20971 net.cpp:425] pool2m <- conv2_2m
I0630 00:43:39.734407 20971 net.cpp:399] pool2m -> pool2m
I0630 00:43:39.734508 20971 net.cpp:141] Setting up pool2m
I0630 00:43:39.734518 20971 net.cpp:148] Top shape: 4 128 98 98 (4917248)
I0630 00:43:39.734521 20971 net.cpp:156] Memory required for data: 2563231744
I0630 00:43:39.734524 20971 layer_factory.hpp:77] Creating layer conv3_1m
I0630 00:43:39.734539 20971 net.cpp:91] Creating Layer conv3_1m
I0630 00:43:39.734544 20971 net.cpp:425] conv3_1m <- pool2m
I0630 00:43:39.734551 20971 net.cpp:399] conv3_1m -> conv3_1m
I0630 00:43:39.736706 20971 net.cpp:141] Setting up conv3_1m
I0630 00:43:39.736745 20971 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0630 00:43:39.736749 20971 net.cpp:156] Memory required for data: 2602569728
I0630 00:43:39.736757 20971 net.cpp:484] Sharing parameters 'conv3_1_w' owned by layer 'conv3_1c', param index 0
I0630 00:43:39.736763 20971 net.cpp:484] Sharing parameters 'conv3_1_b' owned by layer 'conv3_1c', param index 1
I0630 00:43:39.736764 20971 layer_factory.hpp:77] Creating layer relu3_1m
I0630 00:43:39.736793 20971 net.cpp:91] Creating Layer relu3_1m
I0630 00:43:39.736799 20971 net.cpp:425] relu3_1m <- conv3_1m
I0630 00:43:39.736804 20971 net.cpp:386] relu3_1m -> conv3_1m (in-place)
I0630 00:43:39.737388 20971 net.cpp:141] Setting up relu3_1m
I0630 00:43:39.737416 20971 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0630 00:43:39.737421 20971 net.cpp:156] Memory required for data: 2641907712
I0630 00:43:39.737426 20971 layer_factory.hpp:77] Creating layer conv3_2m
I0630 00:43:39.737444 20971 net.cpp:91] Creating Layer conv3_2m
I0630 00:43:39.737452 20971 net.cpp:425] conv3_2m <- conv3_1m
I0630 00:43:39.737464 20971 net.cpp:399] conv3_2m -> conv3_2m
I0630 00:43:39.740454 20971 net.cpp:141] Setting up conv3_2m
I0630 00:43:39.740485 20971 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0630 00:43:39.740488 20971 net.cpp:156] Memory required for data: 2681245696
I0630 00:43:39.740494 20971 net.cpp:484] Sharing parameters 'conv3_2_w' owned by layer 'conv3_2c', param index 0
I0630 00:43:39.740497 20971 net.cpp:484] Sharing parameters 'conv3_2_b' owned by layer 'conv3_2c', param index 1
I0630 00:43:39.740504 20971 layer_factory.hpp:77] Creating layer relu3_2m
I0630 00:43:39.740515 20971 net.cpp:91] Creating Layer relu3_2m
I0630 00:43:39.740520 20971 net.cpp:425] relu3_2m <- conv3_2m
I0630 00:43:39.740526 20971 net.cpp:386] relu3_2m -> conv3_2m (in-place)
I0630 00:43:39.740649 20971 net.cpp:141] Setting up relu3_2m
I0630 00:43:39.740656 20971 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0630 00:43:39.740658 20971 net.cpp:156] Memory required for data: 2720583680
I0630 00:43:39.740660 20971 layer_factory.hpp:77] Creating layer conv3_3m
I0630 00:43:39.740670 20971 net.cpp:91] Creating Layer conv3_3m
I0630 00:43:39.740674 20971 net.cpp:425] conv3_3m <- conv3_2m
I0630 00:43:39.740679 20971 net.cpp:399] conv3_3m -> conv3_3m
I0630 00:43:39.742524 20971 net.cpp:141] Setting up conv3_3m
I0630 00:43:39.742538 20971 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0630 00:43:39.742542 20971 net.cpp:156] Memory required for data: 2759921664
I0630 00:43:39.742545 20971 net.cpp:484] Sharing parameters 'conv3_3_w' owned by layer 'conv3_3c', param index 0
I0630 00:43:39.742549 20971 net.cpp:484] Sharing parameters 'conv3_3_b' owned by layer 'conv3_3c', param index 1
I0630 00:43:39.742552 20971 layer_factory.hpp:77] Creating layer relu3_3m
I0630 00:43:39.742558 20971 net.cpp:91] Creating Layer relu3_3m
I0630 00:43:39.742560 20971 net.cpp:425] relu3_3m <- conv3_3m
I0630 00:43:39.742565 20971 net.cpp:386] relu3_3m -> conv3_3m (in-place)
I0630 00:43:39.742687 20971 net.cpp:141] Setting up relu3_3m
I0630 00:43:39.742698 20971 net.cpp:148] Top shape: 4 256 98 98 (9834496)
I0630 00:43:39.742702 20971 net.cpp:156] Memory required for data: 2799259648
I0630 00:43:39.742703 20971 layer_factory.hpp:77] Creating layer pool3m
I0630 00:43:39.742713 20971 net.cpp:91] Creating Layer pool3m
I0630 00:43:39.742717 20971 net.cpp:425] pool3m <- conv3_3m
I0630 00:43:39.742720 20971 net.cpp:399] pool3m -> pool3m
I0630 00:43:39.742761 20971 net.cpp:141] Setting up pool3m
I0630 00:43:39.742766 20971 net.cpp:148] Top shape: 4 256 49 49 (2458624)
I0630 00:43:39.742769 20971 net.cpp:156] Memory required for data: 2809094144
I0630 00:43:39.742774 20971 layer_factory.hpp:77] Creating layer conv4_1m
I0630 00:43:39.742784 20971 net.cpp:91] Creating Layer conv4_1m
I0630 00:43:39.742785 20971 net.cpp:425] conv4_1m <- pool3m
I0630 00:43:39.742789 20971 net.cpp:399] conv4_1m -> conv4_1m
I0630 00:43:39.745565 20971 net.cpp:141] Setting up conv4_1m
I0630 00:43:39.745595 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.745599 20971 net.cpp:156] Memory required for data: 2828763136
I0630 00:43:39.745602 20971 net.cpp:484] Sharing parameters 'conv4_1_w' owned by layer 'conv4_1c', param index 0
I0630 00:43:39.745605 20971 net.cpp:484] Sharing parameters 'conv4_1_b' owned by layer 'conv4_1c', param index 1
I0630 00:43:39.745609 20971 layer_factory.hpp:77] Creating layer relu4_1m
I0630 00:43:39.745614 20971 net.cpp:91] Creating Layer relu4_1m
I0630 00:43:39.745616 20971 net.cpp:425] relu4_1m <- conv4_1m
I0630 00:43:39.745625 20971 net.cpp:386] relu4_1m -> conv4_1m (in-place)
I0630 00:43:39.745823 20971 net.cpp:141] Setting up relu4_1m
I0630 00:43:39.745831 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.745833 20971 net.cpp:156] Memory required for data: 2848432128
I0630 00:43:39.745836 20971 layer_factory.hpp:77] Creating layer conv4_2m
I0630 00:43:39.745841 20971 net.cpp:91] Creating Layer conv4_2m
I0630 00:43:39.745846 20971 net.cpp:425] conv4_2m <- conv4_1m
I0630 00:43:39.745849 20971 net.cpp:399] conv4_2m -> conv4_2m
I0630 00:43:39.753244 20971 net.cpp:141] Setting up conv4_2m
I0630 00:43:39.753387 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.753412 20971 net.cpp:156] Memory required for data: 2868101120
I0630 00:43:39.753446 20971 net.cpp:484] Sharing parameters 'conv4_2_w' owned by layer 'conv4_2c', param index 0
I0630 00:43:39.753465 20971 net.cpp:484] Sharing parameters 'conv4_2_b' owned by layer 'conv4_2c', param index 1
I0630 00:43:39.753492 20971 layer_factory.hpp:77] Creating layer relu4_2m
I0630 00:43:39.753525 20971 net.cpp:91] Creating Layer relu4_2m
I0630 00:43:39.753543 20971 net.cpp:425] relu4_2m <- conv4_2m
I0630 00:43:39.753563 20971 net.cpp:386] relu4_2m -> conv4_2m (in-place)
I0630 00:43:39.753844 20971 net.cpp:141] Setting up relu4_2m
I0630 00:43:39.753872 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.753887 20971 net.cpp:156] Memory required for data: 2887770112
I0630 00:43:39.753906 20971 layer_factory.hpp:77] Creating layer conv4_3m
I0630 00:43:39.753936 20971 net.cpp:91] Creating Layer conv4_3m
I0630 00:43:39.753957 20971 net.cpp:425] conv4_3m <- conv4_2m
I0630 00:43:39.753975 20971 net.cpp:399] conv4_3m -> conv4_3m
I0630 00:43:39.759976 20971 net.cpp:141] Setting up conv4_3m
I0630 00:43:39.759994 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.759997 20971 net.cpp:156] Memory required for data: 2907439104
I0630 00:43:39.760002 20971 net.cpp:484] Sharing parameters 'conv4_3_w' owned by layer 'conv4_3c', param index 0
I0630 00:43:39.760005 20971 net.cpp:484] Sharing parameters 'conv4_3_b' owned by layer 'conv4_3c', param index 1
I0630 00:43:39.760007 20971 layer_factory.hpp:77] Creating layer relu4_3m
I0630 00:43:39.760015 20971 net.cpp:91] Creating Layer relu4_3m
I0630 00:43:39.760017 20971 net.cpp:425] relu4_3m <- conv4_3m
I0630 00:43:39.760022 20971 net.cpp:386] relu4_3m -> conv4_3m (in-place)
I0630 00:43:39.760222 20971 net.cpp:141] Setting up relu4_3m
I0630 00:43:39.760231 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.760234 20971 net.cpp:156] Memory required for data: 2927108096
I0630 00:43:39.760236 20971 layer_factory.hpp:77] Creating layer conv5_1m
I0630 00:43:39.760244 20971 net.cpp:91] Creating Layer conv5_1m
I0630 00:43:39.760248 20971 net.cpp:425] conv5_1m <- conv4_3m
I0630 00:43:39.760252 20971 net.cpp:399] conv5_1m -> conv5_1m
I0630 00:43:39.767164 20971 net.cpp:141] Setting up conv5_1m
I0630 00:43:39.767201 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.767206 20971 net.cpp:156] Memory required for data: 2946777088
I0630 00:43:39.767215 20971 net.cpp:484] Sharing parameters 'conv5_1_w' owned by layer 'conv5_1c', param index 0
I0630 00:43:39.767221 20971 net.cpp:484] Sharing parameters 'conv5_1_b' owned by layer 'conv5_1c', param index 1
I0630 00:43:39.767226 20971 layer_factory.hpp:77] Creating layer relu5_1m
I0630 00:43:39.767241 20971 net.cpp:91] Creating Layer relu5_1m
I0630 00:43:39.767247 20971 net.cpp:425] relu5_1m <- conv5_1m
I0630 00:43:39.767277 20971 net.cpp:386] relu5_1m -> conv5_1m (in-place)
I0630 00:43:39.767829 20971 net.cpp:141] Setting up relu5_1m
I0630 00:43:39.767855 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.767859 20971 net.cpp:156] Memory required for data: 2966446080
I0630 00:43:39.767868 20971 layer_factory.hpp:77] Creating layer conv5_2m
I0630 00:43:39.767882 20971 net.cpp:91] Creating Layer conv5_2m
I0630 00:43:39.767889 20971 net.cpp:425] conv5_2m <- conv5_1m
I0630 00:43:39.767899 20971 net.cpp:399] conv5_2m -> conv5_2m
I0630 00:43:39.775903 20971 net.cpp:141] Setting up conv5_2m
I0630 00:43:39.775944 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.775949 20971 net.cpp:156] Memory required for data: 2986115072
I0630 00:43:39.775956 20971 net.cpp:484] Sharing parameters 'conv5_2_w' owned by layer 'conv5_2c', param index 0
I0630 00:43:39.775961 20971 net.cpp:484] Sharing parameters 'conv5_2_b' owned by layer 'conv5_2c', param index 1
I0630 00:43:39.775966 20971 layer_factory.hpp:77] Creating layer relu5_2m
I0630 00:43:39.775979 20971 net.cpp:91] Creating Layer relu5_2m
I0630 00:43:39.775985 20971 net.cpp:425] relu5_2m <- conv5_2m
I0630 00:43:39.775991 20971 net.cpp:386] relu5_2m -> conv5_2m (in-place)
I0630 00:43:39.776252 20971 net.cpp:141] Setting up relu5_2m
I0630 00:43:39.776262 20971 net.cpp:148] Top shape: 4 512 49 49 (4917248)
I0630 00:43:39.776265 20971 net.cpp:156] Memory required for data: 3005784064
I0630 00:43:39.776268 20971 layer_factory.hpp:77] Creating layer conv5_3m
I0630 00:43:39.776283 20971 net.cpp:91] Creating Layer conv5_3m
I0630 00:43:39.776288 20971 net.cpp:425] conv5_3m <- conv5_2m
I0630 00:43:39.776293 20971 net.cpp:399] conv5_3m -> conv5_3m
I0630 00:43:39.779695 20971 net.cpp:141] Setting up conv5_3m
I0630 00:43:39.779726 20971 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0630 00:43:39.779729 20971 net.cpp:156] Memory required for data: 3049439232
I0630 00:43:39.779736 20971 net.cpp:484] Sharing parameters 'conv5_3_w' owned by layer 'conv5_3c', param index 0
I0630 00:43:39.779739 20971 net.cpp:484] Sharing parameters 'conv5_3_b' owned by layer 'conv5_3c', param index 1
I0630 00:43:39.779742 20971 layer_factory.hpp:77] Creating layer relu5_3m
I0630 00:43:39.779752 20971 net.cpp:91] Creating Layer relu5_3m
I0630 00:43:39.779755 20971 net.cpp:425] relu5_3m <- conv5_3m
I0630 00:43:39.779760 20971 net.cpp:386] relu5_3m -> conv5_3m (in-place)
I0630 00:43:39.780201 20971 net.cpp:141] Setting up relu5_3m
I0630 00:43:39.780210 20971 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0630 00:43:39.780213 20971 net.cpp:156] Memory required for data: 3093094400
I0630 00:43:39.780218 20971 layer_factory.hpp:77] Creating layer conv1_1n
I0630 00:43:39.780227 20971 net.cpp:91] Creating Layer conv1_1n
I0630 00:43:39.780230 20971 net.cpp:425] conv1_1n <- next_im_cur_im_2_split_0
I0630 00:43:39.780236 20971 net.cpp:399] conv1_1n -> conv1_1n
I0630 00:43:39.781863 20971 net.cpp:141] Setting up conv1_1n
I0630 00:43:39.781896 20971 net.cpp:148] Top shape: 4 64 584 584 (87310336)
I0630 00:43:39.781899 20971 net.cpp:156] Memory required for data: 3442335744
I0630 00:43:39.781908 20971 net.cpp:484] Sharing parameters 'conv1_1_w' owned by layer 'conv1_1c', param index 0
I0630 00:43:39.781914 20971 net.cpp:484] Sharing parameters 'conv1_1_b' owned by layer 'conv1_1c', param index 1
I0630 00:43:39.781919 20971 layer_factory.hpp:77] Creating layer relu1_1n
I0630 00:43:39.781939 20971 net.cpp:91] Creating Layer relu1_1n
I0630 00:43:39.781955 20971 net.cpp:425] relu1_1n <- conv1_1n
I0630 00:43:39.781963 20971 net.cpp:386] relu1_1n -> conv1_1n (in-place)
I0630 00:43:39.782253 20971 net.cpp:141] Setting up relu1_1n
I0630 00:43:39.782263 20971 net.cpp:148] Top shape: 4 64 584 584 (87310336)
I0630 00:43:39.782265 20971 net.cpp:156] Memory required for data: 3791577088
I0630 00:43:39.782269 20971 layer_factory.hpp:77] Creating layer conv1_2n
I0630 00:43:39.782282 20971 net.cpp:91] Creating Layer conv1_2n
I0630 00:43:39.782286 20971 net.cpp:425] conv1_2n <- conv1_1n
I0630 00:43:39.782515 20971 net.cpp:399] conv1_2n -> conv1_2n
I0630 00:43:39.785460 20971 net.cpp:141] Setting up conv1_2n
I0630 00:43:39.785509 20971 net.cpp:148] Top shape: 4 64 584 584 (87310336)
I0630 00:43:39.785514 20971 net.cpp:156] Memory required for data: 4140818432
I0630 00:43:39.785538 20971 net.cpp:484] Sharing parameters 'conv1_2_w' owned by layer 'conv1_2c', param index 0
I0630 00:43:39.785547 20971 net.cpp:484] Sharing parameters 'conv1_2_b' owned by layer 'conv1_2c', param index 1
I0630 00:43:39.785552 20971 layer_factory.hpp:77] Creating layer relu1_2n
I0630 00:43:39.785578 20971 net.cpp:91] Creating Layer relu1_2n
I0630 00:43:39.785583 20971 net.cpp:425] relu1_2n <- conv1_2n
I0630 00:43:39.785594 20971 net.cpp:386] relu1_2n -> conv1_2n (in-place)
I0630 00:43:39.786133 20971 net.cpp:141] Setting up relu1_2n
I0630 00:43:39.786161 20971 net.cpp:148] Top shape: 4 64 584 584 (87310336)
I0630 00:43:39.786165 20971 net.cpp:156] Memory required for data: 4490059776
I0630 00:43:39.786178 20971 layer_factory.hpp:77] Creating layer pool1n
I0630 00:43:39.786221 20971 net.cpp:91] Creating Layer pool1n
I0630 00:43:39.786231 20971 net.cpp:425] pool1n <- conv1_2n
I0630 00:43:39.786242 20971 net.cpp:399] pool1n -> pool1n
I0630 00:43:39.786380 20971 net.cpp:141] Setting up pool1n
I0630 00:43:39.786386 20971 net.cpp:148] Top shape: 4 64 292 292 (21827584)
I0630 00:43:39.786389 20971 net.cpp:156] Memory required for data: 4577370112
I0630 00:43:39.786393 20971 layer_factory.hpp:77] Creating layer conv2_1n
I0630 00:43:39.786409 20971 net.cpp:91] Creating Layer conv2_1n
I0630 00:43:39.786414 20971 net.cpp:425] conv2_1n <- pool1n
I0630 00:43:39.786422 20971 net.cpp:399] conv2_1n -> conv2_1n
I0630 00:43:39.787765 20971 net.cpp:141] Setting up conv2_1n
I0630 00:43:39.787781 20971 net.cpp:148] Top shape: 4 128 292 292 (43655168)
I0630 00:43:39.787783 20971 net.cpp:156] Memory required for data: 4751990784
I0630 00:43:39.787791 20971 net.cpp:484] Sharing parameters 'conv2_1_w' owned by layer 'conv2_1c', param index 0
I0630 00:43:39.787796 20971 net.cpp:484] Sharing parameters 'conv2_1_b' owned by layer 'conv2_1c', param index 1
I0630 00:43:39.787801 20971 layer_factory.hpp:77] Creating layer relu2_1n
I0630 00:43:39.787809 20971 net.cpp:91] Creating Layer relu2_1n
I0630 00:43:39.787812 20971 net.cpp:425] relu2_1n <- conv2_1n
I0630 00:43:39.787817 20971 net.cpp:386] relu2_1n -> conv2_1n (in-place)
I0630 00:43:39.788156 20971 net.cpp:141] Setting up relu2_1n
I0630 00:43:39.788166 20971 net.cpp:148] Top shape: 4 128 292 292 (43655168)
I0630 00:43:39.788170 20971 net.cpp:156] Memory required for data: 4926611456
I0630 00:43:39.788177 20971 layer_factory.hpp:77] Creating layer conv2_2n
I0630 00:43:39.788192 20971 net.cpp:91] Creating Layer conv2_2n
I0630 00:43:39.788197 20971 net.cpp:425] conv2_2n <- conv2_1n
I0630 00:43:39.788204 20971 net.cpp:399] conv2_2n -> conv2_2n
I0630 00:43:39.790071 20971 net.cpp:141] Setting up conv2_2n
I0630 00:43:39.790112 20971 net.cpp:148] Top shape: 4 128 292 292 (43655168)
I0630 00:43:39.790117 20971 net.cpp:156] Memory required for data: 5101232128
I0630 00:43:39.790125 20971 net.cpp:484] Sharing parameters 'conv2_2_w' owned by layer 'conv2_2c', param index 0
I0630 00:43:39.790132 20971 net.cpp:484] Sharing parameters 'conv2_2_b' owned by layer 'conv2_2c', param index 1
I0630 00:43:39.790138 20971 layer_factory.hpp:77] Creating layer relu2_2n
I0630 00:43:39.790149 20971 net.cpp:91] Creating Layer relu2_2n
I0630 00:43:39.790156 20971 net.cpp:425] relu2_2n <- conv2_2n
I0630 00:43:39.790187 20971 net.cpp:386] relu2_2n -> conv2_2n (in-place)
I0630 00:43:39.790347 20971 net.cpp:141] Setting up relu2_2n
I0630 00:43:39.790357 20971 net.cpp:148] Top shape: 4 128 292 292 (43655168)
I0630 00:43:39.790362 20971 net.cpp:156] Memory required for data: 5275852800
I0630 00:43:39.790367 20971 layer_factory.hpp:77] Creating layer pool2n
I0630 00:43:39.790377 20971 net.cpp:91] Creating Layer pool2n
I0630 00:43:39.790380 20971 net.cpp:425] pool2n <- conv2_2n
I0630 00:43:39.790386 20971 net.cpp:399] pool2n -> pool2n
I0630 00:43:39.790490 20971 net.cpp:141] Setting up pool2n
I0630 00:43:39.790498 20971 net.cpp:148] Top shape: 4 128 146 146 (10913792)
I0630 00:43:39.790500 20971 net.cpp:156] Memory required for data: 5319507968
I0630 00:43:39.790503 20971 layer_factory.hpp:77] Creating layer conv3_1n
I0630 00:43:39.790516 20971 net.cpp:91] Creating Layer conv3_1n
I0630 00:43:39.790520 20971 net.cpp:425] conv3_1n <- pool2n
I0630 00:43:39.790527 20971 net.cpp:399] conv3_1n -> conv3_1n
I0630 00:43:39.792655 20971 net.cpp:141] Setting up conv3_1n
I0630 00:43:39.792698 20971 net.cpp:148] Top shape: 4 256 146 146 (21827584)
I0630 00:43:39.792702 20971 net.cpp:156] Memory required for data: 5406818304
I0630 00:43:39.792711 20971 net.cpp:484] Sharing parameters 'conv3_1_w' owned by layer 'conv3_1c', param index 0
I0630 00:43:39.792719 20971 net.cpp:484] Sharing parameters 'conv3_1_b' owned by layer 'conv3_1c', param index 1
I0630 00:43:39.792726 20971 layer_factory.hpp:77] Creating layer relu3_1n
I0630 00:43:39.792743 20971 net.cpp:91] Creating Layer relu3_1n
I0630 00:43:39.792750 20971 net.cpp:425] relu3_1n <- conv3_1n
I0630 00:43:39.792767 20971 net.cpp:386] relu3_1n -> conv3_1n (in-place)
I0630 00:43:39.793097 20971 net.cpp:141] Setting up relu3_1n
I0630 00:43:39.793107 20971 net.cpp:148] Top shape: 4 256 146 146 (21827584)
I0630 00:43:39.793110 20971 net.cpp:156] Memory required for data: 5494128640
I0630 00:43:39.793118 20971 layer_factory.hpp:77] Creating layer conv3_2n
I0630 00:43:39.793136 20971 net.cpp:91] Creating Layer conv3_2n
I0630 00:43:39.793140 20971 net.cpp:425] conv3_2n <- conv3_1n
I0630 00:43:39.793148 20971 net.cpp:399] conv3_2n -> conv3_2n
I0630 00:43:39.796093 20971 net.cpp:141] Setting up conv3_2n
I0630 00:43:39.796140 20971 net.cpp:148] Top shape: 4 256 146 146 (21827584)
I0630 00:43:39.796145 20971 net.cpp:156] Memory required for data: 5581438976
I0630 00:43:39.796154 20971 net.cpp:484] Sharing parameters 'conv3_2_w' owned by layer 'conv3_2c', param index 0
I0630 00:43:39.796160 20971 net.cpp:484] Sharing parameters 'conv3_2_b' owned by layer 'conv3_2c', param index 1
I0630 00:43:39.796165 20971 layer_factory.hpp:77] Creating layer relu3_2n
I0630 00:43:39.796178 20971 net.cpp:91] Creating Layer relu3_2n
I0630 00:43:39.796183 20971 net.cpp:425] relu3_2n <- conv3_2n
I0630 00:43:39.796193 20971 net.cpp:386] relu3_2n -> conv3_2n (in-place)
I0630 00:43:39.796541 20971 net.cpp:141] Setting up relu3_2n
I0630 00:43:39.796555 20971 net.cpp:148] Top shape: 4 256 146 146 (21827584)
I0630 00:43:39.796558 20971 net.cpp:156] Memory required for data: 5668749312
I0630 00:43:39.796562 20971 layer_factory.hpp:77] Creating layer conv3_3n
I0630 00:43:39.796577 20971 net.cpp:91] Creating Layer conv3_3n
I0630 00:43:39.796582 20971 net.cpp:425] conv3_3n <- conv3_2n
I0630 00:43:39.796596 20971 net.cpp:399] conv3_3n -> conv3_3n
I0630 00:43:39.799873 20971 net.cpp:141] Setting up conv3_3n
I0630 00:43:39.799923 20971 net.cpp:148] Top shape: 4 256 146 146 (21827584)
I0630 00:43:39.799928 20971 net.cpp:156] Memory required for data: 5756059648
I0630 00:43:39.799962 20971 net.cpp:484] Sharing parameters 'conv3_3_w' owned by layer 'conv3_3c', param index 0
I0630 00:43:39.799969 20971 net.cpp:484] Sharing parameters 'conv3_3_b' owned by layer 'conv3_3c', param index 1
I0630 00:43:39.799978 20971 layer_factory.hpp:77] Creating layer relu3_3n
I0630 00:43:39.799988 20971 net.cpp:91] Creating Layer relu3_3n
I0630 00:43:39.799993 20971 net.cpp:425] relu3_3n <- conv3_3n
I0630 00:43:39.800001 20971 net.cpp:386] relu3_3n -> conv3_3n (in-place)
I0630 00:43:39.800200 20971 net.cpp:141] Setting up relu3_3n
I0630 00:43:39.800215 20971 net.cpp:148] Top shape: 4 256 146 146 (21827584)
I0630 00:43:39.800217 20971 net.cpp:156] Memory required for data: 5843369984
I0630 00:43:39.800222 20971 layer_factory.hpp:77] Creating layer pool3n
I0630 00:43:39.800235 20971 net.cpp:91] Creating Layer pool3n
I0630 00:43:39.800238 20971 net.cpp:425] pool3n <- conv3_3n
I0630 00:43:39.800245 20971 net.cpp:399] pool3n -> pool3n
I0630 00:43:39.800307 20971 net.cpp:141] Setting up pool3n
I0630 00:43:39.800331 20971 net.cpp:148] Top shape: 4 256 73 73 (5456896)
I0630 00:43:39.800336 20971 net.cpp:156] Memory required for data: 5865197568
I0630 00:43:39.800339 20971 layer_factory.hpp:77] Creating layer conv4_1n
I0630 00:43:39.800350 20971 net.cpp:91] Creating Layer conv4_1n
I0630 00:43:39.800354 20971 net.cpp:425] conv4_1n <- pool3n
I0630 00:43:39.800361 20971 net.cpp:399] conv4_1n -> conv4_1n
I0630 00:43:39.805564 20971 net.cpp:141] Setting up conv4_1n
I0630 00:43:39.805641 20971 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0630 00:43:39.805649 20971 net.cpp:156] Memory required for data: 5908852736
I0630 00:43:39.805662 20971 net.cpp:484] Sharing parameters 'conv4_1_w' owned by layer 'conv4_1c', param index 0
I0630 00:43:39.805672 20971 net.cpp:484] Sharing parameters 'conv4_1_b' owned by layer 'conv4_1c', param index 1
I0630 00:43:39.805680 20971 layer_factory.hpp:77] Creating layer relu4_1n
I0630 00:43:39.805701 20971 net.cpp:91] Creating Layer relu4_1n
I0630 00:43:39.805711 20971 net.cpp:425] relu4_1n <- conv4_1n
I0630 00:43:39.805724 20971 net.cpp:386] relu4_1n -> conv4_1n (in-place)
I0630 00:43:39.806159 20971 net.cpp:141] Setting up relu4_1n
I0630 00:43:39.806172 20971 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0630 00:43:39.806175 20971 net.cpp:156] Memory required for data: 5952507904
I0630 00:43:39.806185 20971 layer_factory.hpp:77] Creating layer conv4_2n
I0630 00:43:39.806202 20971 net.cpp:91] Creating Layer conv4_2n
I0630 00:43:39.806206 20971 net.cpp:425] conv4_2n <- conv4_1n
I0630 00:43:39.806213 20971 net.cpp:399] conv4_2n -> conv4_2n
I0630 00:43:39.817153 20971 net.cpp:141] Setting up conv4_2n
I0630 00:43:39.817200 20971 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0630 00:43:39.817205 20971 net.cpp:156] Memory required for data: 5996163072
I0630 00:43:39.817216 20971 net.cpp:484] Sharing parameters 'conv4_2_w' owned by layer 'conv4_2c', param index 0
I0630 00:43:39.817224 20971 net.cpp:484] Sharing parameters 'conv4_2_b' owned by layer 'conv4_2c', param index 1
I0630 00:43:39.817229 20971 layer_factory.hpp:77] Creating layer relu4_2n
I0630 00:43:39.817250 20971 net.cpp:91] Creating Layer relu4_2n
I0630 00:43:39.817257 20971 net.cpp:425] relu4_2n <- conv4_2n
I0630 00:43:39.817268 20971 net.cpp:386] relu4_2n -> conv4_2n (in-place)
I0630 00:43:39.817788 20971 net.cpp:141] Setting up relu4_2n
I0630 00:43:39.817806 20971 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0630 00:43:39.817811 20971 net.cpp:156] Memory required for data: 6039818240
I0630 00:43:39.817816 20971 layer_factory.hpp:77] Creating layer conv4_3n
I0630 00:43:39.817831 20971 net.cpp:91] Creating Layer conv4_3n
I0630 00:43:39.817836 20971 net.cpp:425] conv4_3n <- conv4_2n
I0630 00:43:39.817844 20971 net.cpp:399] conv4_3n -> conv4_3n
/usr/local/lib/python2.7/dist-packages/skimage/transform/_geometric.py:1312: UserWarning: Bi-quadratic interpolation behavior has changed due to a bug in the implementation of scikit-image. The new version now serves as a wrapper around SciPy's interpolation functions, which itself is not verified to be a correct implementation. Until skimage's implementation is fixed, we recommend to use bi-linear or bi-cubic interpolation instead.
  warnings.warn("Bi-quadratic interpolation behavior has changed due "
I0630 00:43:39.829352 20971 net.cpp:141] Setting up conv4_3n
I0630 00:43:39.829398 20971 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0630 00:43:39.829402 20971 net.cpp:156] Memory required for data: 6083473408
I0630 00:43:39.829421 20971 net.cpp:484] Sharing parameters 'conv4_3_w' owned by layer 'conv4_3c', param index 0
I0630 00:43:39.829427 20971 net.cpp:484] Sharing parameters 'conv4_3_b' owned by layer 'conv4_3c', param index 1
I0630 00:43:39.829432 20971 layer_factory.hpp:77] Creating layer relu4_3n
I0630 00:43:39.829445 20971 net.cpp:91] Creating Layer relu4_3n
I0630 00:43:39.829452 20971 net.cpp:425] relu4_3n <- conv4_3n
I0630 00:43:39.829463 20971 net.cpp:386] relu4_3n -> conv4_3n (in-place)
I0630 00:43:39.829663 20971 net.cpp:141] Setting up relu4_3n
I0630 00:43:39.829686 20971 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0630 00:43:39.829690 20971 net.cpp:156] Memory required for data: 6127128576
I0630 00:43:39.829699 20971 layer_factory.hpp:77] Creating layer conv5_1n
I0630 00:43:39.829715 20971 net.cpp:91] Creating Layer conv5_1n
I0630 00:43:39.829723 20971 net.cpp:425] conv5_1n <- conv4_3n
I0630 00:43:39.829738 20971 net.cpp:399] conv5_1n -> conv5_1n
I0630 00:43:39.834739 20971 net.cpp:141] Setting up conv5_1n
I0630 00:43:39.834758 20971 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0630 00:43:39.834779 20971 net.cpp:156] Memory required for data: 6170783744
I0630 00:43:39.834786 20971 net.cpp:484] Sharing parameters 'conv5_1_w' owned by layer 'conv5_1c', param index 0
I0630 00:43:39.834790 20971 net.cpp:484] Sharing parameters 'conv5_1_b' owned by layer 'conv5_1c', param index 1
I0630 00:43:39.834794 20971 layer_factory.hpp:77] Creating layer relu5_1n
I0630 00:43:39.834801 20971 net.cpp:91] Creating Layer relu5_1n
I0630 00:43:39.834805 20971 net.cpp:425] relu5_1n <- conv5_1n
I0630 00:43:39.834810 20971 net.cpp:386] relu5_1n -> conv5_1n (in-place)
I0630 00:43:39.835108 20971 net.cpp:141] Setting up relu5_1n
I0630 00:43:39.835114 20971 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0630 00:43:39.835116 20971 net.cpp:156] Memory required for data: 6214438912
I0630 00:43:39.835119 20971 layer_factory.hpp:77] Creating layer conv5_2n
I0630 00:43:39.835125 20971 net.cpp:91] Creating Layer conv5_2n
I0630 00:43:39.835129 20971 net.cpp:425] conv5_2n <- conv5_1n
I0630 00:43:39.835132 20971 net.cpp:399] conv5_2n -> conv5_2n
I0630 00:43:39.837976 20971 net.cpp:141] Setting up conv5_2n
I0630 00:43:39.838006 20971 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0630 00:43:39.838011 20971 net.cpp:156] Memory required for data: 6258094080
I0630 00:43:39.838016 20971 net.cpp:484] Sharing parameters 'conv5_2_w' owned by layer 'conv5_2c', param index 0
I0630 00:43:39.838021 20971 net.cpp:484] Sharing parameters 'conv5_2_b' owned by layer 'conv5_2c', param index 1
I0630 00:43:39.838022 20971 layer_factory.hpp:77] Creating layer relu5_2n
I0630 00:43:39.838032 20971 net.cpp:91] Creating Layer relu5_2n
I0630 00:43:39.838035 20971 net.cpp:425] relu5_2n <- conv5_2n
I0630 00:43:39.838039 20971 net.cpp:386] relu5_2n -> conv5_2n (in-place)
I0630 00:43:39.838220 20971 net.cpp:141] Setting up relu5_2n
I0630 00:43:39.838227 20971 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0630 00:43:39.838228 20971 net.cpp:156] Memory required for data: 6301749248
I0630 00:43:39.838232 20971 layer_factory.hpp:77] Creating layer conv5_3n
I0630 00:43:39.838240 20971 net.cpp:91] Creating Layer conv5_3n
I0630 00:43:39.838243 20971 net.cpp:425] conv5_3n <- conv5_2n
I0630 00:43:39.838248 20971 net.cpp:399] conv5_3n -> conv5_3n
I0630 00:43:39.841778 20971 net.cpp:141] Setting up conv5_3n
I0630 00:43:39.841809 20971 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0630 00:43:39.841811 20971 net.cpp:156] Memory required for data: 6345404416
I0630 00:43:39.841815 20971 net.cpp:484] Sharing parameters 'conv5_3_w' owned by layer 'conv5_3c', param index 0
I0630 00:43:39.841819 20971 net.cpp:484] Sharing parameters 'conv5_3_b' owned by layer 'conv5_3c', param index 1
I0630 00:43:39.841821 20971 layer_factory.hpp:77] Creating layer relu5_3n
I0630 00:43:39.841827 20971 net.cpp:91] Creating Layer relu5_3n
I0630 00:43:39.841830 20971 net.cpp:425] relu5_3n <- conv5_3n
I0630 00:43:39.841836 20971 net.cpp:386] relu5_3n -> conv5_3n (in-place)
I0630 00:43:39.842129 20971 net.cpp:141] Setting up relu5_3n
I0630 00:43:39.842136 20971 net.cpp:148] Top shape: 4 512 73 73 (10913792)
I0630 00:43:39.842139 20971 net.cpp:156] Memory required for data: 6389059584
I0630 00:43:39.842141 20971 layer_factory.hpp:77] Creating layer concat1
I0630 00:43:39.842147 20971 net.cpp:91] Creating Layer concat1
I0630 00:43:39.842152 20971 net.cpp:425] concat1 <- conv5_3c
I0630 00:43:39.842155 20971 net.cpp:425] concat1 <- conv5_3m
I0630 00:43:39.842159 20971 net.cpp:425] concat1 <- conv5_3n
I0630 00:43:39.842161 20971 net.cpp:399] concat1 -> concat1
I0630 00:43:39.842186 20971 net.cpp:141] Setting up concat1
I0630 00:43:39.842191 20971 net.cpp:148] Top shape: 4 1536 73 73 (32741376)
I0630 00:43:39.842193 20971 net.cpp:156] Memory required for data: 6520025088
I0630 00:43:39.842195 20971 layer_factory.hpp:77] Creating layer fc6
I0630 00:43:39.842201 20971 net.cpp:91] Creating Layer fc6
I0630 00:43:39.842206 20971 net.cpp:425] fc6 <- concat1
I0630 00:43:39.842211 20971 net.cpp:399] fc6 -> fc6
I0630 00:43:39.970705 20971 net.cpp:141] Setting up fc6
I0630 00:43:39.970798 20971 net.cpp:148] Top shape: 4 1024 49 49 (9834496)
I0630 00:43:39.970804 20971 net.cpp:156] Memory required for data: 6559363072
I0630 00:43:39.970826 20971 layer_factory.hpp:77] Creating layer relu6
I0630 00:43:39.970859 20971 net.cpp:91] Creating Layer relu6
I0630 00:43:39.970866 20971 net.cpp:425] relu6 <- fc6
I0630 00:43:39.970876 20971 net.cpp:386] relu6 -> fc6 (in-place)
I0630 00:43:39.971215 20971 net.cpp:141] Setting up relu6
I0630 00:43:39.971228 20971 net.cpp:148] Top shape: 4 1024 49 49 (9834496)
I0630 00:43:39.971231 20971 net.cpp:156] Memory required for data: 6598701056
I0630 00:43:39.971235 20971 layer_factory.hpp:77] Creating layer drop6
I0630 00:43:39.971253 20971 net.cpp:91] Creating Layer drop6
I0630 00:43:39.971257 20971 net.cpp:425] drop6 <- fc6
I0630 00:43:39.971261 20971 net.cpp:386] drop6 -> fc6 (in-place)
I0630 00:43:39.971314 20971 net.cpp:141] Setting up drop6
I0630 00:43:39.971323 20971 net.cpp:148] Top shape: 4 1024 49 49 (9834496)
I0630 00:43:39.971326 20971 net.cpp:156] Memory required for data: 6638039040
I0630 00:43:39.971330 20971 layer_factory.hpp:77] Creating layer fc7
I0630 00:43:39.971350 20971 net.cpp:91] Creating Layer fc7
I0630 00:43:39.971357 20971 net.cpp:425] fc7 <- fc6
I0630 00:43:39.971371 20971 net.cpp:399] fc7 -> fc7
I0630 00:43:39.975172 20971 net.cpp:141] Setting up fc7
I0630 00:43:39.975211 20971 net.cpp:148] Top shape: 4 1024 49 49 (9834496)
I0630 00:43:39.975215 20971 net.cpp:156] Memory required for data: 6677377024
I0630 00:43:39.975224 20971 layer_factory.hpp:77] Creating layer relu7
I0630 00:43:39.975244 20971 net.cpp:91] Creating Layer relu7
I0630 00:43:39.975249 20971 net.cpp:425] relu7 <- fc7
I0630 00:43:39.975255 20971 net.cpp:386] relu7 -> fc7 (in-place)
I0630 00:43:39.975543 20971 net.cpp:141] Setting up relu7
I0630 00:43:39.975553 20971 net.cpp:148] Top shape: 4 1024 49 49 (9834496)
I0630 00:43:39.975556 20971 net.cpp:156] Memory required for data: 6716715008
I0630 00:43:39.975561 20971 layer_factory.hpp:77] Creating layer drop7
I0630 00:43:39.975569 20971 net.cpp:91] Creating Layer drop7
I0630 00:43:39.975571 20971 net.cpp:425] drop7 <- fc7
I0630 00:43:39.975575 20971 net.cpp:386] drop7 -> fc7 (in-place)
I0630 00:43:39.975603 20971 net.cpp:141] Setting up drop7
I0630 00:43:39.975607 20971 net.cpp:148] Top shape: 4 1024 49 49 (9834496)
I0630 00:43:39.975610 20971 net.cpp:156] Memory required for data: 6756052992
I0630 00:43:39.975613 20971 layer_factory.hpp:77] Creating layer fc8
I0630 00:43:39.975622 20971 net.cpp:91] Creating Layer fc8
I0630 00:43:39.975625 20971 net.cpp:425] fc8 <- fc7
I0630 00:43:39.975630 20971 net.cpp:399] fc8 -> fc8
I0630 00:43:39.976682 20971 net.cpp:141] Setting up fc8
I0630 00:43:39.976692 20971 net.cpp:148] Top shape: 4 2 49 49 (19208)
I0630 00:43:39.976696 20971 net.cpp:156] Memory required for data: 6756129824
I0630 00:43:39.976701 20971 layer_factory.hpp:77] Creating layer upscore
I0630 00:43:39.976716 20971 net.cpp:91] Creating Layer upscore
I0630 00:43:39.976722 20971 net.cpp:425] upscore <- fc8
I0630 00:43:39.976727 20971 net.cpp:399] upscore -> upscore
I0630 00:43:39.976982 20971 net.cpp:141] Setting up upscore
I0630 00:43:39.976990 20971 net.cpp:148] Top shape: 4 2 400 400 (1280000)
I0630 00:43:39.976994 20971 net.cpp:156] Memory required for data: 6761249824
I0630 00:43:39.977000 20971 layer_factory.hpp:77] Creating layer score
I0630 00:43:39.977007 20971 net.cpp:91] Creating Layer score
I0630 00:43:39.977015 20971 net.cpp:425] score <- upscore
I0630 00:43:39.977020 20971 net.cpp:425] score <- next_im_cur_im_2_split_1
I0630 00:43:39.977025 20971 net.cpp:399] score -> score
I0630 00:43:39.977056 20971 net.cpp:141] Setting up score
I0630 00:43:39.977059 20971 net.cpp:148] Top shape: 4 2 384 384 (1179648)
I0630 00:43:39.977062 20971 net.cpp:156] Memory required for data: 6765968416
I0630 00:43:39.977066 20971 layer_factory.hpp:77] Creating layer score_score_0_split
I0630 00:43:39.977071 20971 net.cpp:91] Creating Layer score_score_0_split
I0630 00:43:39.977073 20971 net.cpp:425] score_score_0_split <- score
I0630 00:43:39.977090 20971 net.cpp:399] score_score_0_split -> score_score_0_split_0
I0630 00:43:39.977097 20971 net.cpp:399] score_score_0_split -> score_score_0_split_1
I0630 00:43:39.977133 20971 net.cpp:141] Setting up score_score_0_split
I0630 00:43:39.977139 20971 net.cpp:148] Top shape: 4 2 384 384 (1179648)
I0630 00:43:39.977144 20971 net.cpp:148] Top shape: 4 2 384 384 (1179648)
I0630 00:43:39.977147 20971 net.cpp:156] Memory required for data: 6775405600
I0630 00:43:39.977152 20971 layer_factory.hpp:77] Creating layer loss
I0630 00:43:39.977160 20971 net.cpp:91] Creating Layer loss
I0630 00:43:39.977164 20971 net.cpp:425] loss <- score_score_0_split_0
I0630 00:43:39.977166 20971 net.cpp:425] loss <- label
I0630 00:43:39.977171 20971 net.cpp:399] loss -> loss
I0630 00:43:39.977185 20971 layer_factory.hpp:77] Creating layer loss
I0630 00:43:39.979003 20971 net.cpp:141] Setting up loss
I0630 00:43:39.979023 20971 net.cpp:148] Top shape: (1)
I0630 00:43:39.979027 20971 net.cpp:151]     with loss weight 1
I0630 00:43:39.979060 20971 net.cpp:156] Memory required for data: 6775405604
I0630 00:43:39.979065 20971 layer_factory.hpp:77] Creating layer clinet_top
I0630 00:43:39.979651 20971 net.cpp:91] Creating Layer clinet_top
I0630 00:43:39.979661 20971 net.cpp:425] clinet_top <- score_score_0_split_1
I0630 00:43:39.979668 20971 net.cpp:399] clinet_top -> clinet_top
I0630 00:43:39.980036 20971 net.cpp:141] Setting up clinet_top
I0630 00:43:39.980044 20971 net.cpp:148] Top shape: 1 (1)
I0630 00:43:39.980047 20971 net.cpp:156] Memory required for data: 6775405608
I0630 00:43:39.980051 20971 net.cpp:219] clinet_top does not need backward computation.
I0630 00:43:39.980053 20971 net.cpp:217] loss needs backward computation.
I0630 00:43:39.980057 20971 net.cpp:217] score_score_0_split needs backward computation.
I0630 00:43:39.980062 20971 net.cpp:217] score needs backward computation.
I0630 00:43:39.980069 20971 net.cpp:217] upscore needs backward computation.
I0630 00:43:39.980072 20971 net.cpp:217] fc8 needs backward computation.
I0630 00:43:39.980075 20971 net.cpp:217] drop7 needs backward computation.
I0630 00:43:39.980079 20971 net.cpp:217] relu7 needs backward computation.
I0630 00:43:39.980087 20971 net.cpp:217] fc7 needs backward computation.
I0630 00:43:39.980095 20971 net.cpp:217] drop6 needs backward computation.
I0630 00:43:39.980103 20971 net.cpp:217] relu6 needs backward computation.
I0630 00:43:39.980108 20971 net.cpp:217] fc6 needs backward computation.
I0630 00:43:39.980113 20971 net.cpp:217] concat1 needs backward computation.
I0630 00:43:39.980125 20971 net.cpp:217] relu5_3n needs backward computation.
I0630 00:43:39.980134 20971 net.cpp:217] conv5_3n needs backward computation.
I0630 00:43:39.980139 20971 net.cpp:217] relu5_2n needs backward computation.
I0630 00:43:39.980145 20971 net.cpp:217] conv5_2n needs backward computation.
I0630 00:43:39.980151 20971 net.cpp:217] relu5_1n needs backward computation.
I0630 00:43:39.980159 20971 net.cpp:217] conv5_1n needs backward computation.
I0630 00:43:39.980166 20971 net.cpp:217] relu4_3n needs backward computation.
I0630 00:43:39.980173 20971 net.cpp:217] conv4_3n needs backward computation.
I0630 00:43:39.980183 20971 net.cpp:217] relu4_2n needs backward computation.
I0630 00:43:39.980191 20971 net.cpp:217] conv4_2n needs backward computation.
I0630 00:43:39.980201 20971 net.cpp:217] relu4_1n needs backward computation.
I0630 00:43:39.980207 20971 net.cpp:217] conv4_1n needs backward computation.
I0630 00:43:39.980216 20971 net.cpp:217] pool3n needs backward computation.
I0630 00:43:39.980226 20971 net.cpp:217] relu3_3n needs backward computation.
I0630 00:43:39.980232 20971 net.cpp:217] conv3_3n needs backward computation.
I0630 00:43:39.980239 20971 net.cpp:217] relu3_2n needs backward computation.
I0630 00:43:39.980247 20971 net.cpp:217] conv3_2n needs backward computation.
I0630 00:43:39.980253 20971 net.cpp:217] relu3_1n needs backward computation.
I0630 00:43:39.980276 20971 net.cpp:217] conv3_1n needs backward computation.
I0630 00:43:39.980304 20971 net.cpp:217] pool2n needs backward computation.
I0630 00:43:39.980331 20971 net.cpp:217] relu2_2n needs backward computation.
I0630 00:43:39.980346 20971 net.cpp:217] conv2_2n needs backward computation.
I0630 00:43:39.980355 20971 net.cpp:217] relu2_1n needs backward computation.
I0630 00:43:39.980360 20971 net.cpp:217] conv2_1n needs backward computation.
I0630 00:43:39.980368 20971 net.cpp:217] pool1n needs backward computation.
I0630 00:43:39.980376 20971 net.cpp:217] relu1_2n needs backward computation.
I0630 00:43:39.980389 20971 net.cpp:217] conv1_2n needs backward computation.
I0630 00:43:39.980401 20971 net.cpp:217] relu1_1n needs backward computation.
I0630 00:43:39.980406 20971 net.cpp:217] conv1_1n needs backward computation.
I0630 00:43:39.980422 20971 net.cpp:217] relu5_3m needs backward computation.
I0630 00:43:39.980430 20971 net.cpp:217] conv5_3m needs backward computation.
I0630 00:43:39.980439 20971 net.cpp:217] relu5_2m needs backward computation.
I0630 00:43:39.980448 20971 net.cpp:217] conv5_2m needs backward computation.
I0630 00:43:39.980460 20971 net.cpp:217] relu5_1m needs backward computation.
I0630 00:43:39.980468 20971 net.cpp:217] conv5_1m needs backward computation.
I0630 00:43:39.980478 20971 net.cpp:217] relu4_3m needs backward computation.
I0630 00:43:39.980484 20971 net.cpp:217] conv4_3m needs backward computation.
I0630 00:43:39.980492 20971 net.cpp:217] relu4_2m needs backward computation.
I0630 00:43:39.980499 20971 net.cpp:217] conv4_2m needs backward computation.
I0630 00:43:39.980507 20971 net.cpp:217] relu4_1m needs backward computation.
I0630 00:43:39.980516 20971 net.cpp:217] conv4_1m needs backward computation.
I0630 00:43:39.980530 20971 net.cpp:217] pool3m needs backward computation.
I0630 00:43:39.980548 20971 net.cpp:217] relu3_3m needs backward computation.
I0630 00:43:39.980561 20971 net.cpp:217] conv3_3m needs backward computation.
I0630 00:43:39.980584 20971 net.cpp:217] relu3_2m needs backward computation.
I0630 00:43:39.980593 20971 net.cpp:217] conv3_2m needs backward computation.
I0630 00:43:39.980602 20971 net.cpp:217] relu3_1m needs backward computation.
I0630 00:43:39.980615 20971 net.cpp:217] conv3_1m needs backward computation.
I0630 00:43:39.980633 20971 net.cpp:217] pool2m needs backward computation.
I0630 00:43:39.980643 20971 net.cpp:217] relu2_2m needs backward computation.
I0630 00:43:39.980650 20971 net.cpp:217] conv2_2m needs backward computation.
I0630 00:43:39.980662 20971 net.cpp:217] relu2_1m needs backward computation.
I0630 00:43:39.980669 20971 net.cpp:217] conv2_1m needs backward computation.
I0630 00:43:39.980682 20971 net.cpp:217] pool1m needs backward computation.
I0630 00:43:39.980696 20971 net.cpp:217] relu1_2m needs backward computation.
I0630 00:43:39.980702 20971 net.cpp:217] conv1_2m needs backward computation.
I0630 00:43:39.980708 20971 net.cpp:217] relu1_1m needs backward computation.
I0630 00:43:39.980715 20971 net.cpp:217] conv1_1m needs backward computation.
I0630 00:43:39.980720 20971 net.cpp:217] relu5_3c needs backward computation.
I0630 00:43:39.980722 20971 net.cpp:217] conv5_3c needs backward computation.
I0630 00:43:39.980727 20971 net.cpp:217] relu5_2c needs backward computation.
I0630 00:43:39.980731 20971 net.cpp:217] conv5_2c needs backward computation.
I0630 00:43:39.980737 20971 net.cpp:217] relu5_1c needs backward computation.
I0630 00:43:39.980741 20971 net.cpp:217] conv5_1c needs backward computation.
I0630 00:43:39.980746 20971 net.cpp:217] relu4_3c needs backward computation.
I0630 00:43:39.980748 20971 net.cpp:217] conv4_3c needs backward computation.
I0630 00:43:39.980752 20971 net.cpp:217] relu4_2c needs backward computation.
I0630 00:43:39.980756 20971 net.cpp:217] conv4_2c needs backward computation.
I0630 00:43:39.980759 20971 net.cpp:217] relu4_1c needs backward computation.
I0630 00:43:39.980762 20971 net.cpp:217] conv4_1c needs backward computation.
I0630 00:43:39.980767 20971 net.cpp:217] pool3c needs backward computation.
I0630 00:43:39.980777 20971 net.cpp:217] relu3_3c needs backward computation.
I0630 00:43:39.980789 20971 net.cpp:217] conv3_3c needs backward computation.
I0630 00:43:39.980793 20971 net.cpp:217] relu3_2c needs backward computation.
I0630 00:43:39.980798 20971 net.cpp:217] conv3_2c needs backward computation.
I0630 00:43:39.980801 20971 net.cpp:217] relu3_1c needs backward computation.
I0630 00:43:39.980805 20971 net.cpp:217] conv3_1c needs backward computation.
I0630 00:43:39.980809 20971 net.cpp:217] pool2c needs backward computation.
I0630 00:43:39.980815 20971 net.cpp:217] relu2_2c needs backward computation.
I0630 00:43:39.980818 20971 net.cpp:217] conv2_2c needs backward computation.
I0630 00:43:39.980825 20971 net.cpp:217] relu2_1c needs backward computation.
I0630 00:43:39.980830 20971 net.cpp:217] conv2_1c needs backward computation.
I0630 00:43:39.980835 20971 net.cpp:217] pool1c needs backward computation.
I0630 00:43:39.980839 20971 net.cpp:217] relu1_2c needs backward computation.
I0630 00:43:39.980844 20971 net.cpp:217] conv1_2c needs backward computation.
I0630 00:43:39.980849 20971 net.cpp:217] relu1_1c needs backward computation.
I0630 00:43:39.980851 20971 net.cpp:217] conv1_1c needs backward computation.
I0630 00:43:39.980856 20971 net.cpp:219] next_im_cur_im_2_split does not need backward computation.
I0630 00:43:39.980864 20971 net.cpp:219] cur_im does not need backward computation.
I0630 00:43:39.980868 20971 net.cpp:261] This network produces output clinet_top
I0630 00:43:39.980872 20971 net.cpp:261] This network produces output loss
I0630 00:43:39.994778 20971 net.cpp:274] Network initialization done.
I0630 00:43:39.995021 20971 solver.cpp:60] Solver scaffolding done.
I0630 00:43:39.996094 20971 caffe.cpp:129] Finetuning from ./snapshots/coco_simple_iter_9047.caffemodel
I0630 00:43:40.646600 20971 caffe.cpp:219] Starting Optimization
I0630 00:43:40.646617 20971 solver.cpp:279] Solving 
I0630 00:43:40.646620 20971 solver.cpp:280] Learning Rate Policy: step
I0630 00:43:43.199710 20971 solver.cpp:228] Iteration 0, loss = 0.0735008
I0630 00:43:43.199764 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 00:43:43.199772 20971 solver.cpp:244]     Train net output #1: loss = 0.0735008 (* 1 = 0.0735008 loss)
I0630 00:43:43.199782 20971 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0630 00:45:34.874344 20971 solver.cpp:228] Iteration 20, loss = 0.141889
I0630 00:45:34.874403 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 00:45:34.874410 20971 solver.cpp:244]     Train net output #1: loss = 0.117406 (* 1 = 0.117406 loss)
I0630 00:45:34.874415 20971 sgd_solver.cpp:106] Iteration 20, lr = 1e-05
I0630 00:47:35.920016 20971 solver.cpp:228] Iteration 40, loss = 0.167217
I0630 00:47:35.920430 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 00:47:35.920445 20971 solver.cpp:244]     Train net output #1: loss = 0.160676 (* 1 = 0.160676 loss)
I0630 00:47:35.920454 20971 sgd_solver.cpp:106] Iteration 40, lr = 1e-05
I0630 00:49:24.161861 20971 solver.cpp:228] Iteration 60, loss = 0.240532
I0630 00:49:24.162027 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 00:49:24.162040 20971 solver.cpp:244]     Train net output #1: loss = 0.250984 (* 1 = 0.250984 loss)
I0630 00:49:24.162046 20971 sgd_solver.cpp:106] Iteration 60, lr = 1e-05
I0630 00:51:25.253880 20971 solver.cpp:228] Iteration 80, loss = 0.182877
I0630 00:51:25.253985 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 00:51:25.253995 20971 solver.cpp:244]     Train net output #1: loss = 0.228965 (* 1 = 0.228965 loss)
I0630 00:51:25.253999 20971 sgd_solver.cpp:106] Iteration 80, lr = 1e-05
I0630 00:53:23.693559 20971 solver.cpp:228] Iteration 100, loss = 0.143004
I0630 00:53:23.693639 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 00:53:23.693660 20971 solver.cpp:244]     Train net output #1: loss = 0.142971 (* 1 = 0.142971 loss)
I0630 00:53:23.693667 20971 sgd_solver.cpp:106] Iteration 100, lr = 1e-05
I0630 00:55:11.177080 20971 solver.cpp:228] Iteration 120, loss = 0.150676
I0630 00:55:11.177155 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 00:55:11.177161 20971 solver.cpp:244]     Train net output #1: loss = 0.146306 (* 1 = 0.146306 loss)
I0630 00:55:11.177166 20971 sgd_solver.cpp:106] Iteration 120, lr = 1e-05
I0630 00:56:58.674970 20971 solver.cpp:228] Iteration 140, loss = 0.130741
I0630 00:56:58.675072 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 00:56:58.675082 20971 solver.cpp:244]     Train net output #1: loss = 0.107335 (* 1 = 0.107335 loss)
I0630 00:56:58.675087 20971 sgd_solver.cpp:106] Iteration 140, lr = 1e-05
I0630 00:58:46.753355 20971 solver.cpp:228] Iteration 160, loss = 0.137987
I0630 00:58:46.753417 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 00:58:46.753424 20971 solver.cpp:244]     Train net output #1: loss = 0.13846 (* 1 = 0.13846 loss)
I0630 00:58:46.753429 20971 sgd_solver.cpp:106] Iteration 160, lr = 1e-05
I0630 01:00:33.372809 20971 solver.cpp:228] Iteration 180, loss = 0.128177
I0630 01:00:33.372856 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:00:33.372864 20971 solver.cpp:244]     Train net output #1: loss = 0.104285 (* 1 = 0.104285 loss)
I0630 01:00:33.372869 20971 sgd_solver.cpp:106] Iteration 180, lr = 1e-05
I0630 01:02:20.994226 20971 solver.cpp:228] Iteration 200, loss = 0.0911627
I0630 01:02:20.994323 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:02:20.994331 20971 solver.cpp:244]     Train net output #1: loss = 0.0972193 (* 1 = 0.0972193 loss)
I0630 01:02:20.994335 20971 sgd_solver.cpp:106] Iteration 200, lr = 1e-05
I0630 01:04:08.717298 20971 solver.cpp:228] Iteration 220, loss = 0.109621
I0630 01:04:08.717355 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:04:08.717362 20971 solver.cpp:244]     Train net output #1: loss = 0.0957208 (* 1 = 0.0957208 loss)
I0630 01:04:08.717367 20971 sgd_solver.cpp:106] Iteration 220, lr = 1e-05
I0630 01:06:00.757773 20971 solver.cpp:228] Iteration 240, loss = 0.122454
I0630 01:06:00.757884 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:06:00.757894 20971 solver.cpp:244]     Train net output #1: loss = 0.114417 (* 1 = 0.114417 loss)
I0630 01:06:00.757899 20971 sgd_solver.cpp:106] Iteration 240, lr = 1e-05
I0630 01:07:48.651782 20971 solver.cpp:228] Iteration 260, loss = 0.123775
I0630 01:07:48.651834 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:07:48.651841 20971 solver.cpp:244]     Train net output #1: loss = 0.106148 (* 1 = 0.106148 loss)
I0630 01:07:48.651846 20971 sgd_solver.cpp:106] Iteration 260, lr = 1e-05
I0630 01:09:35.910115 20971 solver.cpp:228] Iteration 280, loss = 0.138542
I0630 01:09:35.910218 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:09:35.910228 20971 solver.cpp:244]     Train net output #1: loss = 0.151196 (* 1 = 0.151196 loss)
I0630 01:09:35.910233 20971 sgd_solver.cpp:106] Iteration 280, lr = 1e-05
I0630 01:11:22.018199 20971 solver.cpp:228] Iteration 300, loss = 0.120518
I0630 01:11:22.018296 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:11:22.018303 20971 solver.cpp:244]     Train net output #1: loss = 0.0992835 (* 1 = 0.0992835 loss)
I0630 01:11:22.018308 20971 sgd_solver.cpp:106] Iteration 300, lr = 1e-05
I0630 01:13:08.339714 20971 solver.cpp:228] Iteration 320, loss = 0.10255
I0630 01:13:08.339792 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:13:08.339798 20971 solver.cpp:244]     Train net output #1: loss = 0.116435 (* 1 = 0.116435 loss)
I0630 01:13:08.339803 20971 sgd_solver.cpp:106] Iteration 320, lr = 1e-05
I0630 01:14:55.628664 20971 solver.cpp:228] Iteration 340, loss = 0.0845172
I0630 01:14:55.628713 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:14:55.628723 20971 solver.cpp:244]     Train net output #1: loss = 0.0627319 (* 1 = 0.0627319 loss)
I0630 01:14:55.628731 20971 sgd_solver.cpp:106] Iteration 340, lr = 1e-05
I0630 01:16:42.863968 20971 solver.cpp:228] Iteration 360, loss = 0.100623
I0630 01:16:42.864092 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:16:42.864102 20971 solver.cpp:244]     Train net output #1: loss = 0.0782006 (* 1 = 0.0782006 loss)
I0630 01:16:42.864107 20971 sgd_solver.cpp:106] Iteration 360, lr = 1e-05
I0630 01:18:33.061408 20971 solver.cpp:228] Iteration 380, loss = 0.0944656
I0630 01:18:33.061502 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:18:33.061509 20971 solver.cpp:244]     Train net output #1: loss = 0.124666 (* 1 = 0.124666 loss)
I0630 01:18:33.061514 20971 sgd_solver.cpp:106] Iteration 380, lr = 1e-05
I0630 01:20:26.586705 20971 solver.cpp:228] Iteration 400, loss = 0.140989
I0630 01:20:26.586762 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:20:26.586769 20971 solver.cpp:244]     Train net output #1: loss = 0.166131 (* 1 = 0.166131 loss)
I0630 01:20:26.586774 20971 sgd_solver.cpp:106] Iteration 400, lr = 1e-05
I0630 01:22:15.783973 20971 solver.cpp:228] Iteration 420, loss = 0.132425
I0630 01:22:15.790493 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:22:15.790521 20971 solver.cpp:244]     Train net output #1: loss = 0.109787 (* 1 = 0.109787 loss)
I0630 01:22:15.790530 20971 sgd_solver.cpp:106] Iteration 420, lr = 1e-05
I0630 01:24:35.896525 20971 solver.cpp:228] Iteration 440, loss = 0.135877
I0630 01:24:35.896610 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:24:35.896617 20971 solver.cpp:244]     Train net output #1: loss = 0.119109 (* 1 = 0.119109 loss)
I0630 01:24:35.896623 20971 sgd_solver.cpp:106] Iteration 440, lr = 1e-05
I0630 01:26:38.700044 20971 solver.cpp:228] Iteration 460, loss = 0.120744
I0630 01:26:38.700119 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:26:38.700129 20971 solver.cpp:244]     Train net output #1: loss = 0.100837 (* 1 = 0.100837 loss)
I0630 01:26:38.700139 20971 sgd_solver.cpp:106] Iteration 460, lr = 1e-05
I0630 01:28:26.570545 20971 solver.cpp:228] Iteration 480, loss = 0.125287
I0630 01:28:26.570638 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:28:26.570647 20971 solver.cpp:244]     Train net output #1: loss = 0.0960439 (* 1 = 0.0960439 loss)
I0630 01:28:26.570652 20971 sgd_solver.cpp:106] Iteration 480, lr = 1e-05
I0630 01:30:13.578521 20971 solver.cpp:228] Iteration 500, loss = 0.114458
I0630 01:30:13.578595 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:30:13.578603 20971 solver.cpp:244]     Train net output #1: loss = 0.157372 (* 1 = 0.157372 loss)
I0630 01:30:13.578608 20971 sgd_solver.cpp:106] Iteration 500, lr = 1e-05
I0630 01:31:59.364984 20971 solver.cpp:228] Iteration 520, loss = 0.126985
I0630 01:31:59.365031 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:31:59.365038 20971 solver.cpp:244]     Train net output #1: loss = 0.120454 (* 1 = 0.120454 loss)
I0630 01:31:59.365043 20971 sgd_solver.cpp:106] Iteration 520, lr = 1e-05
I0630 01:33:45.395980 20971 solver.cpp:228] Iteration 540, loss = 0.0991239
I0630 01:33:45.396036 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:33:45.396044 20971 solver.cpp:244]     Train net output #1: loss = 0.0838483 (* 1 = 0.0838483 loss)
I0630 01:33:45.396049 20971 sgd_solver.cpp:106] Iteration 540, lr = 1e-05
I0630 01:35:31.607185 20971 solver.cpp:228] Iteration 560, loss = 0.0866771
I0630 01:35:31.607255 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:35:31.607264 20971 solver.cpp:244]     Train net output #1: loss = 0.0951383 (* 1 = 0.0951383 loss)
I0630 01:35:31.607270 20971 sgd_solver.cpp:106] Iteration 560, lr = 1e-05
I0630 01:37:20.381130 20971 solver.cpp:228] Iteration 580, loss = 0.0994462
I0630 01:37:20.381206 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:37:20.381213 20971 solver.cpp:244]     Train net output #1: loss = 0.130783 (* 1 = 0.130783 loss)
I0630 01:37:20.381218 20971 sgd_solver.cpp:106] Iteration 580, lr = 1e-05
I0630 01:39:08.671064 20971 solver.cpp:228] Iteration 600, loss = 0.123553
I0630 01:39:08.671142 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:39:08.671150 20971 solver.cpp:244]     Train net output #1: loss = 0.150819 (* 1 = 0.150819 loss)
I0630 01:39:08.671155 20971 sgd_solver.cpp:106] Iteration 600, lr = 1e-05
I0630 01:40:55.800003 20971 solver.cpp:228] Iteration 620, loss = 0.100145
I0630 01:40:55.800094 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:40:55.800104 20971 solver.cpp:244]     Train net output #1: loss = 0.097565 (* 1 = 0.097565 loss)
I0630 01:40:55.800112 20971 sgd_solver.cpp:106] Iteration 620, lr = 1e-05
I0630 01:42:43.042172 20971 solver.cpp:228] Iteration 640, loss = 0.122421
I0630 01:42:43.042253 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:42:43.042261 20971 solver.cpp:244]     Train net output #1: loss = 0.120372 (* 1 = 0.120372 loss)
I0630 01:42:43.042268 20971 sgd_solver.cpp:106] Iteration 640, lr = 1e-05
I0630 01:44:28.640194 20971 solver.cpp:228] Iteration 660, loss = 0.10209
I0630 01:44:28.640267 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:44:28.640275 20971 solver.cpp:244]     Train net output #1: loss = 0.0969817 (* 1 = 0.0969817 loss)
I0630 01:44:28.640280 20971 sgd_solver.cpp:106] Iteration 660, lr = 1e-05
I0630 01:46:14.927979 20971 solver.cpp:228] Iteration 680, loss = 0.0893852
I0630 01:46:14.928050 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:46:14.928058 20971 solver.cpp:244]     Train net output #1: loss = 0.0799454 (* 1 = 0.0799454 loss)
I0630 01:46:14.928066 20971 sgd_solver.cpp:106] Iteration 680, lr = 1e-05
I0630 01:48:02.104604 20971 solver.cpp:228] Iteration 700, loss = 0.0839788
I0630 01:48:02.104707 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:48:02.104717 20971 solver.cpp:244]     Train net output #1: loss = 0.0834461 (* 1 = 0.0834461 loss)
I0630 01:48:02.104728 20971 sgd_solver.cpp:106] Iteration 700, lr = 1e-05
I0630 01:49:49.897025 20971 solver.cpp:228] Iteration 720, loss = 0.0966225
I0630 01:49:49.897102 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:49:49.897110 20971 solver.cpp:244]     Train net output #1: loss = 0.0741029 (* 1 = 0.0741029 loss)
I0630 01:49:49.897116 20971 sgd_solver.cpp:106] Iteration 720, lr = 1e-05
I0630 01:51:40.400045 20971 solver.cpp:228] Iteration 740, loss = 0.0979556
I0630 01:51:40.400133 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:51:40.400141 20971 solver.cpp:244]     Train net output #1: loss = 0.107998 (* 1 = 0.107998 loss)
I0630 01:51:40.400144 20971 sgd_solver.cpp:106] Iteration 740, lr = 1e-05
I0630 01:53:29.752658 20971 solver.cpp:228] Iteration 760, loss = 0.126903
I0630 01:53:29.752754 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:53:29.752764 20971 solver.cpp:244]     Train net output #1: loss = 0.11605 (* 1 = 0.11605 loss)
I0630 01:53:29.752771 20971 sgd_solver.cpp:106] Iteration 760, lr = 1e-05
I0630 01:55:34.324095 20971 solver.cpp:228] Iteration 780, loss = 0.11488
I0630 01:55:34.330521 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:55:34.330560 20971 solver.cpp:244]     Train net output #1: loss = 0.117243 (* 1 = 0.117243 loss)
I0630 01:55:34.330582 20971 sgd_solver.cpp:106] Iteration 780, lr = 1e-05
I0630 01:57:44.245054 20971 solver.cpp:228] Iteration 800, loss = 0.109714
I0630 01:57:44.245101 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:57:44.245108 20971 solver.cpp:244]     Train net output #1: loss = 0.0902059 (* 1 = 0.0902059 loss)
I0630 01:57:44.245115 20971 sgd_solver.cpp:106] Iteration 800, lr = 1e-05
I0630 01:59:30.993048 20971 solver.cpp:228] Iteration 820, loss = 0.107599
I0630 01:59:30.993096 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 01:59:30.993104 20971 solver.cpp:244]     Train net output #1: loss = 0.110921 (* 1 = 0.110921 loss)
I0630 01:59:30.993109 20971 sgd_solver.cpp:106] Iteration 820, lr = 1e-05
I0630 02:01:16.903384 20971 solver.cpp:228] Iteration 840, loss = 0.113139
I0630 02:01:16.903498 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:01:16.903508 20971 solver.cpp:244]     Train net output #1: loss = 0.0926643 (* 1 = 0.0926643 loss)
I0630 02:01:16.903515 20971 sgd_solver.cpp:106] Iteration 840, lr = 1e-05
I0630 02:03:02.734426 20971 solver.cpp:228] Iteration 860, loss = 0.112666
I0630 02:03:02.734524 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:03:02.734530 20971 solver.cpp:244]     Train net output #1: loss = 0.123175 (* 1 = 0.123175 loss)
I0630 02:03:02.734535 20971 sgd_solver.cpp:106] Iteration 860, lr = 1e-05
I0630 02:04:48.959692 20971 solver.cpp:228] Iteration 880, loss = 0.11996
I0630 02:04:48.959780 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:04:48.959795 20971 solver.cpp:244]     Train net output #1: loss = 0.113456 (* 1 = 0.113456 loss)
I0630 02:04:48.959810 20971 sgd_solver.cpp:106] Iteration 880, lr = 1e-05
I0630 02:06:38.592941 20971 solver.cpp:228] Iteration 900, loss = 0.0927873
I0630 02:06:38.593022 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:06:38.593030 20971 solver.cpp:244]     Train net output #1: loss = 0.084972 (* 1 = 0.084972 loss)
I0630 02:06:38.593036 20971 sgd_solver.cpp:106] Iteration 900, lr = 1e-05
I0630 02:08:24.663162 20971 solver.cpp:228] Iteration 920, loss = 0.0850542
I0630 02:08:24.663210 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:08:24.663218 20971 solver.cpp:244]     Train net output #1: loss = 0.102155 (* 1 = 0.102155 loss)
I0630 02:08:24.663225 20971 sgd_solver.cpp:106] Iteration 920, lr = 1e-05
I0630 02:10:11.285075 20971 solver.cpp:228] Iteration 940, loss = 0.0955038
I0630 02:10:11.285121 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:10:11.285128 20971 solver.cpp:244]     Train net output #1: loss = 0.118951 (* 1 = 0.118951 loss)
I0630 02:10:11.285132 20971 sgd_solver.cpp:106] Iteration 940, lr = 1e-05
I0630 02:11:59.610519 20971 solver.cpp:228] Iteration 960, loss = 0.108892
I0630 02:11:59.610703 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:11:59.610710 20971 solver.cpp:244]     Train net output #1: loss = 0.0948252 (* 1 = 0.0948252 loss)
I0630 02:11:59.610715 20971 sgd_solver.cpp:106] Iteration 960, lr = 1e-05
I0630 02:13:46.201616 20971 solver.cpp:228] Iteration 980, loss = 0.0912624
I0630 02:13:46.201707 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:13:46.201715 20971 solver.cpp:244]     Train net output #1: loss = 0.0971026 (* 1 = 0.0971026 loss)
I0630 02:13:46.201720 20971 sgd_solver.cpp:106] Iteration 980, lr = 1e-05
I0630 02:15:33.769137 20971 solver.cpp:228] Iteration 1000, loss = 0.123995
I0630 02:15:33.769197 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:15:33.769204 20971 solver.cpp:244]     Train net output #1: loss = 0.119275 (* 1 = 0.119275 loss)
I0630 02:15:33.769209 20971 sgd_solver.cpp:106] Iteration 1000, lr = 1e-05
I0630 02:17:21.351011 20971 solver.cpp:228] Iteration 1020, loss = 0.0863551
I0630 02:17:21.351071 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:17:21.351079 20971 solver.cpp:244]     Train net output #1: loss = 0.0806392 (* 1 = 0.0806392 loss)
I0630 02:17:21.351083 20971 sgd_solver.cpp:106] Iteration 1020, lr = 1e-05
I0630 02:19:08.331421 20971 solver.cpp:228] Iteration 1040, loss = 0.0836354
I0630 02:19:08.331473 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:19:08.331480 20971 solver.cpp:244]     Train net output #1: loss = 0.0780066 (* 1 = 0.0780066 loss)
I0630 02:19:08.331485 20971 sgd_solver.cpp:106] Iteration 1040, lr = 1e-05
I0630 02:20:54.141522 20971 solver.cpp:228] Iteration 1060, loss = 0.0831772
I0630 02:20:54.141603 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:20:54.141616 20971 solver.cpp:244]     Train net output #1: loss = 0.0979571 (* 1 = 0.0979571 loss)
I0630 02:20:54.141623 20971 sgd_solver.cpp:106] Iteration 1060, lr = 1e-05
I0630 02:22:39.829797 20971 solver.cpp:228] Iteration 1080, loss = 0.0922032
I0630 02:22:39.829891 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:22:39.829900 20971 solver.cpp:244]     Train net output #1: loss = 0.0822025 (* 1 = 0.0822025 loss)
I0630 02:22:39.829907 20971 sgd_solver.cpp:106] Iteration 1080, lr = 1e-05
I0630 02:24:29.763491 20971 solver.cpp:228] Iteration 1100, loss = 0.0953338
I0630 02:24:29.763576 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:24:29.763586 20971 solver.cpp:244]     Train net output #1: loss = 0.0835227 (* 1 = 0.0835227 loss)
I0630 02:24:29.763592 20971 sgd_solver.cpp:106] Iteration 1100, lr = 1e-05
I0630 02:26:16.030191 20971 solver.cpp:228] Iteration 1120, loss = 0.116476
I0630 02:26:16.030251 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:26:16.030257 20971 solver.cpp:244]     Train net output #1: loss = 0.117436 (* 1 = 0.117436 loss)
I0630 02:26:16.030261 20971 sgd_solver.cpp:106] Iteration 1120, lr = 1e-05
I0630 02:28:10.904392 20971 solver.cpp:228] Iteration 1140, loss = 0.105646
I0630 02:28:10.904463 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:28:10.904469 20971 solver.cpp:244]     Train net output #1: loss = 0.11353 (* 1 = 0.11353 loss)
I0630 02:28:10.904474 20971 sgd_solver.cpp:106] Iteration 1140, lr = 1e-05
I0630 02:30:06.991598 20971 solver.cpp:228] Iteration 1160, loss = 0.098922
I0630 02:30:06.991654 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:30:06.991670 20971 solver.cpp:244]     Train net output #1: loss = 0.120358 (* 1 = 0.120358 loss)
I0630 02:30:06.991677 20971 sgd_solver.cpp:106] Iteration 1160, lr = 1e-05
I0630 02:31:54.246881 20971 solver.cpp:228] Iteration 1180, loss = 0.111834
I0630 02:31:54.246984 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:31:54.246992 20971 solver.cpp:244]     Train net output #1: loss = 0.127811 (* 1 = 0.127811 loss)
I0630 02:31:54.247006 20971 sgd_solver.cpp:106] Iteration 1180, lr = 1e-05
I0630 02:33:40.808358 20971 solver.cpp:228] Iteration 1200, loss = 0.103559
I0630 02:33:40.808490 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:33:40.808501 20971 solver.cpp:244]     Train net output #1: loss = 0.0968801 (* 1 = 0.0968801 loss)
I0630 02:33:40.808506 20971 sgd_solver.cpp:106] Iteration 1200, lr = 1e-05
I0630 02:35:27.375861 20971 solver.cpp:228] Iteration 1220, loss = 0.11444
I0630 02:35:27.375906 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:35:27.375913 20971 solver.cpp:244]     Train net output #1: loss = 0.0966858 (* 1 = 0.0966858 loss)
I0630 02:35:27.375918 20971 sgd_solver.cpp:106] Iteration 1220, lr = 1e-05
I0630 02:37:14.078138 20971 solver.cpp:228] Iteration 1240, loss = 0.109365
I0630 02:37:14.078235 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:37:14.078243 20971 solver.cpp:244]     Train net output #1: loss = 0.111345 (* 1 = 0.111345 loss)
I0630 02:37:14.078248 20971 sgd_solver.cpp:106] Iteration 1240, lr = 1e-05
I0630 02:38:02.037653 20971 solver.cpp:454] Snapshotting to binary proto file ./snapshots/davis_sequence_simple_iter_1250.caffemodel
I0630 02:38:06.659957 20971 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/davis_sequence_simple_iter_1250.solverstate
I0630 02:39:01.422940 20971 solver.cpp:228] Iteration 1260, loss = 0.0841278
I0630 02:39:01.423030 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:39:01.423038 20971 solver.cpp:244]     Train net output #1: loss = 0.0805329 (* 1 = 0.0805329 loss)
I0630 02:39:01.423043 20971 sgd_solver.cpp:106] Iteration 1260, lr = 1e-05
I0630 02:40:47.939090 20971 solver.cpp:228] Iteration 1280, loss = 0.0790074
I0630 02:40:47.939177 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:40:47.939185 20971 solver.cpp:244]     Train net output #1: loss = 0.0818224 (* 1 = 0.0818224 loss)
I0630 02:40:47.939190 20971 sgd_solver.cpp:106] Iteration 1280, lr = 1e-05
I0630 02:42:33.996724 20971 solver.cpp:228] Iteration 1300, loss = 0.105752
I0630 02:42:33.996798 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:42:33.996805 20971 solver.cpp:244]     Train net output #1: loss = 0.110501 (* 1 = 0.110501 loss)
I0630 02:42:33.996810 20971 sgd_solver.cpp:106] Iteration 1300, lr = 1e-05
I0630 02:44:21.159656 20971 solver.cpp:228] Iteration 1320, loss = 0.0992215
I0630 02:44:21.159701 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:44:21.159708 20971 solver.cpp:244]     Train net output #1: loss = 0.0876139 (* 1 = 0.0876139 loss)
I0630 02:44:21.159713 20971 sgd_solver.cpp:106] Iteration 1320, lr = 1e-05
I0630 02:46:06.757961 20971 solver.cpp:228] Iteration 1340, loss = 0.0942514
I0630 02:46:06.758013 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:46:06.758020 20971 solver.cpp:244]     Train net output #1: loss = 0.141444 (* 1 = 0.141444 loss)
I0630 02:46:06.758025 20971 sgd_solver.cpp:106] Iteration 1340, lr = 1e-05
I0630 02:47:52.308924 20971 solver.cpp:228] Iteration 1360, loss = 0.109061
I0630 02:47:52.309026 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:47:52.309034 20971 solver.cpp:244]     Train net output #1: loss = 0.082236 (* 1 = 0.082236 loss)
I0630 02:47:52.309039 20971 sgd_solver.cpp:106] Iteration 1360, lr = 1e-05
I0630 02:49:39.108712 20971 solver.cpp:228] Iteration 1380, loss = 0.0860526
I0630 02:49:39.108762 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:49:39.108770 20971 solver.cpp:244]     Train net output #1: loss = 0.101029 (* 1 = 0.101029 loss)
I0630 02:49:39.108777 20971 sgd_solver.cpp:106] Iteration 1380, lr = 1e-05
I0630 02:51:25.074556 20971 solver.cpp:228] Iteration 1400, loss = 0.083406
I0630 02:51:25.074627 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:51:25.074636 20971 solver.cpp:244]     Train net output #1: loss = 0.0805988 (* 1 = 0.0805988 loss)
I0630 02:51:25.074643 20971 sgd_solver.cpp:106] Iteration 1400, lr = 1e-05
I0630 02:53:10.966752 20971 solver.cpp:228] Iteration 1420, loss = 0.0957578
I0630 02:53:10.966806 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:53:10.966815 20971 solver.cpp:244]     Train net output #1: loss = 0.0969073 (* 1 = 0.0969073 loss)
I0630 02:53:10.966820 20971 sgd_solver.cpp:106] Iteration 1420, lr = 1e-05
I0630 02:54:56.837543 20971 solver.cpp:228] Iteration 1440, loss = 0.0879517
I0630 02:54:56.837589 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:54:56.837596 20971 solver.cpp:244]     Train net output #1: loss = 0.120359 (* 1 = 0.120359 loss)
I0630 02:54:56.837601 20971 sgd_solver.cpp:106] Iteration 1440, lr = 1e-05
I0630 02:56:45.459830 20971 solver.cpp:228] Iteration 1460, loss = 0.0983075
I0630 02:56:45.459930 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:56:45.459939 20971 solver.cpp:244]     Train net output #1: loss = 0.121106 (* 1 = 0.121106 loss)
I0630 02:56:45.459944 20971 sgd_solver.cpp:106] Iteration 1460, lr = 1e-05
I0630 02:58:31.393795 20971 solver.cpp:228] Iteration 1480, loss = 0.108991
I0630 02:58:31.393884 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 02:58:31.393895 20971 solver.cpp:244]     Train net output #1: loss = 0.0886058 (* 1 = 0.0886058 loss)
I0630 02:58:31.393903 20971 sgd_solver.cpp:106] Iteration 1480, lr = 1e-05
I0630 03:00:33.205168 20971 solver.cpp:228] Iteration 1500, loss = 0.0957142
I0630 03:00:33.205242 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:00:33.205250 20971 solver.cpp:244]     Train net output #1: loss = 0.0794451 (* 1 = 0.0794451 loss)
I0630 03:00:33.205255 20971 sgd_solver.cpp:106] Iteration 1500, lr = 1e-05
I0630 03:02:19.149464 20971 solver.cpp:228] Iteration 1520, loss = 0.111274
I0630 03:02:19.149538 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:02:19.149544 20971 solver.cpp:244]     Train net output #1: loss = 0.0904336 (* 1 = 0.0904336 loss)
I0630 03:02:19.149549 20971 sgd_solver.cpp:106] Iteration 1520, lr = 1e-05
I0630 03:04:05.012792 20971 solver.cpp:228] Iteration 1540, loss = 0.0993368
I0630 03:04:05.012872 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:04:05.012882 20971 solver.cpp:244]     Train net output #1: loss = 0.0840247 (* 1 = 0.0840247 loss)
I0630 03:04:05.012888 20971 sgd_solver.cpp:106] Iteration 1540, lr = 1e-05
I0630 03:05:50.966492 20971 solver.cpp:228] Iteration 1560, loss = 0.101672
I0630 03:05:50.966573 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:05:50.966581 20971 solver.cpp:244]     Train net output #1: loss = 0.128624 (* 1 = 0.128624 loss)
I0630 03:05:50.966588 20971 sgd_solver.cpp:106] Iteration 1560, lr = 1e-05
I0630 03:07:36.799747 20971 solver.cpp:228] Iteration 1580, loss = 0.113086
I0630 03:07:36.799829 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:07:36.799836 20971 solver.cpp:244]     Train net output #1: loss = 0.110839 (* 1 = 0.110839 loss)
I0630 03:07:36.799841 20971 sgd_solver.cpp:106] Iteration 1580, lr = 1e-05
I0630 03:09:22.909421 20971 solver.cpp:228] Iteration 1600, loss = 0.0926175
I0630 03:09:22.909540 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:09:22.909550 20971 solver.cpp:244]     Train net output #1: loss = 0.0767094 (* 1 = 0.0767094 loss)
I0630 03:09:22.909555 20971 sgd_solver.cpp:106] Iteration 1600, lr = 1e-05
I0630 03:11:08.778131 20971 solver.cpp:228] Iteration 1620, loss = 0.0744806
I0630 03:11:08.778236 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:11:08.778246 20971 solver.cpp:244]     Train net output #1: loss = 0.0743798 (* 1 = 0.0743798 loss)
I0630 03:11:08.778251 20971 sgd_solver.cpp:106] Iteration 1620, lr = 1e-05
I0630 03:12:54.708561 20971 solver.cpp:228] Iteration 1640, loss = 0.0868325
I0630 03:12:54.708607 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:12:54.708614 20971 solver.cpp:244]     Train net output #1: loss = 0.150879 (* 1 = 0.150879 loss)
I0630 03:12:54.708619 20971 sgd_solver.cpp:106] Iteration 1640, lr = 1e-05
I0630 03:14:40.599768 20971 solver.cpp:228] Iteration 1660, loss = 0.105612
I0630 03:14:40.599838 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:14:40.599844 20971 solver.cpp:244]     Train net output #1: loss = 0.076757 (* 1 = 0.076757 loss)
I0630 03:14:40.599849 20971 sgd_solver.cpp:106] Iteration 1660, lr = 1e-05
I0630 03:16:26.425776 20971 solver.cpp:228] Iteration 1680, loss = 0.0814771
I0630 03:16:26.425825 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:16:26.425833 20971 solver.cpp:244]     Train net output #1: loss = 0.076762 (* 1 = 0.076762 loss)
I0630 03:16:26.425837 20971 sgd_solver.cpp:106] Iteration 1680, lr = 1e-05
I0630 03:18:12.247463 20971 solver.cpp:228] Iteration 1700, loss = 0.125183
I0630 03:18:12.247570 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:18:12.247581 20971 solver.cpp:244]     Train net output #1: loss = 0.0943856 (* 1 = 0.0943856 loss)
I0630 03:18:12.247584 20971 sgd_solver.cpp:106] Iteration 1700, lr = 1e-05
I0630 03:19:58.097723 20971 solver.cpp:228] Iteration 1720, loss = 0.0824392
I0630 03:19:58.097793 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:19:58.097801 20971 solver.cpp:244]     Train net output #1: loss = 0.0721924 (* 1 = 0.0721924 loss)
I0630 03:19:58.097806 20971 sgd_solver.cpp:106] Iteration 1720, lr = 1e-05
I0630 03:21:43.959712 20971 solver.cpp:228] Iteration 1740, loss = 0.0833784
I0630 03:21:43.959764 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:21:43.959770 20971 solver.cpp:244]     Train net output #1: loss = 0.0817574 (* 1 = 0.0817574 loss)
I0630 03:21:43.959774 20971 sgd_solver.cpp:106] Iteration 1740, lr = 1e-05
I0630 03:23:29.771386 20971 solver.cpp:228] Iteration 1760, loss = 0.0849772
I0630 03:23:29.771456 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:23:29.771463 20971 solver.cpp:244]     Train net output #1: loss = 0.0974777 (* 1 = 0.0974777 loss)
I0630 03:23:29.771468 20971 sgd_solver.cpp:106] Iteration 1760, lr = 1e-05
I0630 03:25:15.620697 20971 solver.cpp:228] Iteration 1780, loss = 0.0890708
I0630 03:25:15.620806 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:25:15.620815 20971 solver.cpp:244]     Train net output #1: loss = 0.0784461 (* 1 = 0.0784461 loss)
I0630 03:25:15.620820 20971 sgd_solver.cpp:106] Iteration 1780, lr = 1e-05
I0630 03:27:01.764823 20971 solver.cpp:228] Iteration 1800, loss = 0.0972472
I0630 03:27:01.764880 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:27:01.764889 20971 solver.cpp:244]     Train net output #1: loss = 0.0777124 (* 1 = 0.0777124 loss)
I0630 03:27:01.764894 20971 sgd_solver.cpp:106] Iteration 1800, lr = 1e-05
I0630 03:28:47.724845 20971 solver.cpp:228] Iteration 1820, loss = 0.102643
I0630 03:28:47.724951 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:28:47.724961 20971 solver.cpp:244]     Train net output #1: loss = 0.107038 (* 1 = 0.107038 loss)
I0630 03:28:47.724967 20971 sgd_solver.cpp:106] Iteration 1820, lr = 1e-05
I0630 03:30:39.967380 20971 solver.cpp:228] Iteration 1840, loss = 0.0965974
I0630 03:30:39.967424 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:30:39.967432 20971 solver.cpp:244]     Train net output #1: loss = 0.101373 (* 1 = 0.101373 loss)
I0630 03:30:39.967437 20971 sgd_solver.cpp:106] Iteration 1840, lr = 1e-05
I0630 03:32:33.971158 20971 solver.cpp:228] Iteration 1860, loss = 0.092309
I0630 03:32:33.971205 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:32:33.971212 20971 solver.cpp:244]     Train net output #1: loss = 0.108638 (* 1 = 0.108638 loss)
I0630 03:32:33.971217 20971 sgd_solver.cpp:106] Iteration 1860, lr = 1e-05
I0630 03:34:19.847708 20971 solver.cpp:228] Iteration 1880, loss = 0.10783
I0630 03:34:19.847755 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:34:19.847765 20971 solver.cpp:244]     Train net output #1: loss = 0.106029 (* 1 = 0.106029 loss)
I0630 03:34:19.847772 20971 sgd_solver.cpp:106] Iteration 1880, lr = 1e-05
I0630 03:36:06.818200 20971 solver.cpp:228] Iteration 1900, loss = 0.0934829
I0630 03:36:06.818297 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:36:06.818320 20971 solver.cpp:244]     Train net output #1: loss = 0.113894 (* 1 = 0.113894 loss)
I0630 03:36:06.818330 20971 sgd_solver.cpp:106] Iteration 1900, lr = 1e-05
I0630 03:37:53.123584 20971 solver.cpp:228] Iteration 1920, loss = 0.10339
I0630 03:37:53.123687 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:37:53.123695 20971 solver.cpp:244]     Train net output #1: loss = 0.0799567 (* 1 = 0.0799567 loss)
I0630 03:37:53.123700 20971 sgd_solver.cpp:106] Iteration 1920, lr = 1e-05
I0630 03:39:39.726482 20971 solver.cpp:228] Iteration 1940, loss = 0.110577
I0630 03:39:39.726532 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:39:39.726539 20971 solver.cpp:244]     Train net output #1: loss = 0.114372 (* 1 = 0.114372 loss)
I0630 03:39:39.726543 20971 sgd_solver.cpp:106] Iteration 1940, lr = 1e-05
I0630 03:41:27.069546 20971 solver.cpp:228] Iteration 1960, loss = 0.0824453
I0630 03:41:27.069597 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:41:27.069604 20971 solver.cpp:244]     Train net output #1: loss = 0.0793057 (* 1 = 0.0793057 loss)
I0630 03:41:27.069609 20971 sgd_solver.cpp:106] Iteration 1960, lr = 1e-05
I0630 03:43:13.164618 20971 solver.cpp:228] Iteration 1980, loss = 0.0754766
I0630 03:43:13.164721 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:43:13.164728 20971 solver.cpp:244]     Train net output #1: loss = 0.0724569 (* 1 = 0.0724569 loss)
I0630 03:43:13.164733 20971 sgd_solver.cpp:106] Iteration 1980, lr = 1e-05
I0630 03:45:00.291110 20971 solver.cpp:228] Iteration 2000, loss = 0.100363
I0630 03:45:00.291188 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:45:00.291195 20971 solver.cpp:244]     Train net output #1: loss = 0.136505 (* 1 = 0.136505 loss)
I0630 03:45:00.291199 20971 sgd_solver.cpp:106] Iteration 2000, lr = 1e-05
I0630 03:46:46.491555 20971 solver.cpp:228] Iteration 2020, loss = 0.0961378
I0630 03:46:46.491650 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:46:46.491658 20971 solver.cpp:244]     Train net output #1: loss = 0.0772791 (* 1 = 0.0772791 loss)
I0630 03:46:46.491663 20971 sgd_solver.cpp:106] Iteration 2020, lr = 1e-05
I0630 03:48:32.555042 20971 solver.cpp:228] Iteration 2040, loss = 0.0849573
I0630 03:48:32.555106 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:48:32.555114 20971 solver.cpp:244]     Train net output #1: loss = 0.112408 (* 1 = 0.112408 loss)
I0630 03:48:32.555119 20971 sgd_solver.cpp:106] Iteration 2040, lr = 1e-05
I0630 03:50:18.188174 20971 solver.cpp:228] Iteration 2060, loss = 0.136388
I0630 03:50:18.188246 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:50:18.188252 20971 solver.cpp:244]     Train net output #1: loss = 0.0952308 (* 1 = 0.0952308 loss)
I0630 03:50:18.188258 20971 sgd_solver.cpp:106] Iteration 2060, lr = 1e-05
I0630 03:52:03.691532 20971 solver.cpp:228] Iteration 2080, loss = 0.0774858
I0630 03:52:03.691608 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:52:03.691618 20971 solver.cpp:244]     Train net output #1: loss = 0.079719 (* 1 = 0.079719 loss)
I0630 03:52:03.691623 20971 sgd_solver.cpp:106] Iteration 2080, lr = 1e-05
I0630 03:53:50.988046 20971 solver.cpp:228] Iteration 2100, loss = 0.0829747
I0630 03:53:50.988119 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:53:50.988126 20971 solver.cpp:244]     Train net output #1: loss = 0.0816825 (* 1 = 0.0816825 loss)
I0630 03:53:50.988132 20971 sgd_solver.cpp:106] Iteration 2100, lr = 1e-05
I0630 03:55:36.617419 20971 solver.cpp:228] Iteration 2120, loss = 0.086525
I0630 03:55:36.617475 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:55:36.617481 20971 solver.cpp:244]     Train net output #1: loss = 0.0905152 (* 1 = 0.0905152 loss)
I0630 03:55:36.617487 20971 sgd_solver.cpp:106] Iteration 2120, lr = 1e-05
I0630 03:57:22.430734 20971 solver.cpp:228] Iteration 2140, loss = 0.0873366
I0630 03:57:22.430795 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:57:22.430804 20971 solver.cpp:244]     Train net output #1: loss = 0.0843532 (* 1 = 0.0843532 loss)
I0630 03:57:22.430809 20971 sgd_solver.cpp:106] Iteration 2140, lr = 1e-05
I0630 03:59:09.645174 20971 solver.cpp:228] Iteration 2160, loss = 0.0957501
I0630 03:59:09.645217 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 03:59:09.645231 20971 solver.cpp:244]     Train net output #1: loss = 0.132606 (* 1 = 0.132606 loss)
I0630 03:59:09.645247 20971 sgd_solver.cpp:106] Iteration 2160, lr = 1e-05
I0630 04:00:55.230903 20971 solver.cpp:228] Iteration 2180, loss = 0.104858
I0630 04:00:55.230975 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:00:55.230983 20971 solver.cpp:244]     Train net output #1: loss = 0.105391 (* 1 = 0.105391 loss)
I0630 04:00:55.230988 20971 sgd_solver.cpp:106] Iteration 2180, lr = 1e-05
I0630 04:02:45.857354 20971 solver.cpp:228] Iteration 2200, loss = 0.096044
I0630 04:02:45.857476 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:02:45.857484 20971 solver.cpp:244]     Train net output #1: loss = 0.100387 (* 1 = 0.100387 loss)
I0630 04:02:45.857489 20971 sgd_solver.cpp:106] Iteration 2200, lr = 1e-05
I0630 04:04:41.598580 20971 solver.cpp:228] Iteration 2220, loss = 0.0856975
I0630 04:04:41.598633 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:04:41.598639 20971 solver.cpp:244]     Train net output #1: loss = 0.102341 (* 1 = 0.102341 loss)
I0630 04:04:41.598644 20971 sgd_solver.cpp:106] Iteration 2220, lr = 1e-05
I0630 04:06:27.218902 20971 solver.cpp:228] Iteration 2240, loss = 0.108653
I0630 04:06:27.219007 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:06:27.219018 20971 solver.cpp:244]     Train net output #1: loss = 0.106901 (* 1 = 0.106901 loss)
I0630 04:06:27.219023 20971 sgd_solver.cpp:106] Iteration 2240, lr = 1e-05
I0630 04:08:12.734227 20971 solver.cpp:228] Iteration 2260, loss = 0.0902453
I0630 04:08:12.734319 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:08:12.734326 20971 solver.cpp:244]     Train net output #1: loss = 0.0810377 (* 1 = 0.0810377 loss)
I0630 04:08:12.734331 20971 sgd_solver.cpp:106] Iteration 2260, lr = 1e-05
I0630 04:09:58.265395 20971 solver.cpp:228] Iteration 2280, loss = 0.0978533
I0630 04:09:58.265467 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:09:58.265475 20971 solver.cpp:244]     Train net output #1: loss = 0.0768891 (* 1 = 0.0768891 loss)
I0630 04:09:58.265480 20971 sgd_solver.cpp:106] Iteration 2280, lr = 1e-05
I0630 04:11:43.815199 20971 solver.cpp:228] Iteration 2300, loss = 0.107044
I0630 04:11:43.815291 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:11:43.815300 20971 solver.cpp:244]     Train net output #1: loss = 0.107029 (* 1 = 0.107029 loss)
I0630 04:11:43.815305 20971 sgd_solver.cpp:106] Iteration 2300, lr = 1e-05
I0630 04:13:29.731266 20971 solver.cpp:228] Iteration 2320, loss = 0.0822135
I0630 04:13:29.731371 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:13:29.731389 20971 solver.cpp:244]     Train net output #1: loss = 0.077035 (* 1 = 0.077035 loss)
I0630 04:13:29.731392 20971 sgd_solver.cpp:106] Iteration 2320, lr = 1e-05
I0630 04:15:15.290561 20971 solver.cpp:228] Iteration 2340, loss = 0.0729709
I0630 04:15:15.290628 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:15:15.290637 20971 solver.cpp:244]     Train net output #1: loss = 0.06547 (* 1 = 0.06547 loss)
I0630 04:15:15.290649 20971 sgd_solver.cpp:106] Iteration 2340, lr = 1e-05
I0630 04:17:00.900511 20971 solver.cpp:228] Iteration 2360, loss = 0.0965422
I0630 04:17:00.900590 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:17:00.900599 20971 solver.cpp:244]     Train net output #1: loss = 0.122378 (* 1 = 0.122378 loss)
I0630 04:17:00.900604 20971 sgd_solver.cpp:106] Iteration 2360, lr = 1e-05
I0630 04:18:46.477984 20971 solver.cpp:228] Iteration 2380, loss = 0.0946121
I0630 04:18:46.478060 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:18:46.478067 20971 solver.cpp:244]     Train net output #1: loss = 0.0750133 (* 1 = 0.0750133 loss)
I0630 04:18:46.478072 20971 sgd_solver.cpp:106] Iteration 2380, lr = 1e-05
I0630 04:20:34.258769 20971 solver.cpp:228] Iteration 2400, loss = 0.0826278
I0630 04:20:34.258867 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:20:34.258880 20971 solver.cpp:244]     Train net output #1: loss = 0.109052 (* 1 = 0.109052 loss)
I0630 04:20:34.258889 20971 sgd_solver.cpp:106] Iteration 2400, lr = 1e-05
I0630 04:22:22.148929 20971 solver.cpp:228] Iteration 2420, loss = 0.129881
I0630 04:22:22.149003 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:22:22.149010 20971 solver.cpp:244]     Train net output #1: loss = 0.0769376 (* 1 = 0.0769376 loss)
I0630 04:22:22.149015 20971 sgd_solver.cpp:106] Iteration 2420, lr = 1e-05
I0630 04:24:08.992931 20971 solver.cpp:228] Iteration 2440, loss = 0.0754505
I0630 04:24:08.992975 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:24:08.992981 20971 solver.cpp:244]     Train net output #1: loss = 0.0781443 (* 1 = 0.0781443 loss)
I0630 04:24:08.992986 20971 sgd_solver.cpp:106] Iteration 2440, lr = 1e-05
I0630 04:25:56.391273 20971 solver.cpp:228] Iteration 2460, loss = 0.0798752
I0630 04:25:56.391324 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:25:56.391330 20971 solver.cpp:244]     Train net output #1: loss = 0.0772661 (* 1 = 0.0772661 loss)
I0630 04:25:56.391335 20971 sgd_solver.cpp:106] Iteration 2460, lr = 1e-05
I0630 04:27:43.851086 20971 solver.cpp:228] Iteration 2480, loss = 0.0833388
I0630 04:27:43.851176 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:27:43.851183 20971 solver.cpp:244]     Train net output #1: loss = 0.0861183 (* 1 = 0.0861183 loss)
I0630 04:27:43.851188 20971 sgd_solver.cpp:106] Iteration 2480, lr = 1e-05
I0630 04:29:26.274952 20971 solver.cpp:454] Snapshotting to binary proto file ./snapshots/davis_sequence_simple_iter_2500.caffemodel
I0630 04:29:30.927166 20971 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/davis_sequence_simple_iter_2500.solverstate
I0630 04:29:32.812511 20971 solver.cpp:228] Iteration 2500, loss = 0.0864147
I0630 04:29:32.812542 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:29:32.812548 20971 solver.cpp:244]     Train net output #1: loss = 0.0821643 (* 1 = 0.0821643 loss)
I0630 04:29:32.812552 20971 sgd_solver.cpp:106] Iteration 2500, lr = 1e-06
I0630 04:31:20.880789 20971 solver.cpp:228] Iteration 2520, loss = 0.0904375
I0630 04:31:20.880839 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:31:20.880846 20971 solver.cpp:244]     Train net output #1: loss = 0.0938269 (* 1 = 0.0938269 loss)
I0630 04:31:20.880851 20971 sgd_solver.cpp:106] Iteration 2520, lr = 1e-06
I0630 04:33:06.975584 20971 solver.cpp:228] Iteration 2540, loss = 0.0991138
I0630 04:33:06.975635 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:33:06.975641 20971 solver.cpp:244]     Train net output #1: loss = 0.0990468 (* 1 = 0.0990468 loss)
I0630 04:33:06.975646 20971 sgd_solver.cpp:106] Iteration 2540, lr = 1e-06
I0630 04:34:56.750802 20971 solver.cpp:228] Iteration 2560, loss = 0.0952595
I0630 04:34:56.750880 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:34:56.750887 20971 solver.cpp:244]     Train net output #1: loss = 0.0797522 (* 1 = 0.0797522 loss)
I0630 04:34:56.750891 20971 sgd_solver.cpp:106] Iteration 2560, lr = 1e-06
I0630 04:36:51.571328 20971 solver.cpp:228] Iteration 2580, loss = 0.0760253
I0630 04:36:51.571436 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:36:51.571446 20971 solver.cpp:244]     Train net output #1: loss = 0.095884 (* 1 = 0.095884 loss)
I0630 04:36:51.571450 20971 sgd_solver.cpp:106] Iteration 2580, lr = 1e-06
I0630 04:38:37.936061 20971 solver.cpp:228] Iteration 2600, loss = 0.0985653
I0630 04:38:37.936156 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:38:37.936163 20971 solver.cpp:244]     Train net output #1: loss = 0.101674 (* 1 = 0.101674 loss)
I0630 04:38:37.936167 20971 sgd_solver.cpp:106] Iteration 2600, lr = 1e-06
I0630 04:40:30.346042 20971 solver.cpp:228] Iteration 2620, loss = 0.0898886
I0630 04:40:30.346272 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:40:30.346304 20971 solver.cpp:244]     Train net output #1: loss = 0.086925 (* 1 = 0.086925 loss)
I0630 04:40:30.346325 20971 sgd_solver.cpp:106] Iteration 2620, lr = 1e-06
I0630 04:42:15.988792 20971 solver.cpp:228] Iteration 2640, loss = 0.100564
I0630 04:42:15.988852 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:42:15.988859 20971 solver.cpp:244]     Train net output #1: loss = 0.0956394 (* 1 = 0.0956394 loss)
I0630 04:42:15.988863 20971 sgd_solver.cpp:106] Iteration 2640, lr = 1e-06
I0630 04:44:01.917265 20971 solver.cpp:228] Iteration 2660, loss = 0.0946167
I0630 04:44:01.917362 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:44:01.917369 20971 solver.cpp:244]     Train net output #1: loss = 0.0969603 (* 1 = 0.0969603 loss)
I0630 04:44:01.917374 20971 sgd_solver.cpp:106] Iteration 2660, lr = 1e-06
I0630 04:45:48.523172 20971 solver.cpp:228] Iteration 2680, loss = 0.087005
I0630 04:45:48.523249 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:45:48.523257 20971 solver.cpp:244]     Train net output #1: loss = 0.114318 (* 1 = 0.114318 loss)
I0630 04:45:48.523270 20971 sgd_solver.cpp:106] Iteration 2680, lr = 1e-06
I0630 04:47:35.042937 20971 solver.cpp:228] Iteration 2700, loss = 0.0818891
I0630 04:47:35.043018 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:47:35.043025 20971 solver.cpp:244]     Train net output #1: loss = 0.0738405 (* 1 = 0.0738405 loss)
I0630 04:47:35.043030 20971 sgd_solver.cpp:106] Iteration 2700, lr = 1e-06
I0630 04:49:20.805876 20971 solver.cpp:228] Iteration 2720, loss = 0.0936796
I0630 04:49:20.805943 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:49:20.805955 20971 solver.cpp:244]     Train net output #1: loss = 0.117533 (* 1 = 0.117533 loss)
I0630 04:49:20.805965 20971 sgd_solver.cpp:106] Iteration 2720, lr = 1e-06
I0630 04:51:06.794137 20971 solver.cpp:228] Iteration 2740, loss = 0.104655
I0630 04:51:06.794266 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:51:06.794277 20971 solver.cpp:244]     Train net output #1: loss = 0.0760895 (* 1 = 0.0760895 loss)
I0630 04:51:06.794284 20971 sgd_solver.cpp:106] Iteration 2740, lr = 1e-06
I0630 04:52:52.432983 20971 solver.cpp:228] Iteration 2760, loss = 0.0797162
I0630 04:52:52.433058 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:52:52.433065 20971 solver.cpp:244]     Train net output #1: loss = 0.103229 (* 1 = 0.103229 loss)
I0630 04:52:52.433070 20971 sgd_solver.cpp:106] Iteration 2760, lr = 1e-06
I0630 04:54:38.110821 20971 solver.cpp:228] Iteration 2780, loss = 0.101178
I0630 04:54:38.110893 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:54:38.110901 20971 solver.cpp:244]     Train net output #1: loss = 0.106728 (* 1 = 0.106728 loss)
I0630 04:54:38.110908 20971 sgd_solver.cpp:106] Iteration 2780, lr = 1e-06
I0630 04:56:24.815385 20971 solver.cpp:228] Iteration 2800, loss = 0.0803499
I0630 04:56:24.815436 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:56:24.815443 20971 solver.cpp:244]     Train net output #1: loss = 0.0755924 (* 1 = 0.0755924 loss)
I0630 04:56:24.815448 20971 sgd_solver.cpp:106] Iteration 2800, lr = 1e-06
I0630 04:58:14.115555 20971 solver.cpp:228] Iteration 2820, loss = 0.0839306
I0630 04:58:14.115628 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 04:58:14.115635 20971 solver.cpp:244]     Train net output #1: loss = 0.0768541 (* 1 = 0.0768541 loss)
I0630 04:58:14.115640 20971 sgd_solver.cpp:106] Iteration 2820, lr = 1e-06
I0630 05:00:00.508746 20971 solver.cpp:228] Iteration 2840, loss = 0.0838071
I0630 05:00:00.508805 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:00:00.508812 20971 solver.cpp:244]     Train net output #1: loss = 0.0899521 (* 1 = 0.0899521 loss)
I0630 05:00:00.508816 20971 sgd_solver.cpp:106] Iteration 2840, lr = 1e-06
I0630 05:01:49.361346 20971 solver.cpp:228] Iteration 2860, loss = 0.0910111
I0630 05:01:49.361418 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:01:49.361424 20971 solver.cpp:244]     Train net output #1: loss = 0.0718526 (* 1 = 0.0718526 loss)
I0630 05:01:49.361429 20971 sgd_solver.cpp:106] Iteration 2860, lr = 1e-06
I0630 05:03:38.511513 20971 solver.cpp:228] Iteration 2880, loss = 0.086978
I0630 05:03:38.511597 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:03:38.511605 20971 solver.cpp:244]     Train net output #1: loss = 0.0884144 (* 1 = 0.0884144 loss)
I0630 05:03:38.511610 20971 sgd_solver.cpp:106] Iteration 2880, lr = 1e-06
I0630 05:05:25.414849 20971 solver.cpp:228] Iteration 2900, loss = 0.100533
I0630 05:05:25.414922 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:05:25.414939 20971 solver.cpp:244]     Train net output #1: loss = 0.0972339 (* 1 = 0.0972339 loss)
I0630 05:05:25.414948 20971 sgd_solver.cpp:106] Iteration 2900, lr = 1e-06
I0630 05:07:13.466553 20971 solver.cpp:228] Iteration 2920, loss = 0.0969416
I0630 05:07:13.466634 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:07:13.466642 20971 solver.cpp:244]     Train net output #1: loss = 0.0703608 (* 1 = 0.0703608 loss)
I0630 05:07:13.466650 20971 sgd_solver.cpp:106] Iteration 2920, lr = 1e-06
I0630 05:09:19.240088 20971 solver.cpp:228] Iteration 2940, loss = 0.07329
I0630 05:09:19.240146 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:09:19.240156 20971 solver.cpp:244]     Train net output #1: loss = 0.093036 (* 1 = 0.093036 loss)
I0630 05:09:19.240164 20971 sgd_solver.cpp:106] Iteration 2940, lr = 1e-06
I0630 05:11:12.709710 20971 solver.cpp:228] Iteration 2960, loss = 0.0914989
I0630 05:11:12.709810 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:11:12.709817 20971 solver.cpp:244]     Train net output #1: loss = 0.0854213 (* 1 = 0.0854213 loss)
I0630 05:11:12.709822 20971 sgd_solver.cpp:106] Iteration 2960, lr = 1e-06
I0630 05:13:01.612634 20971 solver.cpp:228] Iteration 2980, loss = 0.0914686
I0630 05:13:01.612730 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:13:01.612737 20971 solver.cpp:244]     Train net output #1: loss = 0.0788582 (* 1 = 0.0788582 loss)
I0630 05:13:01.612742 20971 sgd_solver.cpp:106] Iteration 2980, lr = 1e-06
I0630 05:14:47.911360 20971 solver.cpp:228] Iteration 3000, loss = 0.0956256
I0630 05:14:47.911440 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:14:47.911448 20971 solver.cpp:244]     Train net output #1: loss = 0.0876639 (* 1 = 0.0876639 loss)
I0630 05:14:47.911455 20971 sgd_solver.cpp:106] Iteration 3000, lr = 1e-06
I0630 05:16:34.495576 20971 solver.cpp:228] Iteration 3020, loss = 0.096633
I0630 05:16:34.495630 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:16:34.495636 20971 solver.cpp:244]     Train net output #1: loss = 0.0996669 (* 1 = 0.0996669 loss)
I0630 05:16:34.495641 20971 sgd_solver.cpp:106] Iteration 3020, lr = 1e-06
I0630 05:18:22.471099 20971 solver.cpp:228] Iteration 3040, loss = 0.0859528
I0630 05:18:22.471149 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:18:22.471156 20971 solver.cpp:244]     Train net output #1: loss = 0.0812015 (* 1 = 0.0812015 loss)
I0630 05:18:22.471161 20971 sgd_solver.cpp:106] Iteration 3040, lr = 1e-06
I0630 05:20:09.103272 20971 solver.cpp:228] Iteration 3060, loss = 0.0778357
I0630 05:20:09.103323 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:20:09.103330 20971 solver.cpp:244]     Train net output #1: loss = 0.0789089 (* 1 = 0.0789089 loss)
I0630 05:20:09.103340 20971 sgd_solver.cpp:106] Iteration 3060, lr = 1e-06
I0630 05:21:55.766598 20971 solver.cpp:228] Iteration 3080, loss = 0.0877686
I0630 05:21:55.766700 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:21:55.766710 20971 solver.cpp:244]     Train net output #1: loss = 0.11064 (* 1 = 0.11064 loss)
I0630 05:21:55.766715 20971 sgd_solver.cpp:106] Iteration 3080, lr = 1e-06
I0630 05:23:47.445624 20971 solver.cpp:228] Iteration 3100, loss = 0.102598
I0630 05:23:47.445684 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:23:47.445694 20971 solver.cpp:244]     Train net output #1: loss = 0.0749249 (* 1 = 0.0749249 loss)
I0630 05:23:47.445703 20971 sgd_solver.cpp:106] Iteration 3100, lr = 1e-06
I0630 05:25:34.186867 20971 solver.cpp:228] Iteration 3120, loss = 0.0768106
I0630 05:25:34.186954 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:25:34.186961 20971 solver.cpp:244]     Train net output #1: loss = 0.0818429 (* 1 = 0.0818429 loss)
I0630 05:25:34.186966 20971 sgd_solver.cpp:106] Iteration 3120, lr = 1e-06
I0630 05:27:19.812261 20971 solver.cpp:228] Iteration 3140, loss = 0.100384
I0630 05:27:19.812311 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:27:19.812319 20971 solver.cpp:244]     Train net output #1: loss = 0.105341 (* 1 = 0.105341 loss)
I0630 05:27:19.812324 20971 sgd_solver.cpp:106] Iteration 3140, lr = 1e-06
I0630 05:29:06.155812 20971 solver.cpp:228] Iteration 3160, loss = 0.084261
I0630 05:29:06.155920 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:29:06.155933 20971 solver.cpp:244]     Train net output #1: loss = 0.0806007 (* 1 = 0.0806007 loss)
I0630 05:29:06.155941 20971 sgd_solver.cpp:106] Iteration 3160, lr = 1e-06
I0630 05:30:52.403789 20971 solver.cpp:228] Iteration 3180, loss = 0.0930248
I0630 05:30:52.403890 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:30:52.403898 20971 solver.cpp:244]     Train net output #1: loss = 0.0859678 (* 1 = 0.0859678 loss)
I0630 05:30:52.403903 20971 sgd_solver.cpp:106] Iteration 3180, lr = 1e-06
I0630 05:32:39.679854 20971 solver.cpp:228] Iteration 3200, loss = 0.0829928
I0630 05:32:39.679978 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:32:39.679991 20971 solver.cpp:244]     Train net output #1: loss = 0.0768418 (* 1 = 0.0768418 loss)
I0630 05:32:39.679999 20971 sgd_solver.cpp:106] Iteration 3200, lr = 1e-06
I0630 05:34:27.785087 20971 solver.cpp:228] Iteration 3220, loss = 0.0937261
I0630 05:34:27.785161 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:34:27.785171 20971 solver.cpp:244]     Train net output #1: loss = 0.0738731 (* 1 = 0.0738731 loss)
I0630 05:34:27.785176 20971 sgd_solver.cpp:106] Iteration 3220, lr = 1e-06
I0630 05:36:25.188916 20971 solver.cpp:228] Iteration 3240, loss = 0.0864168
I0630 05:36:25.189023 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:36:25.189036 20971 solver.cpp:244]     Train net output #1: loss = 0.0852791 (* 1 = 0.0852791 loss)
I0630 05:36:25.189043 20971 sgd_solver.cpp:106] Iteration 3240, lr = 1e-06
I0630 05:38:18.675134 20971 solver.cpp:228] Iteration 3260, loss = 0.095025
I0630 05:38:18.675182 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:38:18.675189 20971 solver.cpp:244]     Train net output #1: loss = 0.0933674 (* 1 = 0.0933674 loss)
I0630 05:38:18.675194 20971 sgd_solver.cpp:106] Iteration 3260, lr = 1e-06
I0630 05:40:07.563385 20971 solver.cpp:228] Iteration 3280, loss = 0.0975158
I0630 05:40:07.563446 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:40:07.563452 20971 solver.cpp:244]     Train net output #1: loss = 0.0667533 (* 1 = 0.0667533 loss)
I0630 05:40:07.563457 20971 sgd_solver.cpp:106] Iteration 3280, lr = 1e-06
I0630 05:42:04.058477 20971 solver.cpp:228] Iteration 3300, loss = 0.0734109
I0630 05:42:04.058562 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:42:04.058569 20971 solver.cpp:244]     Train net output #1: loss = 0.0840223 (* 1 = 0.0840223 loss)
I0630 05:42:04.058574 20971 sgd_solver.cpp:106] Iteration 3300, lr = 1e-06
I0630 05:43:51.097961 20971 solver.cpp:228] Iteration 3320, loss = 0.100022
I0630 05:43:51.098023 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:43:51.098031 20971 solver.cpp:244]     Train net output #1: loss = 0.0847561 (* 1 = 0.0847561 loss)
I0630 05:43:51.098036 20971 sgd_solver.cpp:106] Iteration 3320, lr = 1e-06
I0630 05:45:38.199311 20971 solver.cpp:228] Iteration 3340, loss = 0.0927124
I0630 05:45:38.199417 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:45:38.199427 20971 solver.cpp:244]     Train net output #1: loss = 0.0773119 (* 1 = 0.0773119 loss)
I0630 05:45:38.199432 20971 sgd_solver.cpp:106] Iteration 3340, lr = 1e-06
I0630 05:47:26.157091 20971 solver.cpp:228] Iteration 3360, loss = 0.0974082
I0630 05:47:26.157137 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:47:26.157146 20971 solver.cpp:244]     Train net output #1: loss = 0.0828192 (* 1 = 0.0828192 loss)
I0630 05:47:26.157152 20971 sgd_solver.cpp:106] Iteration 3360, lr = 1e-06
I0630 05:49:15.267576 20971 solver.cpp:228] Iteration 3380, loss = 0.09532
I0630 05:49:15.267621 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:49:15.267628 20971 solver.cpp:244]     Train net output #1: loss = 0.0987626 (* 1 = 0.0987626 loss)
I0630 05:49:15.267633 20971 sgd_solver.cpp:106] Iteration 3380, lr = 1e-06
I0630 05:51:08.070674 20971 solver.cpp:228] Iteration 3400, loss = 0.0870545
I0630 05:51:08.070776 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:51:08.070790 20971 solver.cpp:244]     Train net output #1: loss = 0.0851744 (* 1 = 0.0851744 loss)
I0630 05:51:08.070796 20971 sgd_solver.cpp:106] Iteration 3400, lr = 1e-06
I0630 05:52:54.972790 20971 solver.cpp:228] Iteration 3420, loss = 0.0832102
I0630 05:52:54.972892 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:52:54.972901 20971 solver.cpp:244]     Train net output #1: loss = 0.0810197 (* 1 = 0.0810197 loss)
I0630 05:52:54.972906 20971 sgd_solver.cpp:106] Iteration 3420, lr = 1e-06
I0630 05:54:43.929774 20971 solver.cpp:228] Iteration 3440, loss = 0.0858885
I0630 05:54:43.929843 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:54:43.929854 20971 solver.cpp:244]     Train net output #1: loss = 0.105704 (* 1 = 0.105704 loss)
I0630 05:54:43.929870 20971 sgd_solver.cpp:106] Iteration 3440, lr = 1e-06
I0630 05:56:37.985621 20971 solver.cpp:228] Iteration 3460, loss = 0.100736
I0630 05:56:37.985671 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:56:37.985677 20971 solver.cpp:244]     Train net output #1: loss = 0.0693246 (* 1 = 0.0693246 loss)
I0630 05:56:37.985682 20971 sgd_solver.cpp:106] Iteration 3460, lr = 1e-06
I0630 05:58:26.278826 20971 solver.cpp:228] Iteration 3480, loss = 0.075893
I0630 05:58:26.278944 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 05:58:26.278954 20971 solver.cpp:244]     Train net output #1: loss = 0.0854639 (* 1 = 0.0854639 loss)
I0630 05:58:26.278959 20971 sgd_solver.cpp:106] Iteration 3480, lr = 1e-06
I0630 06:00:13.067451 20971 solver.cpp:228] Iteration 3500, loss = 0.103304
I0630 06:00:13.067973 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:00:13.067982 20971 solver.cpp:244]     Train net output #1: loss = 0.11021 (* 1 = 0.11021 loss)
I0630 06:00:13.067987 20971 sgd_solver.cpp:106] Iteration 3500, lr = 1e-06
I0630 06:02:00.608371 20971 solver.cpp:228] Iteration 3520, loss = 0.0837082
I0630 06:02:00.608464 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:02:00.608472 20971 solver.cpp:244]     Train net output #1: loss = 0.0729819 (* 1 = 0.0729819 loss)
I0630 06:02:00.608477 20971 sgd_solver.cpp:106] Iteration 3520, lr = 1e-06
I0630 06:03:46.488742 20971 solver.cpp:228] Iteration 3540, loss = 0.0846776
I0630 06:03:46.488822 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:03:46.488833 20971 solver.cpp:244]     Train net output #1: loss = 0.0806939 (* 1 = 0.0806939 loss)
I0630 06:03:46.488839 20971 sgd_solver.cpp:106] Iteration 3540, lr = 1e-06
I0630 06:05:32.034029 20971 solver.cpp:228] Iteration 3560, loss = 0.0831458
I0630 06:05:32.034083 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:05:32.034092 20971 solver.cpp:244]     Train net output #1: loss = 0.0740366 (* 1 = 0.0740366 loss)
I0630 06:05:32.034098 20971 sgd_solver.cpp:106] Iteration 3560, lr = 1e-06
I0630 06:07:18.501088 20971 solver.cpp:228] Iteration 3580, loss = 0.0912079
I0630 06:07:18.501178 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:07:18.501184 20971 solver.cpp:244]     Train net output #1: loss = 0.0816778 (* 1 = 0.0816778 loss)
I0630 06:07:18.501188 20971 sgd_solver.cpp:106] Iteration 3580, lr = 1e-06
I0630 06:09:06.825567 20971 solver.cpp:228] Iteration 3600, loss = 0.0857215
I0630 06:09:06.825678 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:09:06.825697 20971 solver.cpp:244]     Train net output #1: loss = 0.0883474 (* 1 = 0.0883474 loss)
I0630 06:09:06.825706 20971 sgd_solver.cpp:106] Iteration 3600, lr = 1e-06
I0630 06:10:55.155522 20971 solver.cpp:228] Iteration 3620, loss = 0.0954982
I0630 06:10:55.155566 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:10:55.155575 20971 solver.cpp:244]     Train net output #1: loss = 0.0935217 (* 1 = 0.0935217 loss)
I0630 06:10:55.155580 20971 sgd_solver.cpp:106] Iteration 3620, lr = 1e-06
I0630 06:12:42.242846 20971 solver.cpp:228] Iteration 3640, loss = 0.100245
I0630 06:12:42.242918 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:12:42.242926 20971 solver.cpp:244]     Train net output #1: loss = 0.0924003 (* 1 = 0.0924003 loss)
I0630 06:12:42.242930 20971 sgd_solver.cpp:106] Iteration 3640, lr = 1e-06
I0630 06:14:39.119719 20971 solver.cpp:228] Iteration 3660, loss = 0.0714264
I0630 06:14:39.119853 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:14:39.119870 20971 solver.cpp:244]     Train net output #1: loss = 0.0743318 (* 1 = 0.0743318 loss)
I0630 06:14:39.119874 20971 sgd_solver.cpp:106] Iteration 3660, lr = 1e-06
I0630 06:16:26.338134 20971 solver.cpp:228] Iteration 3680, loss = 0.0942105
I0630 06:16:26.338188 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:16:26.338196 20971 solver.cpp:244]     Train net output #1: loss = 0.0763882 (* 1 = 0.0763882 loss)
I0630 06:16:26.338201 20971 sgd_solver.cpp:106] Iteration 3680, lr = 1e-06
I0630 06:18:13.535374 20971 solver.cpp:228] Iteration 3700, loss = 0.0919152
I0630 06:18:13.535939 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:18:13.535949 20971 solver.cpp:244]     Train net output #1: loss = 0.0780703 (* 1 = 0.0780703 loss)
I0630 06:18:13.535954 20971 sgd_solver.cpp:106] Iteration 3700, lr = 1e-06
I0630 06:19:59.490730 20971 solver.cpp:228] Iteration 3720, loss = 0.0934411
I0630 06:19:59.490783 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:19:59.490792 20971 solver.cpp:244]     Train net output #1: loss = 0.117184 (* 1 = 0.117184 loss)
I0630 06:19:59.490797 20971 sgd_solver.cpp:106] Iteration 3720, lr = 1e-06
I0630 06:21:45.179141 20971 solver.cpp:228] Iteration 3740, loss = 0.0972734
I0630 06:21:45.179198 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:21:45.179205 20971 solver.cpp:244]     Train net output #1: loss = 0.103869 (* 1 = 0.103869 loss)
I0630 06:21:45.179209 20971 sgd_solver.cpp:106] Iteration 3740, lr = 1e-06
I0630 06:22:32.744285 20971 solver.cpp:454] Snapshotting to binary proto file ./snapshots/davis_sequence_simple_iter_3750.caffemodel
I0630 06:22:37.594835 20971 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/davis_sequence_simple_iter_3750.solverstate
I0630 06:23:34.441691 20971 solver.cpp:228] Iteration 3760, loss = 0.0876783
I0630 06:23:34.441776 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:23:34.441784 20971 solver.cpp:244]     Train net output #1: loss = 0.0730193 (* 1 = 0.0730193 loss)
I0630 06:23:34.441788 20971 sgd_solver.cpp:106] Iteration 3760, lr = 1e-06
I0630 06:25:20.044701 20971 solver.cpp:228] Iteration 3780, loss = 0.0782744
I0630 06:25:20.044747 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:25:20.044754 20971 solver.cpp:244]     Train net output #1: loss = 0.075812 (* 1 = 0.075812 loss)
I0630 06:25:20.044759 20971 sgd_solver.cpp:106] Iteration 3780, lr = 1e-06
I0630 06:27:07.160126 20971 solver.cpp:228] Iteration 3800, loss = 0.0829235
I0630 06:27:07.160241 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:27:07.160250 20971 solver.cpp:244]     Train net output #1: loss = 0.124709 (* 1 = 0.124709 loss)
I0630 06:27:07.160255 20971 sgd_solver.cpp:106] Iteration 3800, lr = 1e-06
I0630 06:28:57.486824 20971 solver.cpp:228] Iteration 3820, loss = 0.107623
I0630 06:28:57.486976 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:28:57.486986 20971 solver.cpp:244]     Train net output #1: loss = 0.099462 (* 1 = 0.099462 loss)
I0630 06:28:57.486990 20971 sgd_solver.cpp:106] Iteration 3820, lr = 1e-06
I0630 06:30:48.277770 20971 solver.cpp:228] Iteration 3840, loss = 0.0755337
I0630 06:30:48.277844 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:30:48.277854 20971 solver.cpp:244]     Train net output #1: loss = 0.0823426 (* 1 = 0.0823426 loss)
I0630 06:30:48.277861 20971 sgd_solver.cpp:106] Iteration 3840, lr = 1e-06
I0630 06:32:35.645280 20971 solver.cpp:228] Iteration 3860, loss = 0.0999545
I0630 06:32:35.645339 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:32:35.645346 20971 solver.cpp:244]     Train net output #1: loss = 0.102104 (* 1 = 0.102104 loss)
I0630 06:32:35.645351 20971 sgd_solver.cpp:106] Iteration 3860, lr = 1e-06
I0630 06:34:22.231829 20971 solver.cpp:228] Iteration 3880, loss = 0.0905977
I0630 06:34:22.231928 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:34:22.231938 20971 solver.cpp:244]     Train net output #1: loss = 0.0826267 (* 1 = 0.0826267 loss)
I0630 06:34:22.231945 20971 sgd_solver.cpp:106] Iteration 3880, lr = 1e-06
I0630 06:36:08.813596 20971 solver.cpp:228] Iteration 3900, loss = 0.0839565
I0630 06:36:08.813812 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:36:08.813856 20971 solver.cpp:244]     Train net output #1: loss = 0.0824926 (* 1 = 0.0824926 loss)
I0630 06:36:08.813891 20971 sgd_solver.cpp:106] Iteration 3900, lr = 1e-06
I0630 06:37:58.391059 20971 solver.cpp:228] Iteration 3920, loss = 0.0829959
I0630 06:37:58.391124 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:37:58.391130 20971 solver.cpp:244]     Train net output #1: loss = 0.100786 (* 1 = 0.100786 loss)
I0630 06:37:58.391135 20971 sgd_solver.cpp:106] Iteration 3920, lr = 1e-06
I0630 06:39:45.027027 20971 solver.cpp:228] Iteration 3940, loss = 0.093315
I0630 06:39:45.034476 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:39:45.034487 20971 solver.cpp:244]     Train net output #1: loss = 0.0807957 (* 1 = 0.0807957 loss)
I0630 06:39:45.034492 20971 sgd_solver.cpp:106] Iteration 3940, lr = 1e-06
I0630 06:41:32.928462 20971 solver.cpp:228] Iteration 3960, loss = 0.084611
I0630 06:41:32.928509 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:41:32.928516 20971 solver.cpp:244]     Train net output #1: loss = 0.108931 (* 1 = 0.108931 loss)
I0630 06:41:32.928521 20971 sgd_solver.cpp:106] Iteration 3960, lr = 1e-06
I0630 06:43:20.217017 20971 solver.cpp:228] Iteration 3980, loss = 0.0939677
I0630 06:43:20.217108 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:43:20.217114 20971 solver.cpp:244]     Train net output #1: loss = 0.0971255 (* 1 = 0.0971255 loss)
I0630 06:43:20.217119 20971 sgd_solver.cpp:106] Iteration 3980, lr = 1e-06
I0630 06:45:05.959750 20971 solver.cpp:228] Iteration 4000, loss = 0.103243
I0630 06:45:05.959852 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:45:05.959862 20971 solver.cpp:244]     Train net output #1: loss = 0.122365 (* 1 = 0.122365 loss)
I0630 06:45:05.959867 20971 sgd_solver.cpp:106] Iteration 4000, lr = 1e-06
I0630 06:47:03.331213 20971 solver.cpp:228] Iteration 4020, loss = 0.0738212
I0630 06:47:03.331270 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:47:03.331279 20971 solver.cpp:244]     Train net output #1: loss = 0.072447 (* 1 = 0.072447 loss)
I0630 06:47:03.331282 20971 sgd_solver.cpp:106] Iteration 4020, lr = 1e-06
I0630 06:48:49.994514 20971 solver.cpp:228] Iteration 4040, loss = 0.0951456
I0630 06:48:49.994572 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:48:49.994580 20971 solver.cpp:244]     Train net output #1: loss = 0.0932944 (* 1 = 0.0932944 loss)
I0630 06:48:49.994585 20971 sgd_solver.cpp:106] Iteration 4040, lr = 1e-06
I0630 06:50:36.460623 20971 solver.cpp:228] Iteration 4060, loss = 0.0927374
I0630 06:50:36.460670 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:50:36.460677 20971 solver.cpp:244]     Train net output #1: loss = 0.0896192 (* 1 = 0.0896192 loss)
I0630 06:50:36.460682 20971 sgd_solver.cpp:106] Iteration 4060, lr = 1e-06
I0630 06:52:23.345144 20971 solver.cpp:228] Iteration 4080, loss = 0.089215
I0630 06:52:23.345252 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:52:23.345265 20971 solver.cpp:244]     Train net output #1: loss = 0.10797 (* 1 = 0.10797 loss)
I0630 06:52:23.345274 20971 sgd_solver.cpp:106] Iteration 4080, lr = 1e-06
I0630 06:54:09.648069 20971 solver.cpp:228] Iteration 4100, loss = 0.095686
I0630 06:54:09.648118 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:54:09.648123 20971 solver.cpp:244]     Train net output #1: loss = 0.0927226 (* 1 = 0.0927226 loss)
I0630 06:54:09.648128 20971 sgd_solver.cpp:106] Iteration 4100, lr = 1e-06
I0630 06:55:55.710419 20971 solver.cpp:228] Iteration 4120, loss = 0.0921424
I0630 06:55:55.710547 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:55:55.710557 20971 solver.cpp:244]     Train net output #1: loss = 0.0735152 (* 1 = 0.0735152 loss)
I0630 06:55:55.710563 20971 sgd_solver.cpp:106] Iteration 4120, lr = 1e-06
I0630 06:57:41.815866 20971 solver.cpp:228] Iteration 4140, loss = 0.0775927
I0630 06:57:41.815943 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:57:41.815949 20971 solver.cpp:244]     Train net output #1: loss = 0.0688268 (* 1 = 0.0688268 loss)
I0630 06:57:41.815955 20971 sgd_solver.cpp:106] Iteration 4140, lr = 1e-06
I0630 06:59:28.982763 20971 solver.cpp:228] Iteration 4160, loss = 0.0781194
I0630 06:59:28.982810 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 06:59:28.982818 20971 solver.cpp:244]     Train net output #1: loss = 0.0959809 (* 1 = 0.0959809 loss)
I0630 06:59:28.982822 20971 sgd_solver.cpp:106] Iteration 4160, lr = 1e-06
I0630 07:01:15.488528 20971 solver.cpp:228] Iteration 4180, loss = 0.109822
I0630 07:01:15.488610 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 07:01:15.488617 20971 solver.cpp:244]     Train net output #1: loss = 0.10494 (* 1 = 0.10494 loss)
I0630 07:01:15.488622 20971 sgd_solver.cpp:106] Iteration 4180, lr = 1e-06
I0630 07:02:51.612376 20971 solver.cpp:454] Snapshotting to binary proto file ./snapshots/davis_sequence_simple_iter_4199.caffemodel
I0630 07:02:56.230785 20971 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/davis_sequence_simple_iter_4199.solverstate
I0630 07:03:03.409899 20971 solver.cpp:228] Iteration 4200, loss = 0.0771535
I0630 07:03:03.409920 20971 solver.cpp:244]     Train net output #0: clinet_top = 0
I0630 07:03:03.409927 20971 solver.cpp:244]     Train net output #1: loss = 0.0675807 (* 1 = 0.0675807 loss)
I0630 07:03:03.409931 20971 sgd_solver.cpp:106] Iteration 4200, lr = 1e-06
